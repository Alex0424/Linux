{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DOCS","text":"<p>This page provides centralized documentation of tech knowledge.</p> <p>All the commands provided in this documentation have been tested and are guaranteed to work unless outdated!</p> <ul> <li>Author: Alexander Lindholm</li> <li>Source repository</li> </ul>"},{"location":"agile/","title":"Welcome to Agile Mindset Guide","text":"<p>This documentation is a work in progress</p> <ul> <li>Content may be incomplete and Incorrect.</li> </ul> <p>This comprehensive guide covers agile mindset, DevOps practices, and frameworks to help teams deliver value efficiently and continuously.</p>"},{"location":"agile/#what-is-agile","title":"What is Agile?","text":"<p>Agile is a project management and software development mindset that emphasizes:</p> <ul> <li>Individuals and interactions over processes and tools</li> <li>Working software over comprehensive documentation  </li> <li>Customer collaboration over contract negotiation</li> <li>Responding to change over following a plan</li> </ul>"},{"location":"agile/#agile-devops-a-powerful-combination","title":"Agile + DevOps: A Powerful Combination","text":"<p>While Agile focuses on iterative development and team collaboration, DevOps extends these principles to operations and deployment. Together, they create a complete framework for modern software delivery:</p> <p>Why Combine Agile and DevOps?</p> <ul> <li>Agile delivers working software in short cycles</li> <li>DevOps ensures that software reaches users quickly and reliably</li> <li>Together they enable continuous value delivery from development to production</li> </ul>"},{"location":"agile/#key-benefits-of-integration","title":"Key Benefits of Integration","text":"Agile Strength DevOps Enhancement Combined Result \ud83d\udd04 Iterative development \ud83d\ude80 Continuous deployment Faster time-to-market \ud83d\udc65 Cross-functional teams \ud83d\udd17 Dev-Ops collaboration End-to-end ownership \ud83d\udcc8 Regular feedback \ud83d\udcca Continuous monitoring Real-time insights"},{"location":"agile/#getting-started","title":"Getting Started","text":"<p>New to Agile?</p> <p>Start with the Introduction to understand core concepts.</p>"},{"location":"agile/#quick-navigation","title":"Quick Navigation","text":"Section Description Link \ud83d\ude80 Fundamentals Learn the core principles and frameworks Get started \ud83d\udd04 Agile vs DevOps Understand how Agile and DevOps complement each other Compare approaches \u2699\ufe0f Practices Practical guides for agile ceremonies (coming soon) Explore practices"},{"location":"agile/#what-youll-learn","title":"What You'll Learn","text":"<p>Modern Development Approach</p> <p>This guide teaches you to implement both Agile and DevOps as a unified approach:</p> <ul> <li>\ud83d\udccb Agile Planning: Sprint planning, user stories, and backlog management</li> <li>\ud83d\udd27 DevOps Integration: CI/CD, automation, and continuous monitoring  </li> <li>\ud83e\udd1d Team Collaboration: Breaking down silos between development and operations</li> <li>\ud83d\udcca Continuous Improvement: Using metrics and feedback for iterative enhancement</li> </ul>"},{"location":"agile/fundamentals/agile-vs-devops/","title":"Agile vs DevOps: Understanding the Differences","text":"<p>While Agile and DevOps are often mentioned together, they serve different purposes in software development and organizational culture. Understanding their relationship helps teams implement both effectively.</p>"},{"location":"agile/fundamentals/agile-vs-devops/#what-is-devops","title":"What is DevOps?","text":"<p>DevOps is a set of practices that combines software development (Dev) and IT operations (Ops) to shorten the development lifecycle and provide continuous delivery with high software quality.</p>"},{"location":"agile/fundamentals/agile-vs-devops/#key-differences","title":"Key Differences","text":"Aspect Agile DevOps Focus Software development methodology Software development and operational practices Scope Development team Entire organization (Dev + Ops) Goal Deliver working software frequently Continuous integration and deployment Timeline 2-4 week sprints Continuous activities (CI/CD, monitoring, feedback) Communication Within development team Cross-functional collaboration <p>What 'Continuous' Means in DevOps</p> <p>DevOps \"continuous process\" refers to ongoing activities that happen constantly:</p> <ul> <li>Continuous Integration (CI): Code is merged and tested multiple times per day</li> <li>Continuous Deployment (CD): Code changes are automatically deployed to production</li> <li>Continuous Monitoring: Systems are monitored 24/7 for performance and issues</li> <li>Continuous Feedback: User feedback and metrics are collected in real-time</li> </ul> <p>Unlike Agile's sprint cycles, these DevOps practices don't pause between iterations - they run continuously throughout development and after deployment.</p>"},{"location":"agile/fundamentals/agile-vs-devops/#the-cultural-component","title":"The Cultural Component","text":"<p>When we say DevOps emphasizes \"culture,\" we mean:</p> <ul> <li>Shared responsibility - Developers and operations teams share ownership of the entire software lifecycle</li> <li>Collaboration mindset - Breaking down traditional silos between teams</li> <li>Continuous learning - Embracing failure as learning opportunities</li> <li>Automation first - Cultural shift toward automating repetitive tasks</li> <li>Customer focus - Both Dev and Ops align around delivering value to end users</li> </ul> <p>This cultural transformation is what makes DevOps more than just a set of tools - it's a fundamental change in how teams work together.</p>"},{"location":"agile/fundamentals/agile-vs-devops/#similarities","title":"Similarities","text":"<p>Both Agile and DevOps emphasize:</p> <ul> <li>Collaboration over silos</li> <li>Iterative improvement </li> <li>Customer feedback and responsiveness</li> <li>Automation where possible</li> <li>Quality as a shared responsibility</li> </ul>"},{"location":"agile/fundamentals/agile-vs-devops/#how-they-work-together","title":"How They Work Together","text":"<p>Complementary Approaches</p> <p>Agile and DevOps are not competing methodologies - they complement each other perfectly.</p>"},{"location":"agile/fundamentals/agile-vs-devops/#agile-enables-devops","title":"Agile Enables DevOps","text":"<ul> <li>Short iterations align with continuous delivery</li> <li>Cross-functional teams support DevOps culture</li> <li>Regular retrospectives drive operational improvements</li> </ul>"},{"location":"agile/fundamentals/agile-vs-devops/#devops-enhances-agile","title":"DevOps Enhances Agile","text":"<ul> <li>Automated testing speeds up sprint cycles</li> <li>Continuous deployment reduces release friction</li> <li>Infrastructure as code supports rapid scaling</li> </ul>"},{"location":"agile/fundamentals/agile-vs-devops/#implementation-strategy","title":"Implementation Strategy","text":"<pre><code>graph TD\n    A[Start with Agile] --&gt; B[Establish Sprint Cycles]\n    B --&gt; C[Build Cross-functional Teams]\n    C --&gt; D[Introduce DevOps Practices]\n    D --&gt; E[Automate Testing]\n    E --&gt; F[Implement CI/CD]\n    F --&gt; G[Monitor and Iterate]\n    G --&gt; B</code></pre>"},{"location":"agile/fundamentals/agile-vs-devops/#common-misconceptions","title":"Common Misconceptions","text":"<p>Myth vs Reality</p> <p>Myth: DevOps replaces Agile Reality: DevOps extends Agile principles to operations</p> <p>Myth: You must choose one or the other Reality: They work best when implemented together</p>"},{"location":"agile/fundamentals/agile-vs-devops/#best-practices-for-integration","title":"Best Practices for Integration","text":"<ol> <li>Start with Agile fundamentals</li> <li>Establish sprint cycles</li> <li>Build collaborative culture</li> <li> <p>Focus on working software</p> </li> <li> <p>Gradually introduce DevOps</p> </li> <li>Automate manual processes</li> <li>Implement continuous integration</li> <li> <p>Break down Dev/Ops silos</p> </li> <li> <p>Measure and improve</p> </li> <li>Track deployment frequency</li> <li>Monitor mean time to recovery</li> <li>Gather feedback continuously</li> </ol>"},{"location":"agile/fundamentals/agile-vs-devops/#conclusion","title":"Conclusion","text":"<p>Agile and DevOps are complementary approaches that, when combined, create a powerful framework for delivering high-quality software rapidly and reliably. Organizations benefit most when they implement both as part of a cohesive strategy.</p>"},{"location":"agile/fundamentals/introduction/","title":"Introduction to Modern Software Development","text":"<p>Welcome to the fundamentals of modern software development! This guide explores how Agile mindset and DevOps practices work together to create efficient, collaborative, and responsive development environments.</p>"},{"location":"agile/fundamentals/introduction/#the-evolution-of-software-development","title":"The Evolution of Software Development","text":"<p>Traditional software development often involved long planning phases, extensive documentation, and infrequent releases. Modern approaches emphasize:</p> <ul> <li>Iterative development over waterfall planning</li> <li>Collaboration over siloed teams</li> <li>Continuous delivery over infrequent releases</li> <li>Rapid feedback over delayed validation</li> </ul>"},{"location":"agile/fundamentals/introduction/#two-complementary-approaches","title":"Two Complementary Approaches","text":""},{"location":"agile/fundamentals/introduction/#agile-mindset","title":"Agile Mindset","text":"<p>Focuses on how teams work together to build software: - Iterative development in short cycles (sprints) - Cross-functional team collaboration - Customer feedback and adaptation - Working software as the measure of progress</p>"},{"location":"agile/fundamentals/introduction/#devops-practices","title":"DevOps Practices","text":"<p>Focuses on how software moves from development to production: - Continuous integration and deployment - Infrastructure automation - Monitoring and feedback loops - Collaboration between development and operations</p>"},{"location":"agile/fundamentals/introduction/#the-modern-development-lifecycle","title":"The Modern Development Lifecycle","text":"<pre><code>graph LR\n    A[Planning] --&gt; B[Development]\n    B --&gt; C[Testing]\n    C --&gt; D[Deployment]\n    D --&gt; E[Monitoring]\n    E --&gt; F[Feedback]\n    F --&gt; A\n\n    subgraph \"Agile Focus\"\n    A\n    B\n    end\n\n    subgraph \"DevOps Focus\"\n    C\n    D\n    E\n    end\n\n    subgraph \"Shared\"\n    F\n    end</code></pre>"},{"location":"agile/fundamentals/introduction/#benefits-of-integration","title":"Benefits of Integration","text":"<p>When Agile and DevOps work together, teams achieve:</p> <ul> <li>Faster delivery of valuable features</li> <li>Higher quality through continuous testing and monitoring</li> <li>Better collaboration across all teams</li> <li>Increased reliability and reduced downtime</li> <li>Rapid response to customer needs and market changes</li> </ul>"},{"location":"agile/fundamentals/introduction/#getting-started","title":"Getting Started","text":"<p>Learning Path</p> <p>We recommend following this learning sequence:</p> <ol> <li>Start with Agile: Learn the core principles and mindset</li> <li>Understand frameworks: Explore Scrum or other methodologies</li> <li>Add DevOps: See how Agile and DevOps complement each other</li> <li>Practice: Apply specific practices (link not working) in your team</li> </ol>"},{"location":"agile/fundamentals/introduction/#what-makes-this-approach-different","title":"What Makes This Approach Different?","text":"<p>Modern software development breaks down traditional barriers:</p> Traditional Approach Modern Approach Long planning cycles Short, iterative cycles Separate Dev/Ops teams Collaborative, cross-functional teams Infrequent releases Continuous delivery Documentation-heavy Working software focus Change resistance Change embracement <p>Next Steps</p> <p>Dive deeper into Agile Principles to understand the foundation, or explore how Agile compares to DevOps.</p>"},{"location":"agile/fundamentals/principles/","title":"Agile Principles","text":"<p>Agile mindset transforms how teams approach software development and project management by emphasizing iterative progress, collaboration, and adaptability.</p>"},{"location":"agile/fundamentals/principles/#the-agile-manifesto","title":"The Agile Manifesto","text":"<p>The Agile Manifesto defines four core values that guide agile development:</p> <ol> <li>Individuals and interactions over processes and tools</li> <li>Working software over comprehensive documentation</li> <li>Customer collaboration over contract negotiation</li> <li>Responding to change over following a plan</li> </ol> <p>Understanding the Values</p> <p>These values don't dismiss the importance of processes, documentation, contracts, or plans. Instead, they emphasize that the items on the left are more valuable for successful software development.</p>"},{"location":"agile/fundamentals/principles/#the-12-agile-principles","title":"The 12 Agile Principles","text":"<p>Beyond the four values, the Agile Manifesto outlines 12 principles:</p> <ol> <li>Customer satisfaction through early and continuous delivery of valuable software</li> <li>Welcome changing requirements, even late in development</li> <li>Deliver working software frequently, with a preference for shorter timescales</li> <li>Business people and developers must work together daily</li> <li>Build projects around motivated individuals and trust them to get the job done</li> <li>Face-to-face conversation is the most efficient method of communication</li> <li>Working software is the primary measure of progress</li> <li>Sustainable development pace that teams can maintain indefinitely</li> <li>Technical excellence and good design enhance agility</li> <li>Simplicity - maximizing the amount of work not done</li> <li>Self-organizing teams produce the best architectures and designs</li> <li>Regular reflection and adjustment of team behavior</li> </ol>"},{"location":"agile/fundamentals/principles/#benefits-of-agile-principles","title":"Benefits of Agile Principles","text":"<ul> <li>Faster time to market through iterative delivery</li> <li>Improved customer satisfaction via continuous collaboration</li> <li>Better team collaboration and communication</li> <li>Increased adaptability to changing requirements</li> <li>Higher quality deliverables through continuous improvement</li> <li>Reduced risk through early and frequent feedback</li> </ul>"},{"location":"agile/fundamentals/principles/#common-agile-frameworks","title":"Common Agile Frameworks","text":"<pre><code>graph TD\n    A[Agile Mindset] --&gt; B[Scrum]\n    A --&gt; C[Kanban]\n    A --&gt; D[XP - Extreme Programming]\n    A --&gt; E[SAFe - Scaled Agile]\n    B --&gt; F[Sprint Planning]\n    B --&gt; G[Daily Standups]\n    B --&gt; H[Retrospectives]\n    C --&gt; I[Visual Workflow]\n    C --&gt; J[WIP Limits]\n    D --&gt; K[Pair Programming]\n    D --&gt; L[Test-Driven Development]</code></pre> <p>Choosing a Framework</p> <p>Different frameworks work better for different teams and projects:</p> <ul> <li>Scrum: Great for teams new to agile, provides structure</li> <li>Kanban: Ideal for teams with continuous flow of work</li> <li>XP: Best for teams focused on technical excellence</li> <li>SAFe: Suitable for large organizations with multiple teams</li> </ul>"},{"location":"agile/fundamentals/principles/#implementing-agile-principles","title":"Implementing Agile Principles","text":""},{"location":"agile/fundamentals/principles/#start-small","title":"Start Small","text":"<p>Begin with one or two principles and gradually adopt more as your team becomes comfortable with the agile mindset.</p>"},{"location":"agile/fundamentals/principles/#focus-on-culture","title":"Focus on Culture","text":"<p>Agile is more about mindset and culture than specific practices. Emphasize collaboration, communication, and continuous learning.</p>"},{"location":"agile/fundamentals/principles/#measure-and-adapt","title":"Measure and Adapt","text":"<p>Use metrics like velocity, cycle time, and customer satisfaction to understand your progress and make improvements.</p> <p>Next Steps</p> <p>Learn about specific frameworks starting with Scrum Framework or explore how Agile and DevOps work together.</p>"},{"location":"agile/fundamentals/scrum-framework/","title":"The Scrum Framework: A Complete Guide","text":"<p>Scrum is the most widely adopted Agile framework for managing product development. It provides a structured yet flexible approach to delivering valuable software through iterative development and continuous improvement.</p>"},{"location":"agile/fundamentals/scrum-framework/#what-is-scrum","title":"What is Scrum?","text":"<p>Scrum is a lightweight framework that helps teams work together to develop, deliver, and sustain complex products. It's built on empirical process control theory, emphasizing transparency, inspection, and adaptation.</p>"},{"location":"agile/fundamentals/scrum-framework/#core-principles","title":"Core Principles","text":"<p>Scrum is founded on three pillars:</p> <ul> <li>Transparency - All aspects of the process (work, progress, goals, and challenges) are visible to those responsible  for the outcome</li> <li>Inspection - Scrum artifacts(Product Backlog, Sprint Backlog, Increment/Done) and progress are frequently inspected to detect variances</li> <li>Adaptation - Adjustments are made when deviations are detected</li> </ul>"},{"location":"agile/fundamentals/scrum-framework/#the-scrum-team","title":"The Scrum Team","text":""},{"location":"agile/fundamentals/scrum-framework/#product-owner","title":"Product Owner","text":"<ul> <li>Manages the Product Backlog</li> <li>Defines acceptance criteria and priorities</li> <li>Acts as the voice of the customer</li> </ul>"},{"location":"agile/fundamentals/scrum-framework/#scrum-master","title":"Scrum Master","text":"<ul> <li>Facilitates Scrum events</li> <li>Removes impediments/obstacles for the team</li> <li>Coaches the team on Scrum practices</li> </ul>"},{"location":"agile/fundamentals/scrum-framework/#development-team","title":"Development Team","text":"<ul> <li>Develops the product increment</li> <li>Self-organizes to complete work</li> <li>Typically 3-9 cross-functional members</li> </ul>"},{"location":"agile/fundamentals/scrum-framework/#scrum-events-ceremonies","title":"Scrum Events (Ceremonies)","text":""},{"location":"agile/fundamentals/scrum-framework/#sprint","title":"Sprint","text":"<p>Sprint Overview</p> <p>A time-boxed iteration (usually 1-4 weeks) during which a potentially shippable product increment is created.</p>"},{"location":"agile/fundamentals/scrum-framework/#sprint-planning","title":"Sprint Planning","text":"<p>Purpose: Plan the work for the upcoming sprint Duration: Up to 8 hours for a 4-week sprint  </p> <p>Key questions: 1. What can be delivered in this sprint? 2. How will the work be accomplished?</p>"},{"location":"agile/fundamentals/scrum-framework/#daily-scrum","title":"Daily Scrum","text":"<p>Purpose: Synchronize team activities Duration: 15 minutes  </p> <p>Three questions: 1. What did I do yesterday? 2. What will I do today? 3. Are there any impediments?</p>"},{"location":"agile/fundamentals/scrum-framework/#sprint-review","title":"Sprint Review","text":"<p>Purpose: To present the completed product increment to stakeholders Focus: Gather constructive feedback, and inform future backlog adjustments. Participants: Scrum Team + Stakeholders</p>"},{"location":"agile/fundamentals/scrum-framework/#sprint-retrospective","title":"Sprint Retrospective","text":"<p>Purpose: Inspect the team's process and plan improvements Focus: What went well, what could improve, what to commit to Participants: Scrum Team (Product Owner, Scrum Master, Development Team)</p>"},{"location":"agile/fundamentals/scrum-framework/#scrum-artifacts","title":"Scrum Artifacts","text":""},{"location":"agile/fundamentals/scrum-framework/#product-backlog","title":"Product Backlog","text":"<p>Ordered list of features and requirements for the product, prioritized by business value.</p> <p>Example user story format: <pre><code>As a [user type], I want [goal] so that [benefit]\n\nAcceptance Criteria:\n- Given [context], when [action], then [outcome]\n</code></pre></p>"},{"location":"agile/fundamentals/scrum-framework/#sprint-backlog","title":"Sprint Backlog","text":"<p>Product Backlog items selected for the sprint plus the plan for delivering them.</p>"},{"location":"agile/fundamentals/scrum-framework/#product-increment","title":"Product Increment","text":"<p>Sum of all completed items that meet the Definition of Done.</p>"},{"location":"agile/fundamentals/scrum-framework/#definition-of-done-dod","title":"Definition of Done (DoD)","text":"<p>A shared understanding of completion criteria:</p> <ul> <li>[ ] Code is written and reviewed</li> <li>[ ] Tests are written and passing</li> <li>[ ] Documentation is updated</li> <li>[ ] Product Owner has accepted the work</li> </ul>"},{"location":"agile/fundamentals/scrum-framework/#estimation-and-metrics","title":"Estimation and Metrics","text":""},{"location":"agile/fundamentals/scrum-framework/#story-points","title":"Story Points","text":"<p>Relative sizing using Fibonacci sequence (1, 2, 3, 5, 8, 13, 21) focusing on complexity rather than time.</p>"},{"location":"agile/fundamentals/scrum-framework/#velocity","title":"Velocity","text":"<p>Amount of work completed in a sprint, used for planning future sprints.</p>"},{"location":"agile/fundamentals/scrum-framework/#burndown-charts","title":"Burndown Charts","text":"<p>Visual representation of remaining work in a sprint or release.</p>"},{"location":"agile/fundamentals/scrum-framework/#best-practices","title":"Best Practices","text":""},{"location":"agile/fundamentals/scrum-framework/#getting-started","title":"Getting Started","text":"<ol> <li>Form the team with proper roles</li> <li>Create initial Product Backlog</li> <li>Establish Definition of Done</li> <li>Plan and execute first sprint</li> </ol>"},{"location":"agile/fundamentals/scrum-framework/#common-anti-patterns-to-avoid","title":"Common Anti-Patterns to Avoid","text":"<p>Scrum Anti-Patterns</p> <p>Scrum-but: Skipping key ceremonies or practices Mini-waterfall: Treating sprints as sequential phases Proxy Product Owner: Decision-making by non-PO  </p>"},{"location":"agile/fundamentals/scrum-framework/#continuous-improvement","title":"Continuous Improvement","text":""},{"location":"agile/fundamentals/scrum-framework/#retrospective-techniques","title":"Retrospective Techniques","text":"<ul> <li>Start, Stop, Continue - Simple improvement format</li> <li>5 Whys - Root cause analysis of a problem</li> <li>Focus on actionable improvements each sprint</li> </ul>"},{"location":"agile/fundamentals/scrum-framework/#scrum-process-flow","title":"Scrum Process Flow","text":"<pre><code>graph TD\n    A[Product Backlog] --&gt; B[Sprint Planning]\n    B --&gt; C[Sprint Backlog]\n    C --&gt; D[Sprint Execution]\n    D --&gt; E[Daily Scrum]\n    E --&gt; D\n    D --&gt; F[Sprint Review]\n    F --&gt; G[Sprint Retrospective]\n    G --&gt; H[Product Increment]\n    H --&gt; A\n    F --&gt; A\n\n    style A fill:red\n    style C fill:red\n    style H fill:green</code></pre>"},{"location":"agile/fundamentals/scrum-framework/#conclusion","title":"Conclusion","text":"<p>Scrum provides a proven framework for teams to deliver value incrementally while continuously improving. Success requires commitment to its principles, consistent practice, and willingness to adapt based on experience and feedback.</p>"},{"location":"ai/","title":"AI","text":"<p>This is a documentation site about Artificial Intelligence (AI), covering various topics.</p>"},{"location":"ai/coding_with_ai/cli/","title":"AI in CLI","text":""},{"location":"ai/coding_with_ai/cli/#copilot-cli","title":"Copilot CLI","text":"<p>Source installation</p> <p>It's recomended to login with Github CLI that has Copilot subscription</p>"},{"location":"ai/coding_with_ai/cli/#gemini-cli","title":"Gemini CLI","text":"<p>Source installation</p>"},{"location":"ai/coding_with_ai/process_flow/","title":"How does Copilot process data","text":"<p><code>Code Editor</code> -&gt; <code>Proxy Server</code> -&gt; <code>Toxic Filter</code> -&gt; <code>LLM</code></p> <p><code>LLM</code> -&gt; <code>Proxy Server</code> -&gt; <code>Toxic Filter</code> -&gt; <code>Code Editor</code></p>"},{"location":"ai/fundamentals/agents/","title":"Agents","text":""},{"location":"ai/fundamentals/agents/#what-is-an-agent","title":"What is an Agent?","text":"<ul> <li>Performs a specific task or set of tasks autonomously</li> <li>Uses Advanced Natural Language Processing (NLP) of Large Language Models (LLM)</li> </ul> <p>IBM</p>"},{"location":"ai/fundamentals/ai_models/","title":"AI Models","text":"Acronym Full Name Category GPT Generative Pre-trained Transformer Language Model Architecture SLM Small Language Model Language Model (size class) HLM Hybrid Language Model Language Model Architecture LAM Large Action Model Functional Model built on LLMs LRM Large Reasoning Model Functional Model built on LLMs VLM Vision-Language Model Multimodal Model (vision + text) MoE Mixture of Experts Model Architecture Pattern LCM Latent Consistency Model Generative Image Model (diffusion-family)"},{"location":"ai/fundamentals/ai_models/#gpt-generative-pre-trained-transformer","title":"GPT - Generative Pre-trained Transformer","text":"<ul> <li>Dev by OpenAI to power ChatGPT and other generative AI apps</li> <li>Language Language Model (LLM)<ul> <li>based on Transformer deep learning architecture</li> </ul> </li> </ul>"},{"location":"ai/fundamentals/ai_models/#slm-small-language-model","title":"SLM - Small Language Model","text":"<ul> <li>Smaller version of LLM<ul> <li>fewer parameters</li> </ul> </li> </ul>"},{"location":"ai/fundamentals/ai_models/#hlm-hybrid-language-model","title":"HLM - Hybrid Language Model","text":"<p>?</p>"},{"location":"ai/fundamentals/ai_models/#lam-large-action-model","title":"LAM - Large Action Model","text":"<ul> <li>Agentic AI<ul> <li>AI that can perform multiple tasks autonomously</li> </ul> </li> <li>Built on top of LLMs<ul> <li>Uses LLM to understand and generate human-like text</li> </ul> </li> </ul>"},{"location":"ai/fundamentals/ai_models/#lrm-large-reasoning-model","title":"LRM - Large Reasoning Model","text":"<ul> <li>AI model designed to perform complex reasoning tasks<ul> <li>breaking down problems into smaller steps (resoning traces)</li> </ul> </li> </ul>"},{"location":"ai/fundamentals/ai_models/#vlm-vision-language-model","title":"VLM - Vision-Language Model","text":"<ul> <li>Capable of understanding and processing video, image, text.</li> </ul>"},{"location":"ai/fundamentals/ai_models/#moe-mixture-of-experts","title":"MoE - Mixture of Experts","text":"<ul> <li>Devides AI model into separate sub networks (smaller sub-models (\"experts\"))</li> </ul>"},{"location":"ai/fundamentals/ai_models/#lcm-latent-consistency-model","title":"LCM - Latent Consistency Model","text":"<ul> <li>Generative AI model for creating images</li> <li>Focuses on maintaining consistency in generated images</li> </ul> <p>Sources:</p> <ul> <li>IBM - GPT</li> <li>IBM - SLM</li> <li>IBM - HLM/Agentic</li> <li>IBM - LRM</li> <li>NVIDIA - VLM</li> <li>IDM - MoE</li> <li>Arxiv LCM</li> </ul>"},{"location":"ai/fundamentals/deep_learning/","title":"Deep Learning","text":""},{"location":"ai/fundamentals/deep_learning/#layers-of-ai","title":"Layers of AI","text":"<ul> <li>Machine Learning is a subfield of AI</li> <li>Deep Learning is a subfield of Machine Learning</li> <li><code>Artificial Intelligence</code>(<code>Machine Learning</code>(<code>Deep Learning</code>))<ul> <li><code>AI</code>(<code>ML</code>(<code>DL</code>))</li> </ul> </li> </ul>"},{"location":"ai/fundamentals/deep_learning/#deep-learning_1","title":"Deep Learning","text":"<p>Deep Learning uses deep Artificial Neural Networks (with multiple hidden layers) to learn and process more complex hierarchical patterns than traditional Machine Learning algorithms.</p> <pre><code>Inputs           Hidden Layer                    Outputs\n  x1                 h1   h2   h3   h4   h5          y1   y2\n   o                  o    o    o    o    o           o    o\n   | \\               /|\\  /|\\  /|\\  /|\\  /|\\         / \\  / \n   |  \\             / | \\/ | \\/ | \\/ | \\/ | \\       /   \\/  \n   |   \\           /  | /\\ | /\\ | /\\ | /\\ |  \\     /    /\\  \n   |    \\         /   |/  \\|/  \\|/  \\|/  \\|   \\   /    /  \\ \n   o-----\\-------/----o----o----o----o----o----\\-/----/----\\---\n  x2      \\     /     |\\   |\\   |\\   |\\   |\\     X    \\     X\n           \\   /      | \\  | \\  | \\  | \\  | \\   / \\    \\   / \\\n            \\ /       |  \\ |  \\ |  \\ |  \\ |  \\ /   \\    \\ /   \\\n             o        |   \\|   \\|   \\|   \\|   X     \\    X     X\n            x3        |    |    |    |    |  / \\     \\  / \\   / \\\n                      |    |    |    |    | /   \\     \\/   \\ /   \\\n</code></pre> <ul> <li>Inspired by human brain</li> <li>Made out of many interconnected nodes/neurons</li> <li>Semi Supervised Learning</li> <li>Trains on a small amount of labeled data<ul> <li>Learns basic concepts of a task</li> </ul> </li> <li>Trains on a large amount of unlabeled data<ul> <li>Generalizes (makes data more widespread) by learning from new examples</li> </ul> </li> </ul>"},{"location":"ai/fundamentals/deep_learning/#deep-learning-model-types","title":"Deep Learning Model Types","text":"<p>Discriminative</p> <ul> <li>Used to classify or predict</li> <li>Typically trained on a dataset of labeled data</li> <li>Learns the relationship between the features of the data points and the labels</li> </ul> <p>Generative</p> <ul> <li>Generates new data that is similar to the data it was trained on</li> <li>Understands the distribution of data and how likely a given example is</li> <li>Predicts the next word in a sequence</li> </ul>"},{"location":"ai/fundamentals/deep_learning/#large-language-models-llms","title":"Large Language Models (LLMs)","text":"<ul> <li>Is a subset of Deep Learning<ul> <li><code>AI</code>(<code>ML</code>(<code>DL</code>(<code>LLM</code>)))</li> </ul> </li> </ul>"},{"location":"ai/fundamentals/deep_learning/#sources","title":"Sources","text":"<ul> <li>IBM - Deep Learning</li> <li>Google - Intro to AI</li> </ul>"},{"location":"ai/fundamentals/general_ai/","title":"Artificial General Intelligence","text":"<p>Does not exist yet</p> <p>This model will be able to handle tasks on same level as human capabilities</p>"},{"location":"ai/fundamentals/generative_ai/","title":"Generative AI","text":""},{"location":"ai/fundamentals/generative_ai/#generative-ai","title":"Generative AI","text":"<p>Generative AI</p> <ul> <li>subset of Deep Learning</li> <li>Is Natural Language Image, Audio</li> <li>Not a Number, Discrete, Class probability</li> <li>That is calculated by the formula <code>y = f(x)</code></li> </ul> <p>Generative AI uses very large data from multiple sources across the internet to build a foundation Language Model (Also called Foundation Model)</p> <ul> <li>Pathways Language Model (PaLM)<ul> <li>PaLM API simplifies monitoring deployment and training LLM</li> </ul> </li> <li>Language Model for Dialogue applications (LaMDA)</li> <li>GPT</li> </ul> <p>What is Generative AI:</p> <ul> <li>generates new content based on what it has learned from existing content.</li> <li>GenAI uses the statistical model to predict the expected response might be.</li> </ul>"},{"location":"ai/fundamentals/generative_ai/#input-output","title":"Input &amp; Output","text":"<p>Image</p> <ul> <li>Text</li> <li>Image</li> <li>Video</li> </ul> <p>Text (Input)</p> <ul> <li>Text (output)<ul> <li>Translation</li> <li>Summarization</li> <li>Question Answering</li> <li>Grammar Correction</li> </ul> </li> <li>Image (output)<ul> <li>Image generation</li> <li>Video Generation</li> </ul> </li> <li>Audio (output)<ul> <li>Text-To-Speech</li> </ul> </li> <li>Decisions (output)<ul> <li>Play Games</li> </ul> </li> </ul> <p>ML(DL(Generative AI))</p>"},{"location":"ai/fundamentals/hallucinations/","title":"Hallucinations","text":"<p>AI could gives wrong information, reduce hallucination with Prompt Engineering</p>"},{"location":"ai/fundamentals/hallucinations/#prompt-engineering-techniques-to-reduce-hallucinations","title":"Prompt Engineering Techniques to Reduce Hallucinations","text":"<p>Include</p> <ul> <li>Include instructions of requesting the model not to make up stuff but stay with facts.</li> </ul> <p>Restrict</p> <ul> <li>Restrict the output</li> </ul> <p>Add</p> <ul> <li>Add Chain of Thought style of instruction, \u201cSolve the problem step by step.\u201d</li> </ul> <p>Repeat</p> <ul> <li>Repeat most important instructions in the prompt a couple of times.</li> </ul> <p>Position</p> <ul> <li>Position most important instructions in the last making use of latency effect.</li> </ul> <p>I don't know</p> <ul> <li>tell the prompt: say I don't know if you don't know the answer</li> </ul> <p>Ground AI on the data you have learned it</p> <ul> <li>if the data that i provide is not the company data say: i don't know</li> </ul>"},{"location":"ai/fundamentals/machine_learning/","title":"Machine Learning","text":""},{"location":"ai/fundamentals/machine_learning/#machine-learning","title":"Machine Learning","text":"<p>Machine Learning</p> <ul> <li>System that trains a model from input data</li> </ul> <p>Most common classes of Machine Learning models</p> <ul> <li>unsupervised ML models<ul> <li>no tags<ul> <li>grouping current data into groups to find patterns</li> </ul> </li> </ul> </li> <li>supervised ML models<ul> <li>have label data / label tag<ul> <li>{For Example: [name, type, number]}<ul> <li>is used to predict data from past examples</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"ai/fundamentals/machine_learning_types/","title":"Machine Learning Types","text":""},{"location":"ai/fundamentals/machine_learning_types/#supervised-learning","title":"Supervised Learning","text":"<p>model is trained on a labeled dataset (i.e., the target or outcome variable is known)</p> <p>Examples:</p> <ul> <li>Image classification (cat vs dog)</li> <li>Spam detection</li> </ul>"},{"location":"ai/fundamentals/machine_learning_types/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>The model learns from unlabeled data (it finds patterns on its own)</p> <p>Examples:</p> <ul> <li>Clustering (grouping similar items together)</li> <li>Anomaly detection (identifying unusual in data)</li> <li>Dimensionality reduction (reducing number of features(variables) while keeping the important information)</li> </ul>"},{"location":"ai/fundamentals/machine_learning_types/#self-supervised-learning-ssl","title":"Self-Supervised Learning (SSL)","text":"<p>Models to train themselves on unlabeled data, creates its own labels automatically from the data itself.</p> <p>Explanation:</p> <ul> <li>Instead of humans labeling data (like \u201cthis is a cat\u201d), the model takes part of the data, hides it, and learns to predict the missing part.</li> </ul>"},{"location":"ai/fundamentals/machine_learning_types/#reinforcement-learning","title":"Reinforcement Learning","text":"<p>Model learns by trial and error using rewards and penalties.</p> <p>Examples:</p> <ul> <li>Robotics (robot learns to navigate environment)</li> <li>Game playing agents (Chess, Atari games)</li> </ul>"},{"location":"ai/fundamentals/machine_learning_types/#semi-supervised-learning","title":"Semi-Supervised Learning","text":"<p>combination between supervised and unsupervised learning.</p> <p>Example:</p> <p>Imagine you have:</p> <ul> <li>500 labeled images (you know the correct category)</li> <li>50,000 unlabeled images (no labels)</li> </ul> <p>A semi-supervised model:</p> <ul> <li>Learns structure from all 50,000 images.</li> <li>Uses the 500 labeled examples to fine-tune the decision boundaries.</li> </ul> <p>Result:</p> <ul> <li>You get performance close to a fully supervised model without labeling everything.</li> </ul> <p>Why it matters:</p> <ul> <li>Labeling data is expensive and time-consuming. Semi-supervised learning leverages the alot of unlabeled data to improve model performance with minimal labeled data.</li> </ul> <p>sources:</p> <ul> <li>IBM</li> <li>Geeks for Geeks</li> </ul>"},{"location":"ai/fundamentals/narrow_ai/","title":"Narrow AI","text":"<p>Handles specific analysis or filtering tasks.</p> <p>Different training dataset for each task and models</p> <p>A model trained for object detection could not be used for sentiment analysis.</p>"},{"location":"ai/fundamentals/neural_networks/","title":"Neural Networks","text":""},{"location":"ai/fundamentals/neural_networks/#neural-network-structure","title":"Neural Network Structure","text":"<pre><code>graph LR\n    subgraph Input[\"Input Layer\"]\n        I1[Input 1]\n        I2[Input 2]\n        I3[Input 3]\n        I4[Input n]\n    end\n\n    subgraph Hidden1[\"Hidden Layer 1\"]\n        H1_1[Neuron 1]\n        H1_2[Neuron 2]\n        H1_3[Neuron 3]\n        H1_4[Neuron m]\n    end\n\n    subgraph Hidden2[\"Hidden Layer 2\"]\n        H2_1[Neuron 1]\n        H2_2[Neuron 2]\n        H2_3[Neuron 3]\n    end\n\n    subgraph Output[\"Output Layer\"]\n        O1[Output 1]\n        O2[Output 2]\n    end\n\n    I1 --&gt; H1_1 &amp; H1_2 &amp; H1_3 &amp; H1_4\n    I2 --&gt; H1_1 &amp; H1_2 &amp; H1_3 &amp; H1_4\n    I3 --&gt; H1_1 &amp; H1_2 &amp; H1_3 &amp; H1_4\n    I4 --&gt; H1_1 &amp; H1_2 &amp; H1_3 &amp; H1_4\n\n    H1_1 --&gt; H2_1 &amp; H2_2 &amp; H2_3\n    H1_2 --&gt; H2_1 &amp; H2_2 &amp; H2_3\n    H1_3 --&gt; H2_1 &amp; H2_2 &amp; H2_3\n    H1_4 --&gt; H2_1 &amp; H2_2 &amp; H2_3\n\n    H2_1 --&gt; O1 &amp; O2\n    H2_2 --&gt; O1 &amp; O2\n    H2_3 --&gt; O1 &amp; O2\n\n    style Input fill:#4a90e2,color:#fff\n    style Hidden1 fill:#7b68ee,color:#fff\n    style Hidden2 fill:#9370db,color:#fff\n    style Output fill:#2d8a8a,color:#fff</code></pre>"},{"location":"ai/fundamentals/neural_networks/#how-neural-networks-work","title":"How Neural Networks Work","text":"<pre><code>flowchart TD\n    A[Input Data] --&gt; B[Input Layer]\n    B --&gt; C[Hidden Layers]\n    C --&gt; D{Activation Function}\n    D --&gt; E[Weighted Sum]\n    E --&gt; F[Forward Propagation]\n    F --&gt; G[Output Layer]\n    G --&gt; H[Prediction/Result]\n\n    H --&gt; I{Compare with Actual}\n    I --&gt; J[Calculate Loss/Error]\n    J --&gt; K[Backpropagation]\n    K --&gt; L[Update Weights &amp; Biases]\n    L --&gt; M{Training Complete?}\n    M --&gt;|No| B\n    M --&gt;|Yes| N[Trained Model]\n\n    style A fill:#4a90e2,color:#fff\n    style H fill:#2d8a8a,color:#fff\n    style J fill:#e74c3c,color:#fff\n    style N fill:#27ae60,color:#fff</code></pre>"},{"location":"ai/fundamentals/neural_networks/#neural-network-components","title":"Neural Network Components","text":"<ul> <li>Input Layer: Receives raw data (features)</li> <li>Hidden Layers: Process and transform data through weighted connections</li> <li>Output Layer: Produces final prediction or classification</li> <li>Weights: Determine strength of connections between neurons</li> <li>Bias: Allows shifting of activation function</li> <li>Activation Function: Introduces non-linearity (ReLU, Sigmoid, Tanh)</li> <li>Forward Propagation: Data flows from input to output</li> <li>Backpropagation: Error flows backward to update weights</li> <li>Loss Function: Measures prediction error</li> </ul>"},{"location":"ai/fundamentals/neural_networks/#types-of-neural-networks","title":"Types of Neural Networks","text":"<pre><code>graph TD\n    A[Neural Networks] --&gt; B[Feedforward NN]\n    A --&gt; C[Convolutional NN]\n    A --&gt; D[Recurrent NN]\n    A --&gt; E[Transformer]\n\n    B --&gt; B1[Simple Classification]\n    C --&gt; C1[Image Recognition]\n    C --&gt; C2[Computer Vision]\n    D --&gt; D1[Time Series]\n    D --&gt; D2[Natural Language]\n    E --&gt; E1[LLMs]\n    E --&gt; E2[Translation]\n\n    style A fill:#333,color:#fff\n    style B fill:#4a90e2,color:#fff\n    style C fill:#7b68ee,color:#fff\n    style D fill:#e74c3c,color:#fff\n    style E fill:#27ae60,color:#fff</code></pre>"},{"location":"ai/fundamentals/neural_networks/#source","title":"Source","text":"<ul> <li>IBM - Neural Networks</li> </ul>"},{"location":"ai/fundamentals/prompt/","title":"Prompt","text":""},{"location":"ai/fundamentals/prompt/#prompt","title":"Prompt","text":"<p>Input that users sends into the GenAI</p> <ul> <li>quality of input determines the quality output</li> </ul>"},{"location":"ai/fundamentals/rag/","title":"Retrieval-Augmented Generation (RAG)","text":""},{"location":"ai/fundamentals/rag/#what-is-retrieval-augmented-generation","title":"What is Retrieval-Augmented Generation","text":"<ul> <li>optimizing the output of a LLM</li> <li>referencing trusted knowledge base outside of the LLM training data</li> <li>combining pre-trained LLM with internal data source</li> </ul>"},{"location":"ai/fundamentals/rag/#benefits","title":"Benefits","text":"<ul> <li>Accurate and up-to-date information</li> <li>Cost effective way to use LLM for your organization</li> <li>More developer control</li> </ul>"},{"location":"ai/fundamentals/rag/#rag-workflow","title":"RAG Workflow","text":"<pre><code>flowchart TD\n    A[User Query] --&gt; B[Query Processing]\n    B --&gt; C[Retrieve Relevant Documents]\n    C --&gt; D[Knowledge Base/Vector Database]\n    D --&gt; E[Retrieved Context]\n    E --&gt; F[Augment Prompt]\n    A --&gt; F\n    F --&gt; G[LLM Processing]\n    G --&gt; H[Generated Response]\n    H --&gt; I[Final Answer to User]\n\n    style A fill:#4a90e2,color:#fff\n    style D fill:#f39c12,color:#fff\n    style G fill:#9b59b6,color:#fff\n    style I fill:#27ae60,color:#fff</code></pre>"},{"location":"ai/fundamentals/rag/#how-rag-works","title":"How RAG Works","text":"<ol> <li>User Query: User submits a question or request</li> <li>Query Processing: The query is processed and converted into a searchable format (often vector embeddings)</li> <li>Retrieve Relevant Documents: Search the knowledge base for relevant information</li> <li>Knowledge Base: Internal documents, databases, or vector stores containing organizational data</li> <li>Retrieved Context: Relevant documents/snippets are extracted</li> <li>Augment Prompt: Combine user query with retrieved context</li> <li>LLM Processing: The augmented prompt is sent to the LLM</li> <li>Generated Response: LLM generates an answer based on both its training and the retrieved context</li> <li>Final Answer: User receives an accurate, context-aware response</li> </ol> <p>Source: AWS - RAG</p>"},{"location":"ai/fundamentals/super_ai/","title":"Super AI","text":"<p>Does not exist yet</p> <p>Will probably be developed after general ai is out</p> <p>Capable of doing tasks better than humans beings.</p>"},{"location":"cybersecurity/","title":"Cybersecurity","text":"<p>Welcome to the cybersecurity page. Use the navigation to the left to read more.</p>"},{"location":"cybersecurity/threat-landscape/","title":"The Threat Landscape","text":"<p>Picture of threat, risks, and actors that are manipulating our digital system. This mean harmful code, attempted intrusion, social engineering, and insider threat. Tech is changing, new threats is discovered and attackers are constantly evolving their methods, To protect both individuals and organizations, we therefore need to continuously monitor trends and attack vectors and translate them into practical defenses, training, and improved policies.</p>"},{"location":"cybersecurity/threat-landscape/#cyber-threat-actorscta","title":"Cyber Threat Actors(CTA)","text":"<p>individuals or groups that penetrate the system with malicious or curious intentions. Their motives range from financial gain and political goals to outright vandalism.</p>"},{"location":"cybersecurity/threat-landscape/#actor-types","title":"Actor Types:","text":"<p>Explorer</p> <ul> <li>Least malicious type. The driving force is more about recognition and curiosity than harm. actor who is skilled at finding vulnerabilities and exploiting them, similar to how a threat hunter actively searches for threats. They are happy to show what they can do, for example by modifying a web page. They often use social engineering, especially phishing, where the recipient is manipulated into giving up information or opening malicious attachments. To succeed, the message needs to appear harmless and create a sense of urgency. The spearphishing variation is aimed at a selected person or group, and the same basic principles also apply via telephone (vishing) and text message (smishing). Even if the explorer is not seeking maximum damage, the outcome can be noticeable if vulnerabilities are exploited effectively.</li> </ul> <p>Hacktivist</p> <ul> <li>Hacktivists are usually motivated by social justice, political change, government transparency, or anti-censorship goals. They aim to expose wrongdoing, protest policies, or support movements such as human rights or environmental causes. They often operate in loosely organized, anonymous online groups and build botnets to coordinate traffic from thousands of compromised nodes. Using a command-and-control (C2) server, they can flood a target with simultaneous requests in a distributed denial-of-service (DDoS) attack. Their resources are rarely unlimited, but high motivation can still cause significant disruption to visible targets.</li> </ul> <p>Cyberterrorist </p> <ul> <li>Acts of violence, disruption, or intimidation for political, ideological, or religious purposes. These acts can include hacking critical infrastructure like power plants, air traffic control, or financial systems to cause fear, panic, and significant harm.</li> </ul> <p>Cybercriminal (Steal Money) </p> <ul> <li>Cybercriminals are driven by profit. Their operations often involve identity theft, credit card fraud, and ransomware, where victims\u2019 files are encrypted and released only after a payment, usually in cryptocurrency. Sometimes, different threat actors collaborate\u2014criminal and state-sponsored groups may combine their skills, as seen in real-world cases. These overlapping motives make it harder to identify attackers and develop effective countermeasures.</li> </ul> <p>Cyberwarrior </p> <ul> <li>The cyber warrior is the most well-resourced. This actor operates for national interests and may be funded, protected, and equipped by the state. Their most effective tools include exploiting so-called zero-day vulnerabilities in common operating systems and applications. Because the vendor is unaware of the flaw, no patch is available. As a result, attacks can be executed with high precision against strategic targets, ranging from espionage to sabotage. This capability makes the cyber warrior particularly difficult to counter with baseline controls alone.</li> </ul>"},{"location":"cybersecurity/threat-landscape/#hacker-categories-hat-types","title":"Hacker Categories (Hat Types)","text":"<p>White-hat</p> <ul> <li>Works with permission to find vulnerabilities and improve them.</li> </ul> <p>Black-hat</p> <ul> <li>Act without permission to win/chaos.</li> </ul> <p>Grey-hat</p> <ul> <li>Brakes the rules but without malicious intent (may sometimes report what they find, although not always in an ethical manner.)</li> </ul> <p>Blue-hat</p> <ul> <li>Blue hats are external testers who are hired to test systems before or during operation.</li> </ul>"},{"location":"cybersecurity/threat-landscape/#cybersecurity-threats-and-attack-vectors","title":"Cybersecurity threats and attack vectors","text":"<p>A cybersecurity threat can be described as an action that exploits a vulnerability and harms a network or system. When analyzing an attack vector, we look at three parts: the vulnerability (the weak point), the mechanism (the tool or method that exploits the weakness), and the path (the channel the attacker uses to reach the target). A common example is an email that appears to come from a colleague, containing a \u201cdocument\u201d that actually installs malware when opened. In this case, the vulnerability is the user\u2019s trust, the mechanism is the malicious code combined with social engineering, and the path is the email channel. Threats can be categorized as social engineering, malware, unauthorized access, or system design flaws. It\u2019s important to note that a single incident often spans multiple categories. By building skills and procedures to identify, educate, update, and design properly, we can significantly reduce the likelihood of successful attacks.</p>"},{"location":"git/","title":"GIT","text":"<p>This is a collection of useful GIT commands and configurations for command line interface (CLI) users.</p>"},{"location":"git/#links-to-useful-git-practices","title":"Links to useful GIT practices","text":"<ul> <li>GIT Game</li> <li>Video Lecture</li> </ul>"},{"location":"git/#what-is-git-version-control-system-tool","title":"What is GIT (Version Control System Tool)","text":"<ul> <li>Git tracks changes to a project over time, storing them as a series of snapshots (commits).</li> <li>Capture the entire state (files) of a project</li> <li>Authors and timestamp</li> <li>A history of commits(each commit is a change) for rollback capability if bugs happens.</li> <li>Collaboration Tool</li> </ul>"},{"location":"git/#git-history-model-metadata","title":"GIT History Model - Metadata","text":"<p>type blob = array <p>type tree = map <p>type commits = struct     parents: array     author: string     timestamp: datetime     message: string     snapshot: tree <p>type object = blob | tree | commit</p> <p>objects = map <p>Git identifies commits by <code>SHA1</code> (40char string)</p> <p>HEAD: is on what commit you're looking at</p> <p>Check changes compared to latest commit</p> <pre><code>git diff &lt;commit-hash&gt;`hello.txt`\n</code></pre>"},{"location":"git/clone/http/","title":"Git Clone With HTTPS","text":"<pre><code>#git config --global user.name &lt;YOUR USERNAME&gt; # ignore this\n#git config --global user.email &lt;YOUR EMAIL&gt;   # ignore this\n</code></pre> <pre><code>git clone https://github.com/&lt;USERNAME&gt;/&lt;REPO NAME&gt;.git\n</code></pre> <p>after a git pull or push Git will prompt you for your username and password: <pre><code>Username for 'https://github.com': &lt;your-username&gt;\nPassword for 'https://github.com': &lt;Paste your Personal Access Token here&gt;\n</code></pre></p> <p>Cache your credentials temporarily (for 1 hour) <pre><code>git config --global credential.helper 'cache --timeout=3600'\n</code></pre></p> <p>or store credentials permanently in plain text <pre><code>git config --global credential.helper store\n</code></pre></p>"},{"location":"git/clone/ssh/","title":"Git Clone With SSH","text":"<p>generate a new ssh key: <pre><code>ssh-keygen -t ed25519 -C \"your_email@example.com\"\ncat cat ~/.ssh/id_ed25519.pub\n</code></pre> on github.com --&gt; settings/ssh --&gt; New SSH Key --&gt; paste your public ssh key here</p> <p>make sure ssh-agent is running and add ssh key to ssh-agent: <pre><code>eval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/&lt;private_key&gt;\n</code></pre></p> <p>make ssh-agent to remember it permanent, then do this:</p> <p><code>vim ~/.bashrc</code> <pre><code>if [ -z \"$SSH_AUTH_SOCK\" ]; then\n  eval \"$(ssh-agent -s)\"\n  ssh-add ~/.ssh/&lt;private_key&gt;\nfi\n</code></pre></p> <pre><code>git clone git@github.com:USERNAME/REPO_NAME.git\n</code></pre>"},{"location":"git/clone/swap_http_ssh/","title":"Switch from https to ssh or the other way","text":"<p>check status <pre><code>git remote -v\n</code></pre></p>"},{"location":"git/clone/swap_http_ssh/#from-https-to-ssh","title":"from https to ssh","text":"<pre><code>git remote set-url origin https://github.com/username/REPO.git\n</code></pre>"},{"location":"git/clone/swap_http_ssh/#from-ssh-to-https","title":"from ssh to https","text":"<pre><code>git remote set-url origin git@github.com:USERNAME/REPO.git\n</code></pre>"},{"location":"git/commands/bisect/","title":"Bisect","text":""},{"location":"git/commands/bisect/#git-bisect-binary-searches-the-history","title":"Git Bisect (Binary searches the history)","text":"<pre><code>git bisect\n</code></pre>"},{"location":"git/commands/bisect/#script-that-searches-for-latest-commit-where-unit-test-stopped-passing","title":"Script that searches for latest commit where unit test stopped passing","text":"<pre><code>touch ./bisect-test.sh &amp;&amp; \\\nchmod +x &amp;&amp; \\\nvim ./bisect-test.sh\n</code></pre> <pre><code>#!/usr/bin/env bash\n\n# Avoid exiting early; we want to control exit codes explicitly.\nset +e\n\n# Optional: clean/build if your project needs it\n# build_cmd here is an example; replace with your actual build steps.\nif ! ./build.sh &gt; /dev/null 2&gt;&amp;1; then\n  echo \"[skip] build failed; not judging this commit\"\n  exit 125\nfi\n\n# Run your test command; examples:\n#   pytest -q\n#   mvn -q -DskipTests=false test\n#   npm test --silent\n#   go test ./...\n./run-unit-tests.sh\ntest_status=$?\n\n# If your test runner already returns non-zero on failures, you can use it directly.\nif [ $test_status -eq 0 ]; then\n  echo \"[good] tests passed\"\n  exit 0\nelse\n  echo \"[bad] tests failed (exit $test_status)\"\n  # Map any non-zero to 1 so Git treats it as \"bad\"\n  exit 1\nfi\n</code></pre> <pre><code>git bisect start\ngit bisect bad                     # current commit fails\ngit bisect good v1.4.2             # or some SHA/tag you know was passing\ngit bisect run ./bisect-test.sh    # will auto-checkout and test several commits\n# When it finishes, Git prints the first bad commit.\ngit bisect reset                   # return to your original branch\n</code></pre>"},{"location":"git/commands/branch/","title":"Branch","text":""},{"location":"git/commands/branch/#local","title":"Local","text":"<pre><code>git branch -a                           # list all branches\ngit branch -c &lt;branch_name&gt;             # create a new branch\ngit branch -d &lt;branch_name&gt;             # delete a local branch\ngit branch -D &lt;branch_name&gt;             # force delete branch locally\n</code></pre>"},{"location":"git/commands/branch/#remote","title":"Remote","text":"<pre><code>git push origin &lt;branch-name&gt;           # push branch to remote\ngit push origin --delete &lt;branch-name&gt;  # delete branch from remote\n</code></pre>"},{"location":"git/commands/checkout/","title":"Checkout","text":"<pre><code>git checkout &lt;commit-hash&gt;      # move HEAD to specific commit (detached HEAD)\ngit checkout &lt;file-path&gt;        # restore file to last committed state\ngit checkout &lt;branch&gt;           # switch to another branch\n</code></pre>"},{"location":"git/commands/default_commands/","title":"Default Commands","text":"<p>taking a copy of remote repository and initializing a local:</p> <pre><code>git clone &lt;optional arguments&gt; &lt;remote URL/path&gt; ./&lt;path_name&gt;\n</code></pre> <p>Retrieving changes from remote branch to local:</p> <pre><code>git fetch\n</code></pre> <p>Integrate fetched changes from remote into current local branch:</p> <pre><code>git merge\n</code></pre> <p>Same as fetch and merge:</p> <pre><code>git pull\n</code></pre> <p>Add files to staging:</p> <pre><code>git add . -p\n</code></pre> <p>Create a snapshot from staging files:</p> <pre><code>git commit -m \"Updated file1.txt\"\n</code></pre> <p>Send changes from local branch to remote:</p> <pre><code>git push\n</code></pre>"},{"location":"git/commands/default_commands/#git-commands","title":"GIT COMMANDS","text":"<pre><code>git checkout &lt;file&gt;                     # undo changes in a file to recent git push change\ngit restore --staged &lt;file name&gt;        # restore a staged file\ngit revert HEAD                         # revert a commit | this would be saved as history in a commit\ngit reset --hard &lt;commit_id&gt;            # go back in time to a commit_id and remove future history/commits | won't create a commit in timeline\n</code></pre>"},{"location":"git/commands/default_commands/#initialize-a-git-repository","title":"Initialize a GIT repository","text":"<pre><code>cd /path/to/your/project\ngit init\ngit add .\ngit commit -m \"Initial commit\"\n</code></pre> <p>Create repository on github without a readme</p> <p>follow on screen commands</p>"},{"location":"git/commands/default_commands/#check-changes-inside-a-commit","title":"Check changes inside a commit","text":"<pre><code>git cat-file -p &lt;commit-id&gt;\ngit cat-file -p &lt;tree-id&gt;\ngit cat-file -p &lt;blob-id&gt;\n</code></pre>"},{"location":"git/commands/diff/","title":"Diff","text":""},{"location":"git/commands/diff/#everything","title":"Everything <code>*</code> <code>.</code>","text":"<p>Local (working directory vs. last commit):</p> <pre><code>git diff HEAD\n</code></pre> <p>Between 2 <code>commits</code>/<code>branches</code>/<code>tags</code>:</p> <pre><code>git diff &lt;commit1|branch1|tag1|HEAD~1&gt; &lt;commit2|branch2|tag2|HEAD&gt;\n</code></pre>"},{"location":"git/commands/diff/#file","title":"File","text":"<p>Local (working directory vs. last commit):</p> <pre><code>git diff HEAD -- hello.txt\n</code></pre> <p>Between 2 <code>commits</code>/<code>branches</code>/<code>tags</code>:</p> <pre><code>git diff &lt;commit1|branch1|tag1|HEAD~1&gt; &lt;commit2|branch2|tag2|HEAD&gt; -- hello.txt\n</code></pre>"},{"location":"git/commands/diff/#options","title":"Options","text":"<p>staged changes: <code>--cached</code> <code>`git diff --cached</code></p> <p>file names: <code>--name-only</code> <code>git diff --name-only HEAD</code></p> <p>add/rm lines: <code>--stat</code> <code>git diff --stat HEAD</code></p> <p>word-level: <code>--word-diff</code> <code>git diff --word-diff HEAD</code></p>"},{"location":"git/commands/diff/#advanced","title":"Advanced","text":"<pre><code>git diff &lt;commit_id&gt;..&lt;commit_id&gt; # changes between two commits\n</code></pre> <pre><code>git diff &lt;commit_id&gt;...&lt;commit_id&gt; # changes from the common ancestor to the second commit\n</code></pre>"},{"location":"git/commands/diff/#who-edit-what-fileline","title":"Who edit what file/line","text":"<pre><code>git blame\n</code></pre>"},{"location":"git/commands/log/","title":"History","text":""},{"location":"git/commands/log/#visualize-branches-branches-and-merges","title":"Visualize Branches (branches and merges)","text":"<pre><code>git log --oneline --graph --all --decorate\n</code></pre>"},{"location":"git/commands/log/#pretty-log","title":"Pretty log","text":"<pre><code>git log --pretty=format:\"%h %an %ar %s\"\n</code></pre>"},{"location":"git/commands/log/#author","title":"Author","text":"<pre><code>git log --author=\"Alexander\"\n</code></pre>"},{"location":"git/commands/log/#keyword","title":"Keyword","text":"<pre><code>git log --grep=\"bugfix\"\n</code></pre>"},{"location":"git/commands/log/#file","title":"File","text":"<pre><code>git log -- hello.txt\n</code></pre>"},{"location":"git/commands/log/#show-commits-between-two-refs","title":"Show commits between two refs:","text":"<pre><code>git log branch1..branch2\n</code></pre>"},{"location":"git/commands/log/#last-5-commits","title":"Last 5 commits","text":"<pre><code>git log -5\n</code></pre>"},{"location":"git/commands/log/#time","title":"Time","text":"<pre><code>git log --since=\"1 week ago\"\n</code></pre>"},{"location":"git/commands/log/#two-dates","title":"Two Dates","text":"<pre><code>git log --since=\"2024-01-01\" --until=\"2024-01-31\"\n</code></pre>"},{"location":"git/commands/remote_repository/","title":"Remote Repository","text":""},{"location":"git/commands/remote_repository/#add-a-remote-branch","title":"Add a Remote Branch","text":"<pre><code>git remote add &lt;remote_name&gt; &lt;repository path/URL&gt;\ngit push -u &lt;remote_name&gt; &lt;local_branch&gt;:&lt;remote_branch&gt;\ngit branch --set-upstream-to=&lt;remote-branch-name&gt;\n</code></pre> <p><code>-u</code> = <code>--set-upstream</code> - meaning your local branch will now \"track\" the specified remote branch.   - git push (without arguments) will know which remote and branch to push to.   - git pull will automatically pull from the corresponding remote branch.</p>"},{"location":"git/commands/remote_repository/#viewing-remote","title":"Viewing Remote","text":"<pre><code>git remote -v\n</code></pre> <p><code>-v</code> = <code>--verbose</code> This will show the URLs for both fetching and pushing</p>"},{"location":"git/commands/remote_repository/#renaming-remote","title":"Renaming Remote","text":"<pre><code>git remote rename &lt;old_remote_name&gt; &lt;new_remote_name&gt;\n</code></pre>"},{"location":"git/commands/remote_repository/#removing-remote","title":"Removing Remote","text":"<ol> <li> <p>Delete branch on the remote repository (remote changes) <pre><code>git push &lt;remote_name&gt; --delete &lt;branch_name&gt;\n</code></pre></p> </li> <li> <p>Disconnect upstream (local changes) <pre><code>git remote remove &lt;remote_name&gt;\n</code></pre></p> </li> </ol>"},{"location":"git/commands/stash/","title":"Stash","text":""},{"location":"git/commands/stash/#git-stash","title":"Git Stash","text":"<pre><code>git stash # save changes to stash\n\ngit stash list # view stash list\n\ngit stash pop {&lt;stash_id&gt;} # apply and remove stash\n</code></pre>"},{"location":"git/commands/status_ui/","title":"GIT STATUS in CLI prompt (Linux)","text":"<p>Branch status like this</p> <p>To apply this UI prompt info, then edit this file:</p> <p><code>vim ~/.bashrc</code></p> <pre><code>############################################################################################################\n\n# shows on what branch you're on\nparse_git_branch() {\n  git branch 2&gt;/dev/null | grep '*' | sed 's/* //'\n}\n\nexport PS1=\"\\u@\\h \\W \\[\\033[32m\\]\\$(parse_git_branch)\\[\\033[00m\\] $ \"\n############################################################################################################\n# Function to display Git status indicators\nparse_git_status() {\n  local STATUS=\"\"\n  local GIT_DIR=\"$(git rev-parse --git-dir 2&gt;/dev/null)\"\n\n  if [[ -n \"$GIT_DIR\" ]]; then\n    # Check for staged changes\n    if [[ -n $(git diff --cached --name-only) ]]; then\n      STATUS+=\"\u25cf\"  # Staged (green)\n    fi\n\n    # Check for unstaged changes\n    if [[ -n $(git diff --name-only) ]]; then\n      STATUS+=\"\u271a\"  # Unstaged (yellow)\n    fi\n\n    # Check for untracked files\n    if [[ -n $(git ls-files --others --exclude-standard) ]]; then\n      STATUS+=\"\u2731\"  # Untracked (red)\n    fi\n  fi\n\n  echo \"$STATUS\"\n}\n\n# Add to PS1 with branch and status\nexport PS1=\"\\u@\\h \\W \\[\\033[32m\\]\\$(parse_git_branch)\\[\\033[31m\\]\\$(parse_git_status)\\[\\033[00m\\] $ \"\n\n\n#############################################################################################################\nparse_git_ahead_behind() {\n  local GIT_DIR=\"$(git rev-parse --git-dir 2&gt;/dev/null)\"\n\n  if [[ -n \"$GIT_DIR\" ]]; then\n    local UPSTREAM=\"@{u}\"\n    local LOCAL=$(git rev-parse @)\n    local REMOTE=$(git rev-parse \"$UPSTREAM\" 2&gt;/dev/null)\n    local BASE=$(git merge-base @ \"$UPSTREAM\" 2&gt;/dev/null)\n\n    if [[ $LOCAL == $REMOTE ]]; then\n      echo \"\"  # Up to date\n    elif [[ $LOCAL == $BASE ]]; then\n      echo \"\u2193\"  # Need to pull\n    elif [[ $REMOTE == $BASE ]]; then\n      echo \"\u2191\"  # Need to push\n    else\n      echo \"\u2195\"  # Diverged\n    fi\n  fi\n}\n\n# Add to PS1 with branch, status, and ahead/behind info\nexport PS1=\"\\u@\\h \\W \\[\\033[32m\\]\\$(parse_git_branch)\\[\\033[31m\\]\\$(parse_git_status)\\[\\033[33m\\]\\$(parse_git_ahead_behind)\\[\\033[00m\\] $ \"\n\n############################################################################################################\nparse_git_commit_hash() {\n  git log --pretty=format:'%h' -n 1 2&gt;/dev/null\n}\n\n# Add commit hash to PS1\nexport PS1=\"\\u@\\h \\W \\[\\033[32m\\]\\$(parse_git_branch)\\[\\033[31m\\]\\$(parse_git_status)\\[\\033[33m\\]\\$(parse_git_ahead_behind) \\[\\033[36m\\]\\$(parse_git_commit_hash)\\[\\033[00m\\] $ \"\n\n############################################################################################################\nparse_git_commits_since_tag() {\n  git describe --tags --abbrev=0 2&gt;/dev/null\n}\n\nparse_git_commits_count() {\n  local TAG=$(parse_git_commits_since_tag)\n  if [[ -n \"$TAG\" ]]; then\n    git rev-list \"${TAG}..\" --count 2&gt;/dev/null\n  fi\n}\n\n# Add commits since last tag to PS1\nexport PS1=\"\\u@\\h \\W \\[\\033[32m\\]\\$(parse_git_branch)\\[\\033[31m\\]\\$(parse_git_status)\\[\\033[33m\\]\\$(parse_git_ahead_behind) \\[\\033[36m\\]\\$(parse_git_commit_hash)\\[\\033[35m\\]\\$(parse_git_commits_count)\\[\\033[00m\\] $ \"\n\n############################################################################################################\nparse_git_commit_time() {\n  local commit_time=$(git log -1 --pretty=format:%cr 2&gt;/dev/null)\n  echo \"$commit_time\"\n}\n\n# Add time since last commit to PS1\nexport PS1=\"\\u@\\h \\W \\[\\033[32m\\]\\$(parse_git_branch)\\[\\033[31m\\]\\$(parse_git_status)\\[\\033[33m\\]\\$(parse_git_ahead_behind) \\[\\033[36m\\]\\$(parse_git_commit_hash)\\[\\033[34m\\]\\$(parse_git_commit_time)\\[\\033[00m\\] $ \"\n\n############################################################################################################\nparse_git_dirty() {\n  if [[ -n $(git status --porcelain 2&gt;/dev/null) ]]; then\n    echo \"\u2717\"  # Dirty\n  else\n    echo \"\u2713\"  # Clean\n  fi\n}\n\n# Add to PS1 with dirty/clean indicator\nexport PS1=\"\\u@\\h \\W \\[\\033[32m\\]\\$(parse_git_branch)\\[\\033[31m\\]\\$(parse_git_status)\\[\\033[33m\\]\\$(parse_git_ahead_behind) \\[\\033[36m\\]\\$(parse_git_commit_hash) \\[\\033[35m\\]\\$(parse_git_dirty)\\[\\033[00m\\] $ \"\n\n############################################################################################################\n</code></pre>"},{"location":"git/concepts/checkout_vs_cherrypick/","title":"Git Cherry Pick vs Git Checkout","text":""},{"location":"git/concepts/checkout_vs_cherrypick/#checkout","title":"Checkout","text":"<p>Useful Scenario: Move your working directory and HEAD to another commit, branch, or file state.</p> <p>File rollback - restore a file to a few commits ago</p> <p>Detached HEAD - puts you to a past commit</p>"},{"location":"git/concepts/checkout_vs_cherrypick/#cherry-pick","title":"Cherry Pick","text":"<p>Useful Scenario: Take a commit from one branch and apply it on top of the current branch.</p> <p>Useful Scenario - Release and main branch   - Cut the release branch and add few commits ahead of release branch</p>"},{"location":"git/concepts/checkout_vs_cherrypick/#difference","title":"Difference","text":"Aspect git checkout git cherry-pick Effect on history None (just moves HEAD) Rewrites history by adding a new commit Danger Detached HEAD if checking out a commit Can cause duplicate commits if overused"},{"location":"git/concepts/checkout_vs_cherrypick/#about-cherry-pick-vs-checkout-git-conflict-scenario","title":"About cherry-pick VS checkout - git conflict scenario","text":"<p>Cherry Conflict - If the commit you\u2019re cherry-picking modifies the same lines as commits already present in the branch you\u2019re applying it to.</p> <p>Checkout Conflict - If you switch branches and the branch you\u2019re checking out has changes that conflict with uncommitted changes in your working directory.</p> <p></p>"},{"location":"git/concepts/git-config/","title":"Git Config","text":"<p>3 levels of git config hierarchy</p> <pre><code>flowchart TD\n    subgraph System[\"System Level - Operating System\"]\n        direction TB\n        S1[\"Base: git config --system\"]\n        S2[\"View: git config --system --list\"]\n        S3[\"Stored: /etc/gitconfig (UNIX)&lt;br/&gt;C:\\Documents and Settings\\All Users\\Application Data\\Gitconfig (WINDOWS)\"]\n        S1 --- S2 --- S3\n    end\n\n    subgraph Global[\"Global Level - User Specific\"]\n        direction TB\n        G1[\"Base: git config --global\"]\n        G2[\"View: git config --global --list\"]\n        G3[\"Stored: ~/.gitconfig (UNIX)&lt;br/&gt;C:\\Users\\.gitconfig (WINDOWS)\"]\n        G1 --- G2 --- G3\n    end\n\n    subgraph Local[\"Local Level - Repository Specific\"]\n        direction TB\n        L1[\"Base: git config --local\"]\n        L2[\"View: git config --local --list\"]\n        L3[\"Stored: .git/config\"]\n        L1 --- L2 --- L3\n    end\n\n    System --&gt;|Override| Global\n    Global --&gt;|Override| Local\n\n    style System fill:#2d8a8a,stroke:#333,stroke-width:2px,color:#fff\n    style Global fill:#b8860b,stroke:#333,stroke-width:2px,color:#fff\n    style Local fill:#d96e4f,stroke:#333,stroke-width:2px,color:#fff</code></pre>"},{"location":"git/concepts/git-config/#level-1-system-operating-system","title":"Level 1: System - Operating System","text":"<ul> <li>BASE: <code>git config --system</code></li> <li>VIEW: <code>git config --system --list</code></li> <li>Stored: <code>/etc/gitconfig</code></li> </ul>"},{"location":"git/concepts/git-config/#level-2-global-user-specific","title":"Level 2: Global - User Specific","text":"<ul> <li>BASE: <code>git config --global</code></li> <li>VIEW: <code>git config --global --list</code></li> <li>Stored: <code>~/.gitconfig</code></li> </ul>"},{"location":"git/concepts/git-config/#level-3-local-repository-specific","title":"Level 3: Local - Repository Specific","text":"<ul> <li>BASE: <code>git config --local</code></li> <li>VIEW: <code>git config --local --list</code></li> <li>Stored: <code>.git/config</code></li> </ul>"},{"location":"git/concepts/merge_vs_rebase/","title":"GIT MERGE vs REBASE","text":""},{"location":"git/concepts/merge_vs_rebase/#merge","title":"MERGE","text":"<p>Pros: full commit history and branch evolution</p> <p>Cons: Can lead to lots of merge commits -&gt; messy history.</p> <p>INFO: This will create a new \"merge commit\" in the process</p> <p>Keep feature branch up to date - combine the latest changes from main into feature branch</p> <p>Feature branch back into the main branch - Integrates all feature branch commits into main, with a merge commit created to tie histories together.</p>"},{"location":"git/concepts/merge_vs_rebase/#rebase","title":"REBASE","text":"<p>Pros:  - clean, straightforward commit history - Interactive rebase can squash commits if desired (not by default).</p> <p>Cons:  - Rewrites history   - it creates new commit hashes for all rebased commits.</p> <p>Keep feature branch up to date</p> <ul> <li>changes the base of feature branch to the latest commit on main</li> </ul> <p>Feature branch back into the main branch</p> <ul> <li>Move the feature branch changes onto the tip of main</li> <li>Then perform a fast-forward merge</li> </ul>"},{"location":"git/concepts/merge_vs_rebase/#difference","title":"Difference","text":"Scenario Merge Rebase New commit hashes created No Yes History shape Branching with merge commits Linear, rewritten Adds an explicit merge commit connection Yes No Preserves original commits Yes No (rewrites as new ones) Commit history readability Can be cluttered Cleaner, linear Collaboration safety (shared branches) Safe (no history rewrite) Risky (needs force-push)"},{"location":"git/concepts/patchset/","title":"Patchset","text":"<p>A patchset is a review mechanism used in version control systems, particularly in code review tools like Gerrit. It represents a collection of changes or modifications made to the codebase that are grouped together for review and approval before being merged into the main codebase.</p> <p>Examples of patchsets:</p> <pre><code>flowchart TD\n    A[Initial Commit] --&gt; B[Patchset 1: Original Changes]\n    B --&gt; C{Code Review}\n    C --&gt;|Changes Requested| D[Patchset 2: Address Review Comments]\n    D --&gt; E{Code Review}\n    E --&gt;|Minor Issues| F[Patchset 3: Final Fixes]\n    F --&gt; G{Code Review}\n    G --&gt;|Approved| H[Merged to Main Branch]\n\n    subgraph PS1[\" \"]\n        B\n        I1[Added new feature]\n        I2[Updated tests]\n        I3[Modified documentation]\n    end\n\n    subgraph PS2[\" \"]\n        D\n        J1[Fixed logic bug]\n        J2[Improved error handling]\n        J3[Refactored code]\n    end\n\n    subgraph PS3[\" \"]\n        F\n        K1[Fixed typos]\n        K2[Updated variable names]\n        K3[Added missing comments]\n    end\n\n    style B fill:#4a90e2,color:#fff\n    style D fill:#f39c12,color:#fff\n    style F fill:#9b59b6,color:#fff\n    style H fill:#27ae60,color:#fff\n    style C fill:#e74c3c,color:#fff\n    style E fill:#e74c3c,color:#fff\n    style G fill:#27ae60,color:#fff</code></pre>"},{"location":"git/concepts/patchset/#patchset-workflow","title":"Patchset Workflow","text":"<ol> <li>Patchset 1: Developer submits initial changes</li> <li>Contains the original implementation</li> <li> <p>Sent for code review</p> </li> <li> <p>Patchset 2: Developer addresses review feedback</p> </li> <li>Fixes issues identified in review</li> <li>Improves code quality</li> <li> <p>Same change ID, new patchset version</p> </li> <li> <p>Patchset 3: Developer makes final adjustments</p> </li> <li>Addresses remaining minor issues</li> <li>Polishes the changes</li> <li>Ready for merge</li> </ol> <p>Each patchset is a revision of the same change, maintaining the same Change-ID but incrementing the patchset number.</p>"},{"location":"git/concepts/patchset/#commands-to-push-patchsets","title":"Commands to push Patchsets","text":"<p>For Patchset 1</p> <pre><code>git add &lt;files&gt;\ngit commit -m \"patchset 1 description\"\ngit push\n</code></pre> <p>For Patchset 2 and beyond</p> <pre><code>git commit --amend -m \"patchset 2 description\"\n# Or keep commit message from Patchset 1: git commit --amend --no-edit\ngit push\n</code></pre>"},{"location":"kubernetes/","title":"Kubernetes","text":"<p>This is a documentation site about Kubernetes, covering various topics.</p> <p>Use the left sidebar to navigate through different sections.</p>"},{"location":"kubernetes/#acknowledgment","title":"\ud83d\udcda Acknowledgment","text":"<ul> <li>This guide is based on lecture materials provided by Imran Teli, my technology instructor, and other online resources e.g.: kubernetes.io.</li> </ul>"},{"location":"kubernetes/cheatsheet/","title":"Kubernetes Cheat Sheet","text":"<ul> <li>Kubectl Context and Configuration</li> <li>Creating Objects</li> <li>Interacting With Nodes and Cluster</li> </ul>"},{"location":"kubernetes/cheatsheet/#useful-commands-to-automatically-create-yaml-configs","title":"Useful Commands to Automatically Create YAML Configs","text":""},{"location":"kubernetes/cheatsheet/#create-a-declarative-yaml-for-a-pod","title":"Create a Declarative YAML for a Pod","text":"<pre><code>kubectl run nginxpod --image=nginx --dry-run=client -o yaml &gt; ngpod.yaml\ncat ngpod.yaml\n</code></pre>"},{"location":"kubernetes/cheatsheet/#create-a-yaml-for-a-deployment","title":"Create a YAML for a Deployment","text":"<pre><code>kubectl create deployment ngdep --image=nginx --dry-run=client -o yaml &gt; ngdep.yaml\n</code></pre>"},{"location":"kubernetes/commands_arguments/","title":"Commands and Arguments","text":""},{"location":"kubernetes/commands_arguments/#cmd","title":"CMD","text":"<p>Command that will start the container process:</p> <pre><code>FROM ubuntu\nCMD echo \"Hello World\"\n</code></pre> <pre><code>FROM ubuntu\nCMD [\"/usr/bin/wc\",\"--help\"]\n</code></pre> <p>Similar to CMD but higher priority <pre><code>FROM ubuntu\nENTRYPOINT [\"executable\", \"param1\", \"param2\"]\n</code></pre></p> <p>If ENTRYPOINT and CMD are used together then the ENTRYPOINT will run first.</p> <p>Usually when used together the ENTRYPOINT would be the command and CMD the argument, Example:</p> <pre><code>FROM ubuntu\nENTRYPOINT[echo]\nCMD[\"hi\"]\n</code></pre>"},{"location":"kubernetes/commands_arguments/#kubernetes-example","title":"Kubernetes Example","text":"<pre><code>vim commands.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: command-demo\n  labels:\n    purpose: demonstrate-command\nspec:\n  containers:\n\n  - name: command-demo-container\n    image: debian\n    command: [\"printenv\"]\n    args: [\"HOSTNAME\", \"KUBERNETES_PORT\"]\n\n  - name: echo-demo\n    image: debian\n    env:\n      - name: MESSAGE\n        value: \"hello world\"\n    command: [\"/bin/echo\"]\n    args: [\"$(MESSAGE)\"]\n\n  restartPolicy: OnFailure\n</code></pre> <p>Note: You can only use one <code>command</code> and <code>args</code> per container. To try both examples, comment/uncomment the relevant lines or create two containers in the pod. 2 containers running is not recommended in production unless its side-container or container that will start another container.</p> <p>env: - name: MESSAGE   value: \"hello world\" command: [\"/bin/echo\"] args: [\"$(MESSAGE)\"]</p> <p>start pod</p> <pre><code>kubectl apply -f commands.yaml\nkubectl get pod\n\n# wait for status: Completed\n\nkubectl logs command-demo\n</code></pre> <p>Docs</p>"},{"location":"kubernetes/config_map/","title":"Config Map","text":"<p>https://kubernetes.io/docs/concepts/configuration/configmap/#using-configmaps-as-environment-variables</p>"},{"location":"kubernetes/config_map/#environment-variables","title":"Environment Variables","text":"<p>Pods are disposable and do not retain persistent changes.</p> <p>We can inject environment variables into a Pod at runtime.</p>"},{"location":"kubernetes/config_map/#example","title":"Example","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: env-configmap\nspec:\n  containers:\n  - name: envars-test-container\n    image: nginx\n    env:\n    - name: CONFIGMAP_USERNAME\n      valueFrom:\n        configMapKeyRef:\n          name: myconfigmap\n          key: username\n</code></pre>"},{"location":"kubernetes/config_map/#create-config-maps-imperative","title":"Create Config Maps - Imperative","text":"<p>https://kubernetes.io/docs/reference/kubectl/generated/kubectl_create/kubectl_create_configmap/</p> <p><pre><code>kubectl create configmap db-config --from-literal=MYSQL_DATABASE=accounts \\\n --from-literal=MYSQL_ROOT_PASSWORD=somecomplexpass\n</code></pre> <pre><code>configmap/db-config created\n</code></pre></p> <pre><code>kubectl get cm\n</code></pre> <pre><code>kubectl get cm db-config -o yaml\n</code></pre> <pre><code>kubectl describe cm db-config\n</code></pre>"},{"location":"kubernetes/config_map/#create-config-maps-declarative","title":"Create Config Maps - Declarative","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: db-config\ndata:\n  MYSQL_ROOT_PASSWORD: somecomplexpass\n  MYSQL_DATABASE: accounts\n</code></pre> <p>Apply changes: <pre><code>kubectl create -f db-cm.yml\n</code></pre></p>"},{"location":"kubernetes/config_map/#pod-reading-config-maps","title":"POD Reading Config Maps","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: db-pod\n  labels:\n    app: db\n    project: infinity\nspec:\n  containers:\n    - name: mysql-container\n      image: mysql:5.7\n      envFrom:\n        - configMapRef:\n            name: db-config\n      ports:\n        - name: db-port\n          containerPort: 3306\n</code></pre>"},{"location":"kubernetes/config_map/#select-a-key-from-a-config-map","title":"Select a Key from a Config Map","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: db-pod\n  labels:\n    app: db\n    project: infinity\nspec:\n  containers:\n    - name: mysql-container\n      image: mysql:5.7\n      env:\n        - name: DB_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: DB_HOST\n      ports:\n        - name: db-port\n          containerPort: 3306\n</code></pre>"},{"location":"kubernetes/config_map/#hands-on","title":"Hands On","text":"<pre><code>vim samplecm.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: game-demo\ndata:\n  # property-like keys; each key maps to a simple value\n  player_initial_lives: \"3\"\n  ui_properties_file_name: \"user-interface.properties\"\n\n  # file-like keys\n  game.properties: |\n    enemy.types=aliens,monsters\n    player.maximum-lives=5    \n  user-interface.properties: |\n    color.good=purple\n    color.bad=yellow\n    allow.textmode=true\n</code></pre> <pre><code>kubectl apply -f samplecm.yaml\n</code></pre> <pre><code>kubectl get cm\n</code></pre> <pre><code>kubectl get cm game-demo -o yaml\n</code></pre> <p>There are four different ways that you can use a ConfigMap to configure a container inside a Pod:</p> <ol> <li>Inside a container command and args</li> <li>Environment variables for a container</li> <li>Add a file in read-only volume, for the application to read</li> <li>Write code to run inside the Pod that uses the Kubernetes API to read a ConfigMap</li> </ol> <pre><code>vim readcmpod.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: configmap-demo-pod\nspec:\n  containers:\n    - name: demo\n      image: alpine\n      command: [\"sleep\", \"3600\"]\n      env:\n        # Define the environment variable\n        - name: PLAYER_INITIAL_LIVES # Notice that the case is different here\n                                     # from the key name in the ConfigMap.\n          valueFrom:\n            configMapKeyRef:\n              name: game-demo           # The ConfigMap this value comes from.\n              key: player_initial_lives # The key to fetch.\n        - name: UI_PROPERTIES_FILE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: game-demo\n              key: ui_properties_file_name\n      volumeMounts:\n      - name: config\n        mountPath: \"/config\"\n        readOnly: true\n  volumes:\n  # You set volumes at the Pod level, then mount them into containers inside that Pod\n  - name: config\n    configMap:\n      # Provide the name of the ConfigMap you want to mount.\n      name: game-demo\n      # An array of keys from the ConfigMap to create as files\n      items:\n      - key: \"game.properties\"\n        path: \"game.properties\"\n      - key: \"user-interface.properties\"\n        path: \"user-interface.properties\"\n</code></pre> <pre><code>kubectl get cm\n</code></pre> <pre><code>kubectl apply -f readcmpod.yaml\n</code></pre> <pre><code>kubectl get pod\n</code></pre> <pre><code>kubectl exec --stdin --tty configmap-demo-pod -- /bin/sh\n</code></pre> <p>Validate <pre><code>ls /config/\n</code></pre></p> <pre><code>cat /config/game.properties\n</code></pre> <pre><code>cat /config/user-interface.properties\n</code></pre> <pre><code>echo $PLAYER_INITIAL_LIVES\n</code></pre> <pre><code>echo $UI_PROPERTIES_FILE_NAME\n</code></pre>"},{"location":"kubernetes/daemonset/","title":"DaemonSet","text":"<p>DaemonSet</p> <p>A DaemonSet ensures that each node runs one copy of a specific Pod.</p> <p>Commonly used for log collection, monitoring agents, or storage drivers.</p> <p>DaemonSet pods can expose metrics that tools like Prometheus scrape and Grafana visualizes.</p> <p>Example DaemonSet YAML</p>"},{"location":"kubernetes/daemonset/#hands-on-create-a-daemonset","title":"Hands On: Create a DaemonSet","text":"<p>Copy yaml content from example above.</p> <pre><code>vim sampleds.yaml # Paste the yaml content here\n</code></pre> <pre><code>kubectl apply -f samleds.yaml\n# ................ created\n</code></pre> <p>Validate</p> <pre><code>kubectl get ds -A\n</code></pre> <pre><code># Output:\nNAMESPACE      NAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR\nkube-system    ebs-csi-node                   3         3        3         3             3       kubernetes.io/os=linux\nkube-system    fluentd-elasticsearch          3         3        3         3             3       &lt;none&gt;\nkube-system    kops-controller                1         1        1         1             1       kops.k8s.io/kops-controller-pki=,node-role.kubernetes.io/master=\n</code></pre> <pre><code>kubectl get pod -n kube-system\n</code></pre> <pre><code># Output:\nNAME                                                                READY   STATUS    RESTARTS    AGE\ncoredns-7884856795-knjlw                                            1/1     Running   0           48m\ncoredns-7884856795-sclvx                                            1/1     Running   0           48m\ncoredns-autoscaler-57dd867df6-vqwjp                                 1/1     Running   0           48m\ndns-controller-5869b5468f-g44fs                                     1/1     Running   0           48m\nebs-csi-controller-58c77d6dbc-srbqn                                 6/6     Running   0           48m\nebs-csi-node-6884r                                                  3/3     Running   0           48m\nebs-csi-node-bnsf6                                                  3/3     Running   1 (47m ago) 48m\nebs-csi-node-z59c6                                                  3/3     Running   1 (47m ago) 48m\netcd-manager-events-ip-172-20-37-60.us-east-2.compute.internal      1/1     Running   0           48m\netcd-manager-main-ip-172-20-37-60.us-east-2.compute.internal        1/1     Running   0           48m\n**fluentd-elasticsearch-2mdqt**                                     1/1     Running   0           41s\n**fluentd-elasticsearch-fbwb4**                                     1/1     Running   0           41s\n**fluentd-elasticsearch-jsnh8**                                     1/1     Running   0           41s\nkops-controller-w5rsl                                               1/1     Running   0           48m\nkube-apiserver-ip-172-20-37-60.us-east-2.compute.internal           2/2     Running   0           49m\nkube-controller-manager-ip-172-20-37-60.us-east-2.compute.internal  1/1     Running   0           49m\nkube-proxy-ip-172-20-37-60.us-east-2.compute.internal               1/1     Running   0           48m\nkube-proxy-ip-172-20-48-52.us-east-2.compute.internal               1/1     Running   0           47m\nkube-proxy-ip-172-20-77-191.us-east-2.compute.internal              1/1     Running   0           46m\nkube-scheduler-ip-172-20-37-60.us-east-2.compute.internal           1/1     Running   0           48m\n</code></pre>"},{"location":"kubernetes/deployment/","title":"Deployment","text":"<p>Upgrade your apps (pod images).</p> <p>Rollbacks if something goes wrong.</p> <p>A deployment controller provides declarative updates for Pods and ReplicaSets (Deployment creates ReplicaSet to manage number of PODS).</p> <p>You describe a desired state in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate.</p>"},{"location":"kubernetes/deployment/#update-image-tag","title":"Update Image Tag","text":"<p>example tags:</p> <ul> <li>nginx:1.0</li> <li>nginx:2.0</li> <li>nginx:3.0</li> </ul> <p>With deployments you can upgrade from old image tag e.g: <code>nginx:1.0</code> to <code>nginx:3.0</code>.</p> <p>If something goes wrong then the image will roll back to old version <code>nginx:1.0</code>.</p>"},{"location":"kubernetes/deployment/#hands-on","title":"Hands On","text":"<p><code>vim nginx-deployment.yaml</code> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n</code></pre></p> <p>Run the deployment <pre><code>kubectl apply -y nginx-deployment.yaml\n\nkubectl get deployments\n\n# example output:\n# NAME               READY   UP-TO-DATE   AVAILABLE   AGE\n# nginx-deployment   0/3     0            0           1s\n\n\nkubectl get deploy\n\nkubectl get rs\n\nkubectl get pod\n\nkubectl describe pod &lt;pod-name&gt;\n</code></pre></p>"},{"location":"kubernetes/deployment/#updating-a-deployment","title":"Updating a deployment","text":"<pre><code>kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1\n</code></pre> <p>check if new version was changed: <pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre></p> <p>search for <code>image:</code></p> <p>confirm that the version is set to <code>1.16.1</code></p>"},{"location":"kubernetes/deployment/#rollback-to-a-previous-revision","title":"Rollback to a Previous Revision","text":"<p>check if there is old revision</p> <pre><code>kubectl get rs\n</code></pre> <p>output: <pre><code>NAME                       DESIRED\nnginx-deployment-11111111  0 &lt;-- previous revision\nnginx-deployment-11111111  3\n</code></pre></p> <pre><code>kubectl rollout undo deployment/nginx-deployment\n</code></pre> <pre><code>kubectl get rs\n</code></pre> <p>output: <pre><code>NAME                       DESIRED\nnginx-deployment-11111111  0 \nnginx-deployment-11111111  3 &lt;-- previous revision\n</code></pre></p> <pre><code>kubectl get pod\nkubectl describe pod &lt;pod-name&gt; | grep Image\n</code></pre> <p>check revision rollout history <pre><code>kubectl rollout history deployment/nginx-deployment\n</code></pre></p> <p>rollout to revision number <pre><code>kubectl rollout undo deployment/nginx-deployment --to-revision=2\n</code></pre></p>"},{"location":"kubernetes/deployment/#delete-deployment","title":"Delete Deployment","text":"<pre><code>kubectl get deploy\n</code></pre> <pre><code>kubectl delete deploy &lt;name&gt;\n</code></pre>"},{"location":"kubernetes/deployment/#remember","title":"Remember","text":"<p>imperetive is for learning, testing purpose.</p> <p>But in production do it through definition files.</p>"},{"location":"kubernetes/deployment/#link-to-docs","title":"Link to DOCS","text":"<p>Link to Kubernetes deployment - official docs</p>"},{"location":"kubernetes/different_logging/","title":"Logging","text":""},{"location":"kubernetes/different_logging/#test-environments","title":"Test Environments","text":"<p>Before deploying to production, always verify the application in different environments:</p> <ol> <li>Test in local environment</li> <li>Test in test/dev environment</li> <li>Finally in production environment</li> </ol>"},{"location":"kubernetes/different_logging/#debugging-your-kubernetes-cluster","title":"Debugging Your Kubernetes Cluster","text":"<p>Mistakes and bugs can happen \u2014 be prepared to investigate and resolve them efficiently.</p>"},{"location":"kubernetes/different_logging/#troubleshooting-pods","title":"Troubleshooting Pods","text":"<p>List pods and their status:</p> <pre><code>kubectl get pod\nkubectl get pod -o wide\n</code></pre>"},{"location":"kubernetes/different_logging/#viewing-pod-logs-and-events","title":"Viewing Pod Logs and Events","text":""},{"location":"kubernetes/different_logging/#level-1-view-full-pod-definition","title":"Level 1: View Full Pod Definition","text":"<pre><code>kubectl get pod &lt;pod-name&gt; -o yaml\n</code></pre>"},{"location":"kubernetes/different_logging/#level-2-describe-the-pod-look-at-events-for-errors","title":"Level 2: Describe the pod (Look at Events for errors)","text":"<pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre>"},{"location":"kubernetes/different_logging/#level-3-view-pod-logs-commandsprocess-outputs","title":"Level 3: View Pod logs (commands/process outputs)","text":"<pre><code>kubectl logs &lt;pod-name&gt;\n</code></pre>"},{"location":"kubernetes/different_logging/#scenario-example-debugging-a-broken-image","title":"Scenario Example: Debugging a Broken Image","text":"<p>Suppose you find the following error in the logs:</p> <pre><code># Logs:\nkubelet     Pulling image \"nginax:1.15.0\"\nkubelet     Failed to pull image \"nginax:1.15.0\"\n</code></pre> <p>The issue is a misspelled image name (nginax instead of nginx). To fix it:</p>"},{"location":"kubernetes/different_logging/#step-1-delete-the-pod","title":"Step 1: Delete the Pod","text":"<pre><code>kubectl delete pod nginx12\n</code></pre>"},{"location":"kubernetes/different_logging/#step-2-edit-the-pod","title":"Step 2: Edit the Pod","text":"<pre><code># pod2.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx12\nspec:\n  containers:\n  - name: \n    image: nginx:1.15.0 # &lt;-- Corrected image name\n    ports:\n    - containerPort: 80\n</code></pre>"},{"location":"kubernetes/different_logging/#step-3-apply-the-updated-pod","title":"Step 3: Apply the Updated Pod","text":"<pre><code>kubectl apply -f pod2.yaml\n# output example: pod/nginx12 created\n</code></pre>"},{"location":"kubernetes/different_logging/#step-4-verify-the-pod-is-running","title":"Step 4: Verify the Pod is Running","text":"<pre><code>kubect get pod\n</code></pre> <p>You should see: <pre><code>nginx12 1/1 Running\n</code></pre></p>"},{"location":"kubernetes/eks_introduction/","title":"Amazon Elastic Kubernetes Service","text":"<p>There are ways to create and handle Kubernetes by using Kops, Kubeadm, etc.</p> <p>Problems with default k8s setup:</p> <ul> <li>Its complex to manage a Kubernetes cluster.</li> <li>This requires system administration.</li> </ul> <p>Solutions with EKS:</p> <ul> <li>Amazon EKS is an self-managed service.</li> <li>You just have to pass simple information about your cluster details.</li> <li>You can change capacity and scale it whenever you want.</li> <li>Automatically deploys Kubernetes control plane</li> </ul>"},{"location":"kubernetes/eks_introduction/#automation-with-eks","title":"Automation with EKS","text":"<p>Use published Terraform modules</p> <ul> <li>AWS VPC</li> <li>AWS EKS</li> </ul>"},{"location":"kubernetes/eks_introduction/#demo","title":"Demo","text":"<p>Clone a predefined terraform code for EKS</p> <pre><code>git clone https://github.com/hkhcoder/vprofile-project.git\n</code></pre> <pre><code>git switch terraform-eks\n</code></pre>"},{"location":"kubernetes/eks_introduction/#setup-and-run-terraform","title":"Setup and run Terraform","text":"<ol> <li> <p>Install Terraform</p> </li> <li> <p>Install Kubectl</p> </li> <li> <p>IAM</p> </li> <li>Create IAM user</li> <li>Premission: <code>administraitor access</code></li> <li>Security credentials: Create and Download the <code>access key</code></li> <li> <p>Type <code>aws configure</code> in terminal and paste the credentials</p> </li> <li> <p>Go to the repository you recently cloned(repository <code>vprofile-project</code>, branch <code>terraform-eks</code>)</p> </li> <li> <p>Run the following commands to create the EKS Cluster</p> </li> </ol> <pre><code>ls\n# eks-cluster.tf  main.tf  outputs.tf  terraform.tf  variables.tf  vpc.tf\n\nterraform init\n\nterraform plan\n\nterraform apply\n</code></pre> <p>We should have 3 public and 3 private VPC's.</p> <p>In total we should have 6 subnets.</p> <p>Create or update a kubeconfig file for your cluster. Replace region-code with the AWS Region that your cluster is in and replace my-cluster with the name of your cluster. <pre><code>aws eks update-kubeconfig --region region-code --name my-cluster\n</code></pre></p> <p>Test kubeconfig <pre><code>kubectl get nodes\n</code></pre></p>"},{"location":"kubernetes/helm_hands_on/","title":"Helm Hands On","text":""},{"location":"kubernetes/helm_hands_on/#wordpress-setup","title":"WordPress Setup","text":""},{"location":"kubernetes/helm_hands_on/#workflow-for-helm","title":"Workflow for Helm","text":"<ol> <li> <p>Create Kubernetes Definition Files </p> <ul> <li>Set up WordPress using Kubernetes objects:<ul> <li>Deployment</li> <li>Service</li> <li>Persistent Volume Claim (PVC)</li> <li>Ingress</li> <li>Secret</li> </ul> </li> </ul> </li> <li> <p>Convert to Helm </p> <ul> <li>Use AI tools to develop Helm charts efficiently.<ul> <li>Amazon Q (Generative AI)</li> </ul> </li> </ul> </li> <li> <p>Deploy and Manage </p> <ul> <li>Deploy the chart: <code>helm install &lt;release-name&gt; &lt;chart-path&gt;</code></li> <li>Upgrade the chart: <code>helm upgrade &lt;release-name&gt; &lt;chart-name&gt; -f values.yaml</code></li> <li>Uninstall the chart: <code>helm uninstall &lt;release-name&gt;</code></li> <li>List releases: <code>helm list</code></li> </ul> </li> <li> <p>More Options in Helm </p> <ul> <li>Use Code Assistant to implement Dev Best practices.</li> </ul> </li> </ol>"},{"location":"kubernetes/helm_hands_on/#demo","title":"Demo","text":"<p>Have kubectl on your PC</p> <p>Have a kubernetes cluster installed on your AWS EC 2 instance</p> <pre><code>kubectl get nodes\n# NAME        STATUS         ROLE\n# i-dg3       Ready          node\n# i-gha       Ready          control-plane\n# i-7df       Ready          node\n</code></pre> <p>setup ingress controller:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.2/deploy/static/provider/aws/deploy.yaml\n</code></pre> <p>Display and copy entire cubeconfig file:</p> <pre><code>cat ~/.kube/config\n</code></pre> <p>create a kubeconfig file on your PC</p> <pre><code>mkdir ~/.kube\nvim ~/.kube/config # Paste the entire cubeconfig contet here.\n</code></pre>"},{"location":"kubernetes/helm_hands_on/#create-a-worpress-app-mysql-db-in-helm","title":"Create a Worpress App &amp; MySQL DB in Helm","text":"<p>How?</p> <ol> <li> <p>Open a browser, find the definition files, copy paste and make changes.</p> <ol> <li>In google, search for <code>wordpress kubernetes definitions</code></li> <li>You should find a page like <code>Deploying WordPress and MySQL with Persistent Volumes</code></li> <li>Teke this resources and create files, change settings and run it</li> </ol> </li> <li> <p>Ask AmazonQ AI to create it for us.</p> <ol> <li>Install and Setup AmazonQ from VSC Extensions</li> <li>Use the prompt to create the resources/files</li> <li>AmazonQ is currently the most accurate AI for Kubernetes</li> </ol> </li> </ol>"},{"location":"kubernetes/helm_hands_on/#build-with-amazonq","title":"Build with AmazonQ","text":"<p>Make sure we have Nginx ingress controller: <pre><code>kubectl get ns  # NameSpaces\n# NAME              STATUS   AGE\n# default           Active   46m\n# ingress-nginx     Active   21m   &lt;---\n# kube-node-lease   Active   46m\n# kube-public       Active   46m\n# kube-system       Active   46m\n</code></pre></p> <p>Check storage class:</p> <p><pre><code>kubectl get sc # StorageClass\n</code></pre> <pre><code># OUTPUT\nNAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\ndefault                kubernetes.io/aws-ebs   Delete          Immediate              false                  47m\ngp2                    kubernetes.io/aws-ebs   Delete          Immediate              false                  47m\nkops-csi-1-21 (default) ebs.csi.aws.com        Delete          WaitForFirstConsumer   true                   47m\nkops-ssd-1-17          kubernetes.io/aws-ebs   Delete          WaitForFirstConsumer   true                   47m\n</code></pre></p> <p>As you see we have EBS type volume that was created by 'Kops' for AWS.</p> <p>So we need to mention this EBS volume type as 'Storage Class'.</p> <p>Make sure to have all the information before writing the prompt.</p>"},{"location":"kubernetes/helm_hands_on/#amazonq-prompt-demo","title":"AmazonQ Prompt Demo","text":"<p>Open a new foulder with VSC.</p> <p>Prompt AmazonQ this text and wait for AI to build the files.</p> <pre><code>Wordpress setup kubernetes definitions files. Separate files for wordpress app, mysql (needs to be version 8.0), app service, db service, PVC, secret and ingress. PVC should use storage class default, secret file should contain all the db users and db passwords for mysql and wordpress both. Ingress will be nginx with hostname wordpress.alexanderlindholm.net.\n</code></pre> <p>7 files should be created: <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\n1 directory, 7 files\n</code></pre></p> <p>Install Helm</p> <p>Create Helm chart</p> <pre><code>helm create wp-chart\n</code></pre> <p>Additional example/template files should be created in wp-chart directory:</p> <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\u2514\u2500\u2500 wp-chart\n    \u251c\u2500\u2500 charts\n    \u251c\u2500\u2500 Chart.yaml\n    \u251c\u2500\u2500 templates\n    \u2502   \u251c\u2500\u2500 deployment.yaml\n    \u2502   \u251c\u2500\u2500 _helpers.tpl\n    \u2502   \u251c\u2500\u2500 hpa.yaml\n    \u2502   \u251c\u2500\u2500 ingress.yaml\n    \u2502   \u251c\u2500\u2500 NOTES.txt\n    \u2502   \u251c\u2500\u2500 serviceaccount.yaml\n    \u2502   \u251c\u2500\u2500 service.yaml\n    \u2502   \u2514\u2500\u2500 tests\n    \u2502       \u2514\u2500\u2500 test-connection.yaml\n    \u2514\u2500\u2500 values.yaml\n\n5 directories, 17 files\n</code></pre> <p>Delete all <code>.yaml</code> files in templates directory:</p> <pre><code>rm wp-chart/templates/*.yaml\n</code></pre> <p>Delete the wp-chart directory:</p> <pre><code>rm -rf wp-chart/templates/tests/\n</code></pre> <p>Clear all text in <code>values.yaml</code>:</p> <pre><code>echo \"\" &gt; wp-chart/values.yaml\n</code></pre> <p>File structure should now look like this: <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\u2514\u2500\u2500 wp-chart\n    \u251c\u2500\u2500 charts\n    \u251c\u2500\u2500 Chart.yaml\n    \u251c\u2500\u2500 templates\n    \u2502   \u251c\u2500\u2500 _helpers.tpl\n    \u2502   \u2514\u2500\u2500 NOTES.txt\n    \u2514\u2500\u2500 values.yaml\n\n4 directories, 12 files\n</code></pre></p> <p>Copy ai created kubernetes definition files to templates directory:</p> <pre><code>cp ./* ./wp-chart/templates/\n</code></pre> <p>File Structure should now look like: <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\u2514\u2500\u2500 wp-chart\n    \u251c\u2500\u2500 charts\n    \u251c\u2500\u2500 Chart.yaml\n    \u251c\u2500\u2500 templates\n    \u2502   \u251c\u2500\u2500 _helpers.tpl\n    \u2502   \u251c\u2500\u2500 mysql-deployment.yaml\n    \u2502   \u251c\u2500\u2500 mysql-pvc.yaml\n    \u2502   \u251c\u2500\u2500 mysql-service.yaml\n    \u2502   \u251c\u2500\u2500 NOTES.txt\n    \u2502   \u251c\u2500\u2500 wordpress-deployment.yaml\n    \u2502   \u251c\u2500\u2500 wordpress-ingress.yaml\n    \u2502   \u251c\u2500\u2500 wordpress-pvc.yaml\n    \u2502   \u251c\u2500\u2500 wordpress-secret.yaml\n    \u2502   \u2514\u2500\u2500 wordpress-service.yaml\n    \u2514\u2500\u2500 values.yaml\n\n4 directories, 20 files\n</code></pre></p> <p>in <code>mysql-deployment.yaml</code></p> <p>replace</p> <pre><code>metadata:\n  name: wordpress-mysql\n</code></pre> <p>to</p> <pre><code>metadata:\n  name: {{ include \"word-chart.fullname\" . }}-app\n</code></pre> <p>replace</p> <pre><code>image: mysql:8.0\n</code></pre> <p>to</p> <pre><code>image: {{ .Values.mysql.image.repository }}:{{ .Values.mysql.image.tag }}\n</code></pre> <p>Add values in <code>mysql-deployment.yaml</code></p> <pre><code>mysql:\n  image:\n    repository: mysql\n    tag: 8.0\n</code></pre> <p>Then to deploy the app run</p> <pre><code>helm install demo ./wp-chart\n</code></pre>"},{"location":"kubernetes/helm_introduction/","title":"Helm","text":""},{"location":"kubernetes/helm_introduction/#what-is-helm-package-manager","title":"What is Helm Package Manager?","text":"<p>Helm helps you manage your application as a single package on a Kubernetes cluster.</p> <p>To run an application, we often need to use multiple Kubernetes objects, such as:</p> <ul> <li>Deployments</li> <li>Services</li> <li>Ingress</li> <li>Backend Objects:<ul> <li>Volumes</li> <li>Secrets</li> <li>ConfigMaps</li> <li>DaemonSets</li> <li>StatefulSets</li> <li>etc.</li> </ul> </li> </ul> <p>Using Helm, we can convert these definition files into a single Helm chart.</p> <p>This means an application becomes a bundle of different objects packaged into a Helm chart, allowing us to deploy the application as a single suite.</p> <p>This means we deploy the application as a single suit.</p> <p>Helm provides commands to manage applications, such as:</p> <ul> <li><code>helm install &lt;app&gt;</code></li> <li><code>helm uninstall &lt;app&gt;</code></li> <li><code>helm upgrade &lt;app&gt;</code> (change settings or versions)</li> <li>etc.</li> </ul>"},{"location":"kubernetes/helm_introduction/#key-components-of-helm-in-kubernetes","title":"Key Components of Helm in Kubernetes","text":"<p>. Charts     - A package of pre-configured Kubernetes resources for applications. 2. Repositories     - Storage locations for managing and sharing Helm charts. 3. Releases     - Instances of charts running in a Kubernetes cluster. 4. Values     - Configuration settings that customize charts during deployment.</p>"},{"location":"kubernetes/helm_introduction/#chart-structure","title":"Chart Structure","text":"<pre><code>wordpress-chart/\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 ingress.yaml\n\u2502   \u251c\u2500\u2500 mysql-deployment.yaml\n\u2502   \u251c\u2500\u2500 mysql-service.yaml\n\u2502   \u251c\u2500\u2500 NOTES.txt\n\u2502   \u251c\u2500\u2500 persistent-volume-claims.yaml\n\u2502   \u251c\u2500\u2500 secret.yaml\n\u2502   \u251c\u2500\u2500 wordpress-deployment.yaml\n\u2502   \u251c\u2500\u2500 wordpress-service.yaml\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 values.yaml\n</code></pre> <ol> <li> <p>Create a Chart </p> <ul> <li>Use the command: <code>helm create myapp</code></li> </ul> </li> <li> <p>Content of the Chart </p> <ul> <li>Create a <code>templates</code> folder and add <code>values.yaml</code> files.</li> </ul> </li> <li> <p>Deploy and Manage </p> <ul> <li>Deploy the chart: <code>helm install &lt;release-name&gt; &lt;chart-path&gt;</code></li> <li>Upgrade the chart: <code>helm upgrade &lt;release-name&gt; &lt;chart-name&gt; -f values.yaml</code></li> <li>Uninstall the chart: <code>helm uninstall &lt;release-name&gt;</code></li> <li>List releases: <code>helm list</code></li> </ul> </li> <li> <p>Helm Repositories </p> <ul> <li>Add a repository: <code>helm repo add bitnami https://charts.bitnami.com/bitnami</code></li> <li>Update repositories: <code>helm repo update</code></li> <li>Install a chart from a repository: <code>helm install my-nginx bitnami/nginx</code></li> </ul> </li> </ol>"},{"location":"kubernetes/helm_with_ai/","title":"Helm with AI","text":"<p>Prompt AmazonQ this text and wait for AI to build the files.</p> <pre><code>Wordpress setup kubernetes definitions files. Separate files for wordpress app, mysql (needs to be version 8.0), app service, db service, PVC, secret and ingress. PVC should use storage class default, secret file should contain all the db users and db passwords for mysql and wordpress both. Ingress will be nginx with hostname wordpress.alexanderlindholm.net.\n</code></pre> <p>7 files should be created: <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\n1 directory, 7 files\n</code></pre></p> <p>Use AmazonQ to read definition files and create the chart for us.</p> <p>Prompt AmazonQ this text and wait for AI to built the chart.</p> <pre><code>Create helm charts from these kubernetes definitions file. Use release name in metadata. Replace other hardcoded values into variables and add those variables in values.yaml file.\n</code></pre> <p>Check the chart to make sure everything is correct.</p> <p>Lint the chart</p> <pre><code>helm lint wordpress-chart\n</code></pre> <pre><code>helm template wordpress-chart\n</code></pre> <p>if everything looks good launch Kubernetes Chart</p> <pre><code>helm install wp wordpress-chart -n wp-ns --create-namespace\n</code></pre> <p>Get namespace status</p> <pre><code>helm list -n wp-ns\n</code></pre> <p>Get all resources in <code>wp-ns</code> namespace</p> <pre><code>kubectl get all -n wp-ns\n</code></pre> <p>Check ingress status</p> <pre><code>kubectl get ingress -n wp-ns\n</code></pre> <p>Describe ingress</p> <pre><code>kubectl describe ingress -n wp-ns\n</code></pre>"},{"location":"kubernetes/helm_with_ai/#version","title":"Version","text":"<p>If there are new changes to the chart then the version needs to be changed:</p> <pre><code>vim Chart.yaml\n</code></pre> <pre><code>apiVersion: v2\nname: wordpress\ndescription: A Helm chart for WordPress with MySQL\ntype: application\nversion: 0.1.1 # &lt;-- Change this version\nappVersion: \"1.0.0\"\n</code></pre> <p>Upgrade the Kubernetes to use latest changes</p> <pre><code>helm upgrade wp wordpress-chart -n wp-ns\n</code></pre> <p>Get namespace status</p> <pre><code>helm list -n wp-ns\n</code></pre> <p>Get all resources in <code>wp-ns</code> namespace</p> <pre><code>kubectl get all -n wp-ns\n</code></pre>"},{"location":"kubernetes/helm_with_ai/#ask-ai-to-improve-the-code","title":"Ask AI to Improve the Code","text":"<p>For Example prompt AI this:</p> <pre><code>Improve helm charts as per developmental best practices.\n</code></pre>"},{"location":"kubernetes/history/","title":"History","text":""},{"location":"kubernetes/history/#google-containers-2014","title":"Google + Containers (2014)","text":"<p>At Google, everything from Search to Gmail runs inside Linux containers. By 2014, Google was launching over 2 billion container instances per week across its global data centers. The power of containers allowed Google to deliver highly reliable and efficiently scalable services.</p> <p>That same year, Google took a major step forward \u2014 making its container orchestration expertise available to the world.</p>"},{"location":"kubernetes/history/#kubernetes-history","title":"\ud83d\udcdc Kubernetes History","text":""},{"location":"kubernetes/history/#2014-the-birth-of-kubernetes","title":"\ud83d\udee0\ufe0f 2014 \u2013 The Birth of Kubernetes","text":"<p>Kubernetes was created by Google as an open-source version of its internal container orchestration system, Borg. - Mid-2014: Google announces Kubernetes to the public.</p>"},{"location":"kubernetes/history/#2015-official-launch","title":"\ud83d\ude80 2015 \u2013 Official Launch","text":"<ul> <li>July 21, 2015: Kubernetes v1.0 is released.  </li> <li>Google partners with the Linux Foundation to form the Cloud Native Computing Foundation (CNCF) to manage the project.</li> </ul>"},{"location":"kubernetes/history/#2016-kubernetes-goes-mainstream","title":"\ud83c\udf0d 2016 \u2013 Kubernetes Goes Mainstream","text":"<ul> <li>Tools like kops, Minikube, and kubeadm emerge to simplify Kubernetes adoption.  </li> <li>September 29, 2016: The Pok\u00e9mon GO case study is published, highlighting Kubernetes at scale in production.</li> </ul>"},{"location":"kubernetes/history/#2017-enterprise-adoption-accelerates","title":"\ud83c\udfe2 2017 \u2013 Enterprise Adoption Accelerates","text":"<ul> <li>Google and IBM announce Istio, a service mesh for Kubernetes.  </li> <li>GitHub migrates infrastructure to Kubernetes.  </li> <li>Oracle joins the CNCF as a major cloud provider.</li> </ul>"},{"location":"kubernetes/ingress/","title":"Ingress","text":""},{"location":"kubernetes/ingress/#what-is-ingress","title":"What is Ingress ?","text":"<p>Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster.</p> <pre><code>graph LR\n    client[Client] --&gt; lb[Ingress-managed Load Balancer]\n    lb --&gt; ingress[Ingress]\n    ingress --&gt; service[Service]\n    service --&gt; pod1[Pod]\n    service --&gt; pod2[Pod]</code></pre>"},{"location":"kubernetes/ingress/#prerequisites","title":"Prerequisites","text":"<p>You must have an Ingress controller to satisfy an Ingress. Only creating an Ingress resource has no effect.</p> <p>Ingress Controllers List</p> <ul> <li>AKS Application Gateway Ingress Controller</li> <li>Apache APISIX ingress controller</li> <li>Avi Kubernetes Operator</li> <li>NGINX Ingress Controller for Kubernetes</li> <li>And many many more</li> </ul>"},{"location":"kubernetes/ingress/#hands-on-install-nginx-ingress","title":"Hands On: Install Nginx Ingress","text":"<pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.3/deploy/static/provider/aws/deploy.yaml\n</code></pre> <pre><code>kubectl get ns\n# ingress-nginx    Active    12s\n</code></pre> <pre><code>kubectl get all -n ingress-nginx\n</code></pre> <pre><code>NAME                                           READY   STATUS      RESTARTS   AGE\npod/ingress-nginx-admission-create-12345       0/1     Completed   0          23s\npod/ingress-nginx-admission-patch-12345        0/1     Completed   1          23s\npod/ingress-nginx-controller-69fbbf9f9c-h67pr  0/1     Running     0          23s\nNAME                                        TYPE           CLUSTER-IP       EXTERNAL-IP                                                      PORT(S)                       AGE\nservice/ingress-nginx-controller            LoadBalancer   100.68.173.127   a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com   80:32718/TCP, 443:32372/TCP   23s\nservice/ingress-nginx-controller-admission  ClusterIP      100.66.154.8     &lt;none&gt;                                                           443/TCP                       23s\n\nNAME                                        READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/ingress-nginx-controller    1/1     1            1           23s\n\nNAME                                                  DESIRED   CURRENT   READY   AGE\nreplicaset.apps/ingress-nginx-controller-69fbfbf9f9c  1         1         1    23s\n\nNAME                                           COMPLETIONS   DURATION   AGE\njob.batch/ingress-nginx-admission-create       1/1           3s         23s\njob.batch/ingress-nginx-admission-patch        1/1           4s         23s\n</code></pre> <p>In this example the credentials are:</p> <ul> <li>External DNS (Load Balancer): <ul> <li><code>a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com</code></li> </ul> </li> <li>Internal IP (Load Balancer): <code>100.68.173.127</code></li> <li>Internal IP (Cluster IP): <code>100.66.154.8</code></li> <li>Ingress routing (following your defined rules): <ul> <li><code>pod/ingress-nginx-controller-69fbbf9f9c-h67pr</code></li> </ul> </li> <li>Deployment: <code>deployment.apps/ingress-nginx-controller</code></li> <li>Replica set: <code>replicaset.apps/ingress-nginx-controller-69fbfbf9f9c</code></li> <li>Jobs:<ul> <li><code>job.batch/ingress-nginx-admission-create</code></li> <li><code>job.batch/ingress-nginx-admission-patch</code></li> </ul> </li> </ul> <p>This commands will create a loadbalancer in ROUTE 53 (AWS Cloud)</p> <p><pre><code>vim vprodep.yaml\n</code></pre> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  selector:\n    matchLabels:\n      run: my-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        run: my-app\n    spec:\n      containers:\n        - name: my-app\n          image: imranvisualpath/vproappfix\n          ports:\n            - containerPort: 8080\n</code></pre></p> <pre><code>vim vprosvc.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\nspec:\n  ports:\n    - port: 8080\n      protocol: TCP\n      targetPort: 8080\n  selector:\n    run: my-app\n  type: ClusterIP\n</code></pre> <pre><code>vim vproingress.yaml\n</code></pre> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: vpro-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: vprofile.alexanderlindholm.net\n      http:\n        paths:\n          - path: /login\n            pathType: Prefix\n            backend:\n              service:\n                name: my-app\n                port:\n                  number: 8080\n</code></pre> <p>replace <code>alexanderlindholm.net</code> with your DNS name</p> <pre><code>kubectl apply -f vprodep.yaml\n</code></pre> <pre><code>kubectl apply -f vprosvc.yaml\n</code></pre> <p>Create DNS CNAME before Applying <code>vproingress.yaml</code></p> <p>Visit your DNS provider, in my case it will be Namecheap</p> <ol> <li> <p>Go to DNS records section (Advanced DNS for Namecheap)</p> </li> <li> <p>Apply this credentials:</p> <ul> <li><code>TYPE: CNAME</code></li> <li><code>Name: vprofile</code></li> <li><code>Value: a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com</code></li> </ul> </li> </ol> <p>Check if my-app service is running:</p> <pre><code>kubectl get svc\n# my-app    ClusterIP    100.69.158.126    &lt;none&gt;    8080/TCP    120s\nkubectl describe svc my-app\n</code></pre> <p>Keep in mind that we are creating Ingress rule for this ClusterIP Service</p> <ol> <li>Client makes an HTTP request to: http://vprofile.alexanderlindholm.net/login (This DNS name resolves to the External IP/DNS of the Ingress LoadBalancer.)</li> <li>The request hits the Ingress Controller (NGINX) via the LoadBalancer, which processes the request using the rules defined in your Ingress resource. It then forwards the request to the my-app Service (which is of type ClusterIP).</li> <li>The ClusterIP Service (my-app) routes the traffic to one of the backing Pods (using label selectors), and the application running in the pod responds.</li> </ol> <pre><code>graph LR\n    client[\"Client (vprofile.alexanderlindholm.net/login)\"] --&gt; lb[\"LoadBalancer (Ingress Controller)\"]\n    lb --&gt; ingress[\"Ingress Resource: /login\"]\n    ingress --&gt; service[\"ClusterIP Service: my-app\"]\n    service --&gt; pod[\"Pod: my-app\"]</code></pre> <pre><code>kubectl apply -f vproingress.yaml\n</code></pre> <pre><code>kubectl get ingress\n# vpro-ingress   nginx   vprofile.alexanderlindholm.net   a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com\n</code></pre> <p>Visit page at: <code>a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com</code>.</p> <p>This URL would be different for you.</p> <pre><code>kubectl delete ingress vpro-ingress\n</code></pre>"},{"location":"kubernetes/ingress/#optional-change-app-path-to-fix-content-rendering-on-the-page","title":"Optional: Change app path to fix content rendering on the page","text":"<p>The page is not rendering because the routing is happening internally not in the app</p> <pre><code>vim vproingress.yaml\n# change /login to /\n</code></pre> <pre><code>kubectl apply -f vproingress.yaml &amp;&amp; kubectl get ingress --watch\n</code></pre>"},{"location":"kubernetes/ingress/#delete","title":"Delete","text":"<pre><code>kubectl get ns\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.3/deploy/static/provider/aws/deploy.yaml\n</code></pre>"},{"location":"kubernetes/introduction/","title":"Introduction to Kubernetes?","text":"<p>If the Docker Engine fails, all containers running on that engine will go down, making them inaccessible to users.</p> <p>This is where Kubernetes comes in \u2014 it manages multiple Docker Engines, known as Docker nodes, within a Kubernetes cluster. This setup ensures high availability and fault tolerance.</p> <p></p> <p>For example, if a container on the third node fails, Kubernetes automatically reschedules and migrates that container to a healthy node in the cluster.</p>"},{"location":"kubernetes/introduction/#container-orchestration","title":"\ud83e\udde0 Container Orchestration","text":"<p>Container orchestration refers to managing the deployment, scaling, networking, and availability of containers across a cluster of Docker/worker nodes.</p> <p>In Kubernetes, these nodes form a single pool of compute resources that is fault-tolerant and self-healing.</p>"},{"location":"kubernetes/introduction/#popular-container-orchestration-tools","title":"\ud83d\udd27 Popular Container Orchestration Tools","text":"<ul> <li>Docker Swarm</li> <li>Kubernetes \ud83c\udf1f</li> <li>Mesosphere Marathon</li> <li>AWS ECS &amp; EKS</li> <li>Azure Container Service</li> <li>Google Kubernetes Engine (GKE)</li> <li>CoreOS Fleet</li> <li>OpenShift</li> </ul>"},{"location":"kubernetes/introduction/#what-kubernetes-provides","title":"\ud83d\ude80 What Kubernetes Provides","text":"<ul> <li> <p>Service Discovery &amp; Load Balancing   Automatically exposes containers using DNS names or IPs and distributes traffic across them.</p> </li> <li> <p>Storage Orchestration   Mounts persistent storage from local disks or cloud providers like:</p> </li> <li>SAN (Storage Area Network)</li> <li>NAS (Network Attached Storage)</li> <li>AWS EBS volumes</li> <li> <p>Ceph</p> </li> <li> <p>Automated Rollouts &amp; Rollbacks   Gradually updates applications and rolls back if something goes wrong.</p> </li> <li> <p>Automatic Bin Packing   Places containers based on resource requirements and availability to maximize efficiency.</p> </li> <li> <p>Self-Healing   Automatically restarts failed containers, replaces unresponsive nodes, and kills misbehaving containers.</p> </li> <li> <p>Secrets &amp; Configuration Management   Manages sensitive data like passwords, SSH keys, and environment variables securely and separately from your application code.</p> </li> </ul>"},{"location":"kubernetes/introduction/#kubernetes-architecture","title":"\ud83d\udcca Kubernetes Architecture","text":"<p>link to model</p>"},{"location":"kubernetes/introduction/#components","title":"\ud83c\udf9b Components","text":""},{"location":"kubernetes/introduction/#master-component-kube-api-server","title":"\ud83e\udde0 Master Component: Kube API Server","text":"<ul> <li>Acts as the central communication hub for all Kubernetes components.</li> <li>Exposes the Kubernetes API, making it the frontend of the control plane.</li> <li>Handles all external and internal requests, including scheduling, deployments, and health checks.</li> <li>Admins interact with it via the <code>[kubectl](https://kubernetes.io/docs/reference/kubectl/)</code> CLI or through automated systems.</li> <li>A web-based dashboard can be integrated using the API.</li> <li>Enables integration with third-party tools and services like CI/CD, monitoring, and more.</li> </ul>"},{"location":"kubernetes/introduction/#master-etcd-server","title":"\ud83d\udcbe Master: etcd Server","text":"<ul> <li>Stores all cluster data for the Kubernetes control plane.</li> <li>A consistent and highly available key-value store that serves as Kubernetes' backing store.</li> <li>The Kube API Server retrieves and writes data to etcd.</li> <li>It should be backed up regularly to ensure disaster recovery.</li> <li>Maintains the current state of all objects in the cluster (nodes, pods, configs, etc.).</li> </ul>"},{"location":"kubernetes/introduction/#master-kube-scheduler","title":"\ud83d\udce6 Master: Kube Scheduler","text":"<ul> <li>Monitors newly created pods that do not yet have an assigned node.</li> <li>Selects the most suitable node for each pod to run on.</li> <li>Key factors considered during scheduling include:</li> <li>Resource requirements (CPU, memory)</li> <li>Hardware/software/policy constraints</li> <li>Affinity and anti-affinity rules</li> <li>Data locality</li> <li>Inter-workload interference</li> <li>Deadlines and priorities</li> </ul>"},{"location":"kubernetes/introduction/#master-controller-manager","title":"\ud83e\udde9 Master: Controller Manager","text":"<p>Logically, each controller is a separate process. However, to reduce complexity, they are all compiled into a single binary and run in a single process: the kube-controller-manager.</p> <p>These controllers include:</p> <ul> <li> <p>Node Controller   Detects and responds when nodes become unresponsive or go offline.</p> </li> <li> <p>Replication Controller   Ensures the correct number of pod replicas are running for each replication controller object in the cluster.</p> </li> <li> <p>Endpoint Controller   Populates the <code>Endpoints</code> object, connecting Services to their corresponding Pods.</p> </li> <li> <p>Service Account &amp; Token Controller   Automatically creates default service accounts and API tokens for newly created namespaces.</p> </li> </ul>"},{"location":"kubernetes/introduction/#node-components","title":"\ud83e\uddf1 Node Components","text":""},{"location":"kubernetes/introduction/#kubelet","title":"\ud83d\udccc Kubelet","text":"<ul> <li>An agent that runs on every node in the cluster.</li> <li>Ensures that the containers described in the PodSpec are running and healthy.</li> <li>Communicates with the Kube API Server to receive instructions and report status.</li> </ul>"},{"location":"kubernetes/introduction/#kube-proxy","title":"\ud83c\udf10 Kube Proxy","text":"<ul> <li>A network proxy that also runs on each node in the cluster.</li> <li>Maintains network rules on nodes, allowing:</li> <li>Communication between Pods within the cluster</li> <li>External access to Services from outside the cluster</li> <li>Handles TCP/UDP forwarding and supports virtual IPs via iptables or IPVS.</li> </ul>"},{"location":"kubernetes/introduction/#container-runtime","title":"\ud83d\udd27 Container Runtime","text":"<ul> <li>The software responsible for running containers on each node.</li> <li>Kubernetes supports multiple container runtimes via the Container Runtime Interface (CRI), including:</li> <li>Docker</li> <li>containerd</li> <li>CRI-O</li> <li>rktlet (now deprecated)</li> </ul>"},{"location":"kubernetes/introduction/#pods","title":"\ud83d\udce6 PODS","text":"<p>(Reference: Imran Teli)</p> <p> </p>"},{"location":"kubernetes/introduction/#addons","title":"\ud83e\udde9 Addons","text":"<p>Kubernetes supports a variety of addons that extend its core functionality:</p> <ul> <li> <p>DNS   Provides name resolution for services and pods within the cluster.</p> </li> <li> <p>Web UI (Dashboard)   A web-based interface for managing and visualizing the cluster.</p> </li> <li> <p>Container Resource Monitoring   Tracks usage metrics like CPU, memory, and disk for containers.</p> </li> <li> <p>Cluster-Level Logging   Collects and stores logs from all cluster components for debugging and auditing.</p> </li> </ul>"},{"location":"kubernetes/introduction/#kubernetes-setup-tools","title":"\u2699\ufe0f Kubernetes Setup Tools","text":""},{"location":"kubernetes/introduction/#the-hard-way-manual-setup","title":"\ud83d\udee0\ufe0f The Hard Way (Manual Setup)","text":"<ul> <li>Full manual installation of Kubernetes components (used for learning and deep understanding).</li> <li>Requires setting up etcd, API server, controller manager, scheduler, kubelet, and kube-proxy manually.</li> </ul>"},{"location":"kubernetes/introduction/#minikube","title":"\ud83e\uddea Minikube","text":"<ul> <li>Creates a single-node Kubernetes cluster on your local machine.</li> <li>Great for testing, development, and learning.</li> </ul>"},{"location":"kubernetes/introduction/#kubeadm","title":"\u26a1 Kubeadm","text":"<ul> <li>Tool to easily set up multi-node Kubernetes clusters.</li> <li>Platform-agnostic: works on VMs, EC2 instances, physical machines, and more.</li> <li>Handles essential steps like initializing the cluster and joining nodes.</li> </ul>"},{"location":"kubernetes/introduction/#kops","title":"\u2601\ufe0f Kops","text":"<ul> <li>Used for deploying production-grade multi-node Kubernetes clusters on AWS.</li> <li>Supports HA (High Availability) setups, upgrades, and more.</li> </ul>"},{"location":"kubernetes/introduction/#whats-next","title":"\ud83d\udcd8 What's Next?","text":"<ul> <li>Kubernetes History</li> <li>Setup kubernetes on Raspberry PI</li> </ul>"},{"location":"kubernetes/jobs_cron_jobs/","title":"Jobs and Cron Jobs","text":""},{"location":"kubernetes/jobs_cron_jobs/#jobs","title":"Jobs","text":"<p>A Job runs a task to completion \u2014 once or multiple times, depending on settings.</p> <p>They temporarily run as pods on nodes to handle specific tasks.</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: pi\nspec:\n  template:\n    spec:\n      containers:\n      - name: pi\n        image: perl:5.34.0\n        command: [\"perl\",  \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n      restartPolicy: Never\n  backoffLimit: 4\n</code></pre>"},{"location":"kubernetes/jobs_cron_jobs/#cronjob","title":"CronJob","text":"<p>A CronJob runs Jobs on a schedule, like a Linux cron job. Each run creates a Pod that executes the task.</p> <p>They temporarily run as pods on nodes to handle specific tasks.</p> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  schedule: \"* * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: hello\n            image: busybox:1.28\n            imagePullPolicy: IfNotPresent\n            command:\n            - /bin/sh\n            - -c\n            - date; echo Hello from the Kubernetes cluster\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"kubernetes/kube_config/","title":"What is Kube Config File?","text":"<p>The kubeconfig file is a configuration file used by <code>kubectl</code> to access Kubernetes clusters. By default, it is located at <code>~/.kube/config</code></p>"},{"location":"kubernetes/kube_config/#the-kubeconfig-file-organizes-information-about","title":"The Kubeconfig File Organizes Information About:","text":"<ol> <li>Cluster \u2013 API server addresses and associated settings</li> <li>Users \u2013 Credentials and authentication information</li> <li>Namespaces \u2013 Default namespace for kubectl commands (A namespace in Kubernetes is a way to divide cluster resources between multiple users or applications.)</li> <li>Authentication mechanisms \u2013 How users authenticate with clusters</li> </ol>"},{"location":"kubernetes/kube_config/#kubeconfig-example","title":"kubeconfig example","text":"<pre><code>apiVersion: v1\nkind: Config\n\nproxy-url: https://proxy.host:3128\n\nclusters:\n- cluster:\n    proxy-url: http://proxy.example.org:3128\n    server: https://k8s.example.org/k8s/clusters/c-xxyyzz\n  name: development\n\nusers:\n- name: developer\n\ncontexts:\n- context:\n    cluster: development\n    user: developer\n  name: development\n\ncurrent-context: development\n</code></pre> <p>The contexts section maps a cluster to a user, allowing <code>ubectl</code> to know which credentials to use for which cluster.</p> <p>The current-context defines which context is used by default when running <code>kubectl</code> commands.</p> <p>If you have <code>kubectl</code> installed on another machine, you can copy the kubeconfig file to that machine to access the same Kubernetes cluster from both.</p> <p><code>current-context</code> </p> <p>if you have cubectl installed on another machine and you can copy cubeconfig file to that machine then you can talk to api master node from both machines </p> <p>Find more information see the official kubeconfig docs.</p>"},{"location":"kubernetes/kubernetes_infrastructure_diagram/","title":"Kubernetes architecture diagram","text":""},{"location":"kubernetes/kubernetes_infrastructure_diagram/#kubernetes-infrastructure-diagram","title":"Kubernetes Infrastructure Diagram","text":"<p>CLICK ME to view the diagram in Excalidraw</p> <p></p>"},{"location":"kubernetes/lens/","title":"Lens","text":""},{"location":"kubernetes/lens/#what-is-lens","title":"What is Lens ?","text":"<p>Lens is a central tool used to visualize data for all your Kubernetes clusters.</p>"},{"location":"kubernetes/lens/#setting-up-lens","title":"Setting up Lens","text":"<ol> <li> <p>Install Lens from here.</p> </li> <li> <p>Open the application.</p> </li> <li> <p>Open your kubeconfig:</p> <ul> <li>Navigate to <code>home</code> directory \u2192 <code>KUBERNETES CLUSTERS</code> \u2192 <code>Local Kubeconfigs</code> \u2192 <code>+ Add Kubeconfig</code></li> </ul> </li> </ol> <p>Right-click on the cluster name to access shortcuts to <code>Settings</code> and more.</p> <p>Lens requires a Prometheus scraping tool to display and visualize data as graphs.</p> <p>Enable metrics in <code>Settings</code> \u2192 <code>Lens Metrics</code></p>"},{"location":"kubernetes/limits/","title":"Limits","text":""},{"location":"kubernetes/limits/#limits","title":"Limits","text":"<p>Use limits to set the minimum and maximum amount of CPU, RAM, etc.</p> <pre><code>---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: frontend\nspec:\n  containers:\n  - name: app\n    image: images.my-company.example/app:v4\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"\n  - name: log-aggregator\n    image: images.my-company.example/log-aggregator:v6\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"\n</code></pre>"},{"location":"kubernetes/namespaces/","title":"Namespaces","text":"<p>Namespaces lets you isolate group of resources within a single cluster.</p>"},{"location":"kubernetes/namespaces/#default-kubernetes-namespace","title":"Default Kubernetes Namespace","text":"<p>These namespaces gets created automatically when a cluster is created:</p> <ul> <li>default</li> <li>kube-system</li> <li>kube-public</li> <li>kube-node-lease</li> </ul> <p>Get namespaces: <code>kubectl get namespaces</code></p>"},{"location":"kubernetes/namespaces/#cli-commands","title":"CLI Commands","text":"<p>Get all objects in default namespace: <code>kubectl get all</code></p> <p>Show all resources from all namespaces: <code>kubectl get all-  namespaces</code></p> <p>Services from a specific namespace: <code>kubectl svc -n kube-system</code></p> <p>Create namespace: <code>kubectl create ns kubekart</code></p> <p>And run a pod: <code>kubectl run nginx1 --image=nginx -n kubekart</code></p> <p>Get pod from your namespace: <code>kubectl get podf -n kubekart</code></p> <p>Delete a namespace: <code>kubectl delete ns kubekart</code></p>"},{"location":"kubernetes/namespaces/#specify-namespace-in-definition-file","title":"Specify Namespace in Definition File:","text":"<pre><code>cat pod1.yaml\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx12\n  namespace: kubekart\n  labels:\n    app: frontend\n    project: infinity\nspec:\n  containers:\n    - name: httpd-container\n      image: httpd\n      imagePullPolicy: IfNotPresent\n      ports:\n        - name: http-port\n          containerPort: 8080 # exposed port\n</code></pre> <p><code>kubectl apply -f pod1.yaml</code></p> <p>Extra namespaces example:</p> <ul> <li>dev</li> <li>prod</li> </ul>"},{"location":"kubernetes/namespaces/#change-preferred-namespace-in-kubeconfig-file","title":"Change preferred namespace in kubeconfig file","text":"<pre><code>kubectl config set-context --current --namespace=&lt;insert-namespace-name-here&gt;\n# Validate\nkubectl config view --minify | grep namespace:\n</code></pre>"},{"location":"kubernetes/objects/","title":"Objects in K8S","text":""},{"location":"kubernetes/objects/#pod","title":"Pod","text":"<ul> <li>The smallest deployable unit in Kubernetes.</li> <li>Represent a single instance of running processes in your cluster</li> <li>Can contain one or more containers that share storage and network</li> <li>Pods that run a single container<ul> <li>The \"one-container-per-pod\" model is the most common Kubernetes use case (Kubernetes manages the Pods rather than the containers directly).</li> </ul> </li> <li>Multi Container POD<ul> <li>Tightly coupled and need to share resources</li> <li>One main container and other as sidecar or init container (or both)</li> <li>Each Pod is meant to run a single instance of a given application</li> <li>Should use multiple Pods to scale horizontally</li> </ul> </li> </ul> <p>Definitions file in example similar to docker compose / docker run. <code>pod-setup.yml</code> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: webapp-pod\n  labels:\n    app: frontend\n    project: infinity\nspec:\n  containers:\n    - name: httpd-container\n      image: httpd\n      imagePullPolicy: IfNotPresent\n      ports:\n        - name: http-port\n          containerPort: 8080 # exposed port\n</code></pre></p> <p>Then to create the pod run this command:  <pre><code>kubectl create -f pod-setup.yml\n</code></pre></p> <p>Use commands below to get info</p> <pre><code>kubectl get pod\nkubectl describe pod webapp-pod\nkubectl get pod webapp-pod -o yaml\nkubectl get pod webapp-pod -o yaml &gt; webpod-definition.yml\n</code></pre> <p>Edit pod webapp-pod</p> <pre><code>kubectl edit webapp-pod\n</code></pre> <p>Type of Kind:</p> Kind API Version Pod v1 Service v1 Deployment apps/v1 Ingress networking.k8s.io/v1 <p>Pods docs</p>"},{"location":"kubernetes/objects/#service","title":"Service","text":"<ul> <li>Provides a stable network endpoint to access Pods.</li> <li>Supports different types: ClusterIP (default), NodePort, LoadBalancer, and ExternalName.</li> <li>Enables load balancing across multiple Pod replicas.</li> </ul>"},{"location":"kubernetes/objects/#replica-set","title":"Replica Set","text":"<ul> <li>Ensures a specified number of Pod replicas are running at any given time.</li> <li>Automatically replaces failed or terminated Pods to maintain the desired count.</li> </ul>"},{"location":"kubernetes/objects/#deployment","title":"Deployment","text":"<ul> <li>Provides declarative updates for Pods and ReplicaSets.</li> <li>Manages rollouts and rollbacks of application versions.</li> <li>Supports updating container images via image tags.</li> </ul>"},{"location":"kubernetes/objects/#config-map","title":"Config Map","text":"<ul> <li>Stores non-sensitive configuration data as key-value pairs.</li> <li>Used to decouple configuration artifacts from application code.</li> <li>Can inject data into Pods as environment variables, command-line arguments, or configuration files.</li> </ul>"},{"location":"kubernetes/objects/#secret","title":"Secret","text":"<ul> <li>Stores sensitive data (e.g., passwords, tokens, SSH keys) in base64-encoded format.</li> <li>Prevents exposing sensitive information in plain text.</li> <li>Can be mounted as files or exposed as environment variables in Pods.</li> </ul>"},{"location":"kubernetes/objects/#volumes","title":"Volumes","text":"<ul> <li> <p>Provide persistent or temporary storage for Pods.</p> </li> <li> <p>Volume types include:</p> <ul> <li>emptyDir \u2013 Temporary storage shared between containers in a Pod.</li> <li>hostPath \u2013 Mounts a file or directory from the host node.</li> <li>persistentVolumeClaim (PVC) \u2013 Abstraction for durable storage, often backed by cloud storage solutions.</li> <li>configMap/secret \u2013 Mount configuration or secret data as files.</li> <li>nfs, csi, awsElasticBlockStore, etc. \u2013 Other network and cloud-specific storage options.</li> </ul> </li> </ul>"},{"location":"kubernetes/replicaset/","title":"ReplicaSet","text":""},{"location":"kubernetes/replicaset/#problem","title":"Problem","text":"<p>If a pod is running a web application and the pod goes down, then users won't be able to access the data.</p> <p>Somone would need to log in and fix the problem, but this takes time.</p>"},{"location":"kubernetes/replicaset/#replicaset_1","title":"ReplicaSet","text":"<p>If a pod crashes, it will create a new pod automatically with a health check.</p> <p>A ReplicaSet can be used to scale the number of pods.</p> <p></p>"},{"location":"kubernetes/replicaset/#example-yaml","title":"Example YAML","text":"<p><code>vim sampleReplicaSet.yaml</code>:</p> <pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: guestbook\n    tier: frontend\nspec:\n  # modify replicas according to your case\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        tier: frontend\n    spec:\n      containers:\n        - name: php-redis\n          image: gcr.io/google_samples/gb-frontend:v3\n</code></pre>"},{"location":"kubernetes/replicaset/#commands","title":"Commands","text":"<p>create replica: <pre><code>kubectl create -f sampleReplicaSet.yaml\n</code></pre></p> <p>update replica: <pre><code>kubectl apply -f sampleReplicaSet.yaml\n</code></pre></p> <p>get replica: <pre><code>kubectl get rs\n</code></pre></p> <p>get pods: <pre><code>kubectl get pod\n</code></pre></p> <p>scale replicas: <pre><code># not recommended in production\nkubectl scale --replicas=1 rs/frontend\n# frontend = replica name\n</code></pre></p> <p>edit live config: <pre><code># not recommended in production\nkubectl edit rs frontend\n</code></pre></p> <p>delete replica: <pre><code>kubectl delete rs frontend\n</code></pre></p>"},{"location":"kubernetes/secrets/","title":"Secrets","text":"<p>A Secret is an object that contains a small amount of sensitive data such as a password, a token, or a key.</p>"},{"location":"kubernetes/secrets/#base64-encoding-method","title":"Base64 Encoding Method","text":"<p>There is a way to encrypt a secret but that's outside the scope of this docs.</p> <p>Base64 Encoding Example</p> <p>You can use <code>base64</code> to encode and decode secrets for Kubernetes. Kubernetes stores secret data as base64-encoded strings, so any values you provide will be encoded automatically when you create a Secret.</p> <pre><code># Encode a string to base64\necho -n \"secretpass\" | base64\n# Output: c2VjcmV0cGFzcw==\n\n# Decode a base64 string\necho 'c2VjcmV0cGFzcw==' | base64 --decode\n# Output: secretpass\n</code></pre>"},{"location":"kubernetes/secrets/#create-secret-imperative","title":"Create Secret | Imperative","text":"<pre><code>kubectl create secret generic db-secret --from-literal=MYSQL_ROOT_PASSWORD=somecomplexpassword\n# Output: secret/db-secret created\n</code></pre>"},{"location":"kubernetes/secrets/#create-secret-from-files","title":"Create Secret from Files","text":"<pre><code># Create files needed for rest of example.\necho -n 'admin' &gt; ./username.txt\necho -n '1f2d1e2e67df' &gt; ./password.txt\n\nkubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txt\n</code></pre>"},{"location":"kubernetes/secrets/#view-secret","title":"View Secret","text":"<pre><code>$ kubectl get secret db-secret -o yaml\napiVersion: v1\ndata:\n  MYSQL_ROOT_PASSWORD: c29tZWNvbXBsZXhwYXNzd29yZA==\nkind: Secret\nmetadata:\n  ...\n</code></pre>"},{"location":"kubernetes/secrets/#create-secret-declarative","title":"Create Secret | Declarative","text":"<p>First, encode your secret value using base64:</p> <pre><code>echo -n \"somecomplexpassword\" | base64\n# Output: c29tZWNvbXBsZXhwYXNzd29yZA==\n</code></pre> <p>Then create a YAML file (e.g., <code>db-secret.yml</code>):</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: mysecret\ntype: Opaque\ndata:\n  my_root_pass: c29tZWNvbXBsZXhwYXNzd29yZA==\n</code></pre>"},{"location":"kubernetes/secrets/#pod-reading-secret","title":"POD Reading Secret","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: db-pod\n  labels:\n    app: db\n    project: infinity\nspec:\n  containers:\n    - name: mysql-container\n      image: mysql:5.7\n      envFrom:\n        - secretRef:\n            name: db-secret\n</code></pre>"},{"location":"kubernetes/secrets/#pod-reading-specific-secret-key","title":"POD Reading Specific Secret Key","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: db-pod\n  labels:\n    app: db\n    project: infinity\nspec:\n  containers:\n    - name: mysql-container\n      image: mysql:5.7\n      env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: my_root_pass\n</code></pre>"},{"location":"kubernetes/secrets/#docker-config-secrets","title":"Docker config Secrets","text":"<p>Create Docker secret</p> <pre><code>kubectl create secret docker-registry secret-tiger-docker \\\n  --docker-email=tiger@acme.example \\\n  --docker-username=tiger \\\n  --docker-password=pass1234 \\\n  --docker-server=my-registry.example:5000\n</code></pre> <p>This command creates a Secret of type kubernetes.io/dockerconfigjson</p> <p>Retrieve the .data.dockerconfigjson field from that new Secret and decode the data:</p> <pre><code>kubectl get secret secret-tiger-docker -o jsonpath='{.data.*}' | base64 -d\n</code></pre> <p>Output</p> <pre><code>{\n  \"auths\": {\n    \"my-registry.example:5000\": {\n      \"username\": \"tiger\",\n      \"password\": \"pass1234\",\n      \"email\": \"tiger@acme.example\",\n      \"auth\": \"dGlnZXI6cGFzczEyMzQ=\"\n    }\n  }\n</code></pre> <p>Create a Pod that uses your Secret</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: private-reg\nspec:\n  containers:\n  - name: private-reg-container\n    image: &lt;your-private-image&gt;\n  imagePullSecrets:\n  - name: secret-tiger-docker\n</code></pre>"},{"location":"kubernetes/secrets/#hands-on","title":"Hands On","text":"<pre><code>echo -n \"admin\" | base64\n\necho -n \"mysecretpass\" | base 64\n\nvim mysecret.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: mysecret\ndata:\n  username: YWRtaW4=\n  password: bXlzZWNyZXRwYXNz\ntype: Opaque\n</code></pre> <p>VULNERABILITY: hardcoded-credentials Embedding credentials in source code risks unauthorized access</p> <p><pre><code>kubectl create -f mysecret.yaml\n# secret/mysecret created\n</code></pre> <pre><code>vim readsecret.yaml\n</code></pre></p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: secret-env-pod\nspec:\n  containers:\n    - name: mycontainer\n      image: redis\n      env:\n        - name: SECRET_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: mysecret\n              key: username\n              optional: false  # same as default; \"mysecret\" must exist and include a key named \"username\"\n        - name: SECRET_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysecret\n              key: password\n              optional: false  # same as default; \"mysecret\" must exist and include a key named \"password\"\n  restartPolicy: Never\n</code></pre> <pre><code>kubectl create -f readsecret.yaml\n# secret/mysecret created\n</code></pre> <pre><code>kubectl get pod\n</code></pre> <pre><code># OUTPUT\nNAME                 READY   STATUS    RESTARTS   AGE\nsecret-env-pod       1/1     Running   0          24s\n</code></pre> <pre><code>kubectl exec --stdin --tty secret-env-pod -- /bin/bash\nroot@secret-env-pod:data# echo $SECRET_USERNAME\nadmin\nroot@secret-env-pod:data# echo $SECRET_PASSWORD\nmysecretpass\n</code></pre>"},{"location":"kubernetes/service/","title":"Service","text":""},{"location":"kubernetes/service/#host-service-in-kubernetes","title":"Host Service In Kubernetes","text":"<ul> <li>If you want to expose the application running inside a pod as a network service then you will need to host a service</li> <li>Similar to load balancers</li> </ul>"},{"location":"kubernetes/service/#info","title":"Info","text":"<p>Kubernetes Pods are mortal. They are born and when they die they are not resurrected. If you use a Deployment to run your app, it can destroy and create Pods dynamically.</p> <p>Each Pod gets its own IP address, however the set of Pods running in one moment in time could be different from the set of Pods running that application a moment later.</p> <p>This leads to a problem: if some set of Pods(call them backenders) have functionality to other set of Pods(call them frontenders) inside your cluster, how do the frontenders find out keep track of which IP address to connect to, so that the frontend can use the backend part of the workload?</p> <p>Enter Services.</p>"},{"location":"kubernetes/service/#service-commands","title":"Service Commands","text":"<p>Create <pre><code>kubectl create -f service-defs.yml\n</code></pre></p> <p>Get info <pre><code>kubectl get svc\n</code></pre></p> <p>Delete <pre><code>kubectl delete svc &lt;service name&gt;\n</code></pre></p>"},{"location":"kubernetes/service/#services","title":"Services","text":""},{"location":"kubernetes/service/#nodeport","title":"NodePort","text":"<ul> <li>Similar to Port mapping in Docker</li> <li>A host port and map it to a container port</li> <li>Not for production</li> </ul> <p>Service example for the file <code>service-defs.yml</code>: <pre><code>apiVersion: v1\nkind: Service\n  name: webapp-service\nspec:\n  type: NodePort #  &lt;-- Service\n  ports:\n  - targetPort: 80\n    port: 80\n    nodePort: 30005\n    protocol: TCP\n  selector:\n    app: frontend # &lt;-- This is a Pod label\n</code></pre></p>"},{"location":"kubernetes/service/#example","title":"Example","text":"<p>Pod reference <code>vproapppod.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: vproapp\n  labels:\n    app: vproapp\nspec:\n  containers:\n    - name: appcontainer\n      image: imranvisualpath/freshtomapp:V7\n      ports:\n        - name: vproapp-port\n          containerPort: 8080\n</code></pre> <p>NodePort Service <code>`vproapp-nodeport.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: helloworld-service\nspec:\n  ports:\n  - port: 8090\n    nodePort: 30001\n    targetPort: vproapp-port\n    protocol: TCP\n  selector:\n    app: vproapp\n  type: NodePort\n</code></pre> <pre><code>kubectl create -f vproapp-nodeport.yaml\n</code></pre> <pre><code>kubectl get svc\nkubectl describe svc &lt;nodeport-service-name&gt;\n</code></pre> <p>output example <pre><code>IP: 200.20.200.200 &lt;-- static ip of your service\nEndpoints: 100.10.1.1:8080 &lt;-- your pod ip\n</code></pre></p> <pre><code>svc describe pod | grep IP\n</code></pre> <p>Output will show same ip as on <code>endpoints</code> config value.</p> <p>To access the TomApp Application use the IP address of either master or any worker nodes <pre><code>curl 200.20.200.200:30001\n</code></pre></p>"},{"location":"kubernetes/service/#loadbalancer","title":"LoadBalancer","text":"<ul> <li>Expose to outside network for production usecases.</li> </ul>"},{"location":"kubernetes/service/#example_1","title":"Example","text":"<p>Pod reference <code>vproapppod.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: vproapp\n  labels:\n    app: vproapp\nspec:\n  containers:\n    - name: appcontainer\n      image: imranvisualpath/freshtomapp:V7\n      ports:\n        - name: vproapp-port\n          containerPort: 8080\n</code></pre> <p>NodePort Service <code>`vproapp-nodebalancer.yml</code>:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: helloworld-service\nspec:\n  ports:\n  - port: 80\n    targetPort: vproapp-port\n    protocol: TCP\n  selector:\n    app: vproapp\n  type: LoadBalancer\n</code></pre> <p>To access the TomApp Application use the IP address of either master or any worker nodes</p> <pre><code>curl 200.20.200.200\n</code></pre>"},{"location":"kubernetes/service/#clusterip","title":"ClusterIP","text":"<ul> <li>Internal network communication between pods.</li> <li>Example: Tomcat connecting to MySQL</li> </ul>"},{"location":"kubernetes/service/#example_2","title":"Example","text":"<p>Pod reference <code>vproapppod.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: app-pod\n  labels:\n    app: backend\n    project: infinity\nspec:\n  containers:\n    - name: tomcat-container\n      image: tomcat\n      ports:\n        - name: app-port\n          containerPort: 8080\n</code></pre> <p>ClusterIP Service<code>tom-svc-clusterip.yml</code>:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: app-service\nspec:\n  type: ClusterIP\n  ports:\n    - targetPort: 8080\n      port: 8080\n      protocol: TCP\n  selector:\n    app: backend\n</code></pre>"},{"location":"kubernetes/setup_kops/","title":"Setup Kubernetes with Kops","text":""},{"location":"kubernetes/setup_kops/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li>\ud83d\udc27 Linux-based OS</li> <li>kubectl installed</li> <li>Registered domain (e.g., from Namecheap)</li> <li>A subdomain configured via AWS Route 53 with 4 NS (Name Server) records</li> </ul>"},{"location":"kubernetes/setup_kops/#launch-ec2-instance","title":"\u2601\ufe0f Launch EC2 Instance","text":"<ul> <li>Name: <code>kops</code></li> <li>AMI (Amazon Machine Image): <code>Ubuntu Server 24.04 LTS</code> (but its recommended to use 22.04 as its stable)</li> <li>Instance type: <code>t2.micro</code></li> <li>Key pair: <code>Name: 'kopskey'</code>, <code>Key pair type: 'RSA'</code>, <code>Private key file format: '.pem'</code></li> <li>Security group: <code>Name: 'kops-sg'</code>, <code>Inbound rules: SSH from My IP}</code></li> </ul>"},{"location":"kubernetes/setup_kops/#create-iam-user","title":"\ud83d\udc64 Create IAM User","text":"<ul> <li>Name: <code>kopsadmin</code></li> <li>Permissions: <code>Attach policies directly -&gt; AdministratorAccess</code></li> </ul>"},{"location":"kubernetes/setup_kops/#create-access-key","title":"\ud83d\udd10 Create Access key","text":"<ul> <li>Choose Command Line Interface (CLI)</li> <li>Copy the Access Key ID and Secret Access Key</li> </ul>"},{"location":"kubernetes/setup_kops/#connect-to-ec2-instance","title":"\ud83d\udd11 Connect to EC2 Instance","text":"<pre><code>chmod 600 kopskey.pem\nssh -i kopskey.pem ubuntu@@&lt;your_ec2_public_ip&gt;\n</code></pre> <p>Update and install AWS CLI: <pre><code>sudo apt update\nsudo snap install aws-cli --classic\n</code></pre></p> <p>Configure AWS CLI: <pre><code>aws configure\n</code></pre> <pre><code>AWS Access Key ID [None]: *********************\nAWS Secret Key [None]: **************************\nDefault region name [None]: us-east-1\nDefault output format [None]: json\n</code></pre></p>"},{"location":"kubernetes/setup_kops/#generate-ssh-keys","title":"\ud83d\udd10 Generate SSH keys","text":"<pre><code>ssh-keygen\nls ~/.ssh\n# output authorized_keys id_ed25519 id_ed25519.pub\n</code></pre>"},{"location":"kubernetes/setup_kops/#install-kops","title":"\ud83d\udee0\ufe0f Install Kops","text":"<pre><code>curl -Lo kops https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '\"' -f 4)/kops-linux-amd64\n\nchmod +x kops\n\nsudo mv kops /usr/local/bin/kops\n</code></pre>"},{"location":"kubernetes/setup_kops/#install-kubectl","title":"\ud83e\uddf0 Install kubectl","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n# check if installed\nkubectl version --client\n</code></pre>"},{"location":"kubernetes/setup_kops/#create-a-bucket-with-amazon-s3","title":"\ud83e\udea3 Create a bucket with Amazon S3","text":"<p>In the AWS Console or CLI:</p> <ul> <li>Bucket type: <code>General purpose</code></li> <li>Bucket name: <code>kopsstate1877</code> &lt;= This needs to be unique</li> </ul>"},{"location":"kubernetes/setup_kops/#create-the-dns-zone-with-amazon-route-53","title":"\ud83c\udf10 Create the DNS Zone with Amazon <code>Route 53</code>","text":"<p>Using example domain: alexanderlindholm.net</p> <ol> <li> <p>Go to Route 53 &gt; Hosted Zones</p> </li> <li> <p>Create a Public Hosted Zone:</p> </li> </ol> <p>domain name: <code>kubevpro.alexanderlindholm.net</code></p> <p>Type: <code>Public hosted zone</code></p>"},{"location":"kubernetes/setup_kops/#copy-ns-records","title":"\ud83e\uddfe Copy NS Records","text":"<ol> <li> <p>Click into your new hosted zone</p> </li> <li> <p>Under Records, copy the 4 NS records (e.g., ns-xxx.awsdns-xx.com)</p> </li> </ol>"},{"location":"kubernetes/setup_kops/#update-dns-records-in-namecheap","title":"\ud83d\udd17 Update DNS Records in Namecheap","text":"<p>In your domain provider\u2019s dashboard, add:</p> Type Host Value TTL NS Record kubevpro ns-xxx.awsdns-xx.com Automatic NS Record kubevpro ns-xxxx.awsdns-xx.org Automatic NS Record kubevpro ns-xxx.awsdns-xx.net Automatic NS Record kubevpro ns-xxxx.awsdns-xx.uk Automatic <p>replace Value column with the 4 NS Type Records from AWS Route 53</p>"},{"location":"kubernetes/setup_kops/#create-your-kubernetes-cluster","title":"\ud83d\ude80 Create Your Kubernetes Cluster","text":"<pre><code>kops create cluster \\\n  --name=kubevpro.alexanderlindholm.net \\\n  --state=s3://kopsstate1877 \\\n  --zones=us-east-1a,us-east-1b \\\n  --node-count=2 \\\n  --node-size=t3.small \\\n  --control-plane-size=t3.medium \\\n  --dns-zone=kubevpro.alexanderlindholm.net \\\n  --node-volume-size=12 \\\n  --control-plane-volume-size=12 \\\n  --ssh-public-key ~/.ssh/id_ed25519.pub\n</code></pre> <p>Apply the configuration: <pre><code>kops update cluster --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877 --yes --admin\n</code></pre></p>"},{"location":"kubernetes/setup_kops/#validate-the-cluster","title":"\u2705 Validate the Cluster","text":"<pre><code>kops validate cluster --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877\n</code></pre>"},{"location":"kubernetes/setup_kops/#useful-commandskube","title":"\ud83d\udd0d Useful CommandsKube","text":"<p>Get kubeconfig: <pre><code>cat .kube/config\n# config is created by master node\n</code></pre></p> <p>List nodes: <pre><code>kubectl get nodes\n</code></pre></p>"},{"location":"kubernetes/setup_kops/#delete-the-cluster","title":"\ud83d\uddd1\ufe0f Delete the Cluster","text":"<pre><code>kops delete cluster --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877 --yes\n</code></pre> <p>Then power off or delete the EC2 instance (Kops)</p>"},{"location":"kubernetes/setup_kops/#troubleshoot","title":"\u26a0\ufe0f Troubleshoot","text":"<p>List instance groups: <pre><code>kops get ig --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877\n\n# Output Example:\n# NAME              ROLE        MACHINETYPE MIN MAX ZONES\n# control-plane-us-east-1a  ControlPlane    t3.medium   1   1   us-east-1a\n# nodes-us-east-1a      Node        t3.small    1   1   us-east-1a\n# nodes-us-east-1b      Node        t3.small    1   1   us-east-1b\n</code></pre></p> <p>Edit an instance group (e.g., if an AMI is invalid): <pre><code>kops edit ig nodes-us-east-1a --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877\n</code></pre></p> <p>\ud83c\udf10 Verify DNS <pre><code>dig +short api.kubevpro.alexanderlindholm.net\n# output example: \n# 5.34.68.27\n</code></pre></p> <p>You should see this IP listed in Route 53 &gt; Hosted Zones under A or CNAME record for your subdomain.</p>"},{"location":"kubernetes/setup_kubectl/","title":"Kubectl","text":""},{"location":"kubernetes/setup_kubectl/#system-requirements","title":"\ud83d\udccb System Requirements","text":"<ul> <li>\ud83d\udc27 Linux-based OS</li> </ul>"},{"location":"kubernetes/setup_kubectl/#install-kubectl-binary","title":"\ud83d\udd27 Install <code>kubectl</code> binary","text":"<p>Based on the official kubectl documentation</p>"},{"location":"kubernetes/setup_kubectl/#download-the-latest-release","title":"\ud83d\udce5 Download the Latest Release","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n</code></pre>"},{"location":"kubernetes/setup_kubectl/#validate-the-binary","title":"\u2705 Validate the Binary","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256\"\n\necho \"$(cat kubectl.sha256)  kubectl\" | sha256sum --check\n\n# If valid, the output should be: \"kubectl: OK\"\n# If not, it will say: \"kubectl: FAILED\"\n</code></pre>"},{"location":"kubernetes/setup_kubectl/#install-kubectl","title":"\ud83d\udee0 Install kubectl","text":"<pre><code>sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n</code></pre>"},{"location":"kubernetes/setup_minikube/","title":"Setup Local Test Environment with Minikube","text":""},{"location":"kubernetes/setup_minikube/#system-requirements","title":"\ud83d\udccb System Requirements","text":"<ul> <li>\ud83d\udc27 Linux-based OS</li> <li>Docker or a compatible VM hypervisor (e.g., VirtualBox, Hyper-V)</li> <li>kubectl installed</li> </ul>"},{"location":"kubernetes/setup_minikube/#install-binary-minikube","title":"\ud83d\udce6 Install Binary Minikube","text":"<p>This is a copy of the official install docs</p>"},{"location":"kubernetes/setup_minikube/#binary-installation","title":"\ud83d\udd27 Binary Installation","text":"<pre><code>curl -LO https://github.com/kubernetes/minikube/releases/latest/download/minikube-linux-amd64\n\nsudo install minikube-linux-amd64 /usr/local/bin/minikube &amp;&amp; rm minikube-linux-amd64\n</code></pre>"},{"location":"kubernetes/setup_minikube/#start-your-cluster","title":"\ud83d\udfe2 Start your cluster","text":"<pre><code>minikube start\n</code></pre>"},{"location":"kubernetes/setup_minikube/#interact-with-your-cluster","title":"\ud83d\udce1 Interact with your cluster","text":"<pre><code>kubectl get po -A\n</code></pre> <p>Or</p> <pre><code>minikube kubectl -- get po -A\n</code></pre>"},{"location":"kubernetes/setup_minikube/#deploy-dashboard","title":"\ud83d\udda5\ufe0f Deploy dashboard","text":"<pre><code>minikube dashboard\n</code></pre>"},{"location":"kubernetes/setup_minikube/#get-nodes","title":"\ud83e\uddf1 Get Nodes","text":"<pre><code>kubectl get nodes\n</code></pre>"},{"location":"kubernetes/setup_minikube/#deploy-a-test-application","title":"\ud83d\udce6 Deploy a Test Application","text":"<pre><code>kubectl create deployment hello-minikube --image=kicbase/echo-server:1.0\n\nkubectl expose deployment hello-minikube --type=NodePort --port=8080\n\n# Display service\nkubectl get services hello-minikube\n\n# Access this service by letting minkube launch a web browser for you\nminikube service hello-minikube\n\n# Alternativly enable port forwarding\nkubectl port-forward service/hello-minikube 7080:8080\n</code></pre>"},{"location":"kubernetes/setup_minikube/#delete-cluster-resources","title":"\u274c Delete Cluster &amp; Resources","text":"<pre><code>kubectl get svc\nkubectl delete svc hello-minikube\n\nkubectl get deploy\nkubectl delete deploy hello-minikube\n\nminikube stop\nminikube delete\n</code></pre>"},{"location":"kubernetes/setup_minikube/#commands-to-manage-your-cluster","title":"\ud83d\udee0 Commands to Manage Your Cluster","text":"<pre><code>minikube pause                                      # Pause Kubernetes without impacting deployed applications\n\nminikube unpause                                    # Unpause a paused instance\n\nminikube stop                                       # Halt the cluster\n\nminikube config set memory 9001                     # Change the default memory limit (requires a restart)\n\nminikube addons list                                # minikube addons list\n\nminikube start -p aged --kubernetes-version=v1.16.1 # Create a second cluster running an older Kubernetes release\n\nminikube delete --all                               # Delete all of the minikube clusters\n</code></pre>"},{"location":"kubernetes/taints_tolerations/","title":"Taints and Tolerations","text":""},{"location":"kubernetes/taints_tolerations/#taints-and-toleration","title":"Taints and Toleration","text":"<p>Only allows specific pods with the required tolerations (key-value pairs) to be scheduled on nodes that have matching taints.</p>"},{"location":"kubernetes/volumes/","title":"Volumes","text":""},{"location":"kubernetes/volumes/#type-of-volumes","title":"Type of Volumes","text":"<ul> <li>awsElasticBlockStore</li> <li>azureDisk</li> <li>cephhfs</li> <li>cinder</li> <li>fc (fibre channel)</li> <li>flocker (deprecated)</li> <li>gcePersistentDisk (for Google Cloud)</li> <li>glusterfs (RedHat)</li> <li>iscsi</li> <li>local</li> <li>NFS</li> <li>portworxVolume</li> <li>vSphere VMDK</li> <li>hostPath (not recommended for production)</li> </ul>"},{"location":"kubernetes/volumes/#hostpath-configuration-example","title":"hostPath configuration example","text":"<pre><code>---\n# This manifest mounts /data/foo on the host as /foo inside the\n# single container that runs within the hostpath-example-linux Pod.\n#\n# The mount into the container is read-only.\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hostpath-example-linux\nspec:\n  os: { name: linux }\n  nodeSelector:\n    kubernetes.io/os: linux\n  containers:\n  - name: example-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - mountPath: /foo # &lt;-- container volume\n      name: example-volume \n      readOnly: true\n  volumes:\n  - name: example-volume\n    # mount /data/foo, but only if that directory already exists\n    hostPath:\n      path: /data/foo # directory location on host\n      type: Directory # this field is optional\n</code></pre>"},{"location":"kubernetes/volumes/#hands-on","title":"Hands on","text":"<pre><code>vim mysqlpod.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: dbpod\nspec:\n  os: { name: linux }\n  nodeSelector:\n    kubernetes.io/os: linux\n  containers:\n  - name: mysql\n    image: mysql:5.7\n    volumeMounts:\n    - mountPath: /var/lib/mysql # &lt;-- container volume\n      name: dbvol\n      readOnly: true\n  volumes:\n  - name: dbvol\n    hostPath:\n      path: /data\n      type: DirectoryOrCreate\n</code></pre> <pre><code>kubectl apply -f mysqlpod.yaml\n\nkubectl get pods\n\nkubectl describe dbpod\n\nkubectl delete pod dbpod\n</code></pre> <p>validate that volume host path is <code>/data</code></p> <p>validate that mount volume is <code>/var/lib/mysql</code></p>"},{"location":"linux/","title":"Linux","text":"<p>This is a documentation site about Linux, covering various topics.</p> <p>Use the left sidebar to navigate through different sections.</p>"},{"location":"linux/GUI/","title":"GUI","text":""},{"location":"linux/GUI/#desktop-environment","title":"Desktop Environment","text":""},{"location":"linux/GUI/#list","title":"List","text":"<ol> <li>GNOME (GNOME 49 and higher)<ul> <li>very common</li> <li>simple &amp; easy</li> </ul> </li> <li>MATE<ul> <li>fork from GNOME 2 with independent development</li> </ul> </li> <li>KDE Plasma<ul> <li>lightweight, customizable</li> </ul> </li> <li>XFCE<ul> <li>extremely lightweight</li> </ul> </li> <li>Budgie<ul> <li>luxurious home computing experience</li> </ul> </li> <li>Pantheon<ul> <li>similar to MacOS design</li> </ul> </li> <li>Cinnamon<ul> <li>dev by Linux Mint</li> </ul> </li> <li>Unity<ul> <li>once Ubuntu's default desktop, now comunity-maintained</li> </ul> </li> </ol>"},{"location":"linux/GUI/#tiling-window-managers","title":"Tiling Window Managers","text":""},{"location":"linux/GUI/#list_1","title":"List","text":"<ul> <li>i3</li> <li>vile but easy, fast &amp; quick</li> <li>HyperLand</li> <li>futuristic</li> </ul>"},{"location":"linux/GUI/#window-managers","title":"Window Managers","text":""},{"location":"linux/GUI/#list_2","title":"List","text":"<ul> <li>Openbox</li> <li>Fluxbox</li> <li>IceWM</li> </ul>"},{"location":"linux/HTTP_CRUD/","title":"CRUD HTTP Methods with \ud83c\udf00 CURL","text":"<p>Flags</p> <ul> <li><code>-X</code> = Request Method</li> <li><code>-X GET</code> = Read data</li> <li><code>-X POST</code> = Create data</li> <li><code>-X PUT</code> = Update or replace data</li> <li><code>-X DELETE</code> = Remove data</li> <li><code>-X PATCH</code> = Partially update data</li> <li><code>-d</code> = Sends data in the request body</li> <li><code>-d '{\"name\":\"alex\",\"role\":\"dev\"}'</code></li> <li><code>-d \"name=alex&amp;role=dev\"</code></li> <li><code>-F</code> = Upload a file (multipart/form-data)</li> <li><code>-F \"file=@report.pdf\"</code></li> <li><code>-H</code> = Add custom request headers</li> <li><code>-H \"Content-Type: application/json\"</code></li> <li><code>-H \"Authorization: Bearer TOKEN\"</code></li> <li><code>-H \"X-Client-Version: 1.2.0\"</code></li> <li><code>-v</code> = Verbose (Show detailed request and response info)</li> <li><code>-L</code> = Follow redirects (301 or 302 CODE)</li> <li><code>-C -</code> = Resumes partial download</li> <li><code>curl -O https://example.com/largefile.zip</code> \u2192 Start download  </li> <li>(If it fails midway...)  </li> <li><code>curl -C - -O https://example.com/largefile.zip</code> \u2192 Continue from where it stopped</li> <li><code>-u user:pass</code> = Basic Auth</li> </ul>"},{"location":"linux/HTTP_CRUD/#get-read","title":"\ud83d\udd3d GET (READ)","text":""},{"location":"linux/HTTP_CRUD/#terminal-output","title":"\ud83d\udcdf Terminal Output","text":"<pre><code>curl -X GET https://api.example.com/users\n</code></pre>"},{"location":"linux/HTTP_CRUD/#download-files","title":"\ud83d\udcbe Download Files","text":"<p>Save with original filename <pre><code>curl -O https://example.com/file.txt\n</code></pre></p> <p>Save as a specific filename <pre><code>curl -o myfile.txt https://example.com/file.txt\n</code></pre></p>"},{"location":"linux/HTTP_CRUD/#post-create","title":"\u2795 POST (CREATE)","text":"<pre><code>curl -X POST https://api.example.com/developers \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"Alexander\", \"role\": \"DevOps\"}'\n</code></pre>"},{"location":"linux/HTTP_CRUD/#put-update-replace","title":"\u270d\ufe0f PUT (UPDATE / REPLACE)","text":""},{"location":"linux/HTTP_CRUD/#replace-data-for-user-with-id-3","title":"Replace data for user with ID 3","text":"<pre><code>curl -X PUT \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"email\": \"updated.email@example.com\"}' \\\n  https://crud.ba3a.tech/users/3\n</code></pre>"},{"location":"linux/HTTP_CRUD/#delete","title":"\u274c DELETE","text":"<pre><code>curl -X DELETE https://crud.ba3a.tech/users/3\n</code></pre>"},{"location":"linux/HTTP_CRUD/#upload-a-file-with-token-auth","title":"\ud83d\udd12 Upload a File with Token Auth","text":"<pre><code>curl -X POST https://api.example.com/upload \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -F \"file=@report.pdf\"\n</code></pre>"},{"location":"linux/HTTP_CRUD/#debugging","title":"\ud83d\udd75\ufe0f Debugging","text":"<p>View only headers <pre><code>curl -I https://example.com\n</code></pre></p> <p>Verbose output (full request/response) <pre><code>curl -v https://example.com\n</code></pre></p>"},{"location":"linux/HTTP_CRUD/#download-with-wget-easier-download-tool","title":"\ud83c\udf10 Download With WGET (easier download tool)","text":""},{"location":"linux/HTTP_CRUD/#save-to-a-directory-prefix","title":"Save to a directory (prefix)","text":"<pre><code>wget --https-only -P ./path &lt;URL&gt;\n</code></pre>"},{"location":"linux/HTTP_CRUD/#save-to-a-specific-file","title":"Save to a specific file","text":"<pre><code>wget --https-only -O ./path/file.txt &lt;URL&gt;\n</code></pre>"},{"location":"linux/archive/","title":"Archive Commands","text":""},{"location":"linux/archive/#tar","title":"\ud83d\udcbe TAR","text":"<p>Flags</p> <ul> <li><code>-c</code> = create</li> <li><code>-x</code> = extract</li> <li><code>-z</code> = gzip</li> <li><code>-v</code> = verbose</li> <li><code>-f</code> = filename</li> <li><code>-C</code> = extract into directory</li> </ul>"},{"location":"linux/archive/#create-a-tar-archive","title":"\ud83d\udcbe Create a <code>.tar</code> archive","text":"<pre><code>tar -cvf archive.tar &lt;file_or_directory&gt;\n</code></pre>"},{"location":"linux/archive/#extract-a-tar-archive","title":"\ud83d\udcbe Extract a <code>.tar</code> archive","text":"<pre><code>tar -xvf archive.tar -C &lt;/target_directory&gt;\n</code></pre>"},{"location":"linux/archive/#tar-tar-file-preview","title":"\ud83d\udcbe TAR <code>.tar</code> file preview","text":"<pre><code>tar -tvf archive.tar\n</code></pre>"},{"location":"linux/archive/#create-a-tar-gzip-targz-archive","title":"\ud83d\udddc\ufe0f Create a TAR + GZIP <code>.tar.gz</code> archive","text":"<pre><code>tar -czvf archive.tar.gz &lt;file_or_directory&gt;\n</code></pre>"},{"location":"linux/archive/#extract-a-tar-gzip-targz-archive","title":"\ud83d\udddc\ufe0f Extract a TAR + GZIP <code>.tar.gz</code> archive","text":"<pre><code>tar -xzvf archive.tar.gz -C &lt;/target_directory&gt;\n</code></pre>"},{"location":"linux/archive/#tar-gzip-targz-file-preview","title":"\ud83d\udddc\ufe0f TAR + GZIP <code>.tar.gz</code> file preview","text":"<pre><code>tar -tzvf archive.tar.gz\n</code></pre>"},{"location":"linux/archive/#gzip-only-single-files","title":"\ud83d\udcc3 GZIP <code>\u26a0\ufe0f only single files \u26a0\ufe0f</code>","text":"<p>Flags</p> <ul> <li><code>-k</code> = keep file</li> <li><code>-c</code> = Write compressed or decompressed data to stdout</li> <li><code>&gt;</code> = Redirect that output into a new file</li> </ul>"},{"location":"linux/archive/#archive-compress-to-gz-file-with-gzip","title":"\ud83d\udcc4 Archive (Compress) to <code>.gz</code> file with GZIP","text":"<pre><code>gzip -k archive.txt\n</code></pre> <p>\ud83d\udca1 or (same result using output redirection):</p> <pre><code>gzip -c archive.txt &gt; archive.txt.gz\n</code></pre> <p>\u2705 Also keeps the original file.</p>"},{"location":"linux/archive/#extract-decompress-a-gz-file-with-gzip","title":"\ud83d\udcc4 Extract (Decompress) a <code>.gz</code> file with GZIP","text":"<pre><code>gunzip -k archive.txt.gz\n</code></pre> <p>\ud83d\udca1 or (same result using output redirection):</p> <pre><code>gunzip -c archive.txt.gz &gt; archive.txt\n</code></pre> <p>\u2705 Also keeps the original file.</p>"},{"location":"linux/archive/#zip","title":"\ud83d\udd17 \u2704\u2508\u2508\u2508\u2508 ZIP","text":"<p>Flags</p> <ul> <li><code>-r</code> = Recursively include directories and files</li> </ul>"},{"location":"linux/archive/#create-a-zip-archive","title":"\ud83d\udd17 Create a <code>.zip</code> archive","text":"<pre><code>zip -r archive.zip &lt;file_or_directory&gt;\n</code></pre>"},{"location":"linux/archive/#extract-unzip-a-zip-archive","title":"\ud83d\udd17 Extract (Unzip) a <code>.zip</code> archive","text":"<pre><code>unzip archive.zip -d &lt;/target_directory&gt;\n</code></pre>"},{"location":"linux/archive/#zip-file-preview","title":"\ud83d\udd17 Zip file preview","text":"<pre><code>unzip -l archive.zip\n</code></pre>"},{"location":"linux/archive/#validate-file-info","title":"\ud83d\udd0d Validate file info","text":"<pre><code>file archive.zip\nfile archive.tar.gz\nfile archive.tar\nfile archive.gz\n</code></pre>"},{"location":"linux/boot/","title":"Boot","text":"<pre><code>graph TD\n  ON[\"POWER ON\"]\n  B[\"BIOS / UEFI\"]\n  P[\"POST\n  (runs inside BIOS/UEFI)\"]\n  D[\"BOOT DEVICE\"]\n  G[\"BOOT LOADER\"]\n  K[\"Kernel\"]\n  DR[\"Kernel Initialization\n  (Drivers, Modules, Initramfs)\"]\n  SYS[\"Systemd (PID 1)\"]\n  TARGET[\"Run .target files\"]\n  STARTUP[\"User space startup\n  (login, desktop, services)\"]\n\n  ON --&gt; B --&gt; P\n  B ---&gt; D --&gt; G --&gt; K --&gt; DR --&gt; SYS --&gt; TARGET --&gt; STARTUP</code></pre> <p>BIOS / UEFI</p> <ul> <li>Firmware that initializes hardware and starts the boot process</li> </ul> <p>POST (Power On Self Test)</p> <ul> <li>Tests all important hardware parts</li> </ul> <p>BOOT DEVICE</p> <ul> <li>SSD, HDD, CD</li> <li>System partition</li> </ul> <p>BOOT LOADER</p> <ul> <li>GRUB2</li> <li>Is a part of the distribution (not Linux Kernel)</li> </ul> <p>Kernel</p> <ul> <li>Core software that manages hardware, memory, and system resources</li> </ul> <p>Kernel Initialization</p> <ul> <li>Load:</li> <li>Device Drivers</li> <li>Kernel Modules</li> <li>Initramfs</li> <li>Mount the root filesystem</li> <li>Start the first user-space process (/lib/systemd/systemd)</li> </ul> <p>Systemd is responsible for booting the user space and managing services:</p> <ul> <li>Acts as parent of all processes on Linux</li> <li>Mounts file systems and disks</li> <li>Launches background processes (networking, sound, &amp; power management)</li> <li>Handles user logins</li> <li>Starts the desktop environment (if installed)</li> </ul> <p>.target files <pre><code>basic.target (Mounts filesystems)\n  \u2193\nmulti-user.target (Starts networking, login, SSH, etc.)\n  \u2193\ngraphical.target (if a desktop environment is installed)\n</code></pre></p>"},{"location":"linux/commands/","title":"Linux default \"command-line shell\" commands","text":"<pre><code>command list:\n$ whoami                       #display your username\n$ pwd                          #print working directory\n$ ls                           #list files\n$ cd /example/dir              #change to /example/dir directory\n$ cd ..                        #change to one step back directory\n$ cd                           #change to home directory\n$ mkdir ./dir                  #create directory\n$ mkdir -p /home/$USER/{a,b}/{x,y,z}     #create multiple directories\n$ ln -s /dir/fileA.txt fileB   #create a link\n$ unlink fileC                 #remove a link\n$ cat                          #displaying file conten &amp; concatenation\n$ sudo -i                      #switch to root user\n$ touch file{1..10}.txt        #create 10 files\n$ cp file.txt dir/             #move txt file to another directory\n$ cp /dir1/file.txt /dir1/dir2 # cp txt file to another directory using absolute path\n$ cp -r dirX dirY/             # copy a directory to another directory\n$ mv file.txt dir/             #move file to directory\n$ mv dir1 dir2/                #move directory to another directory\n$ mv fileA.txt fileB.txt       #rename file\n$ mv *.txt dir/                #move all txt files to a directory\n$ rm file.txt                  #remove a file\n$ rm -r dir                    #remove a directory\n$ rm -rf dir                   #remove a directory with force\n$ rm -rf *                     #remove everything with force\n$ file file_example            #check file info bin or txt...\n$ vim /etc/host                #idk\n$ vim /etc/hostname            #change host name in vim\n$ hostname name_example        #change hostname in command\n$ free -m                      #memmory utilization\n$ df -h                        #disk partition\n$ uptime                       #\n$ date                         #\n$ wc -l /etc/passwd            #count number of lines in file\n$ cat /proc/cpuinfo            #cpuinfo\n$ tail -f err.log              #follow log file\n\n\n\nFILE:\nuptime &gt; /tmp/sysinfo.txt            #write command to file\nuptime &gt;&gt; /tmp/sysinfo.txt           #append command to file\necho \"your_text\" &gt; tmp/sysinfo.txt   #write text to file\necho \"your_text\" &gt;&gt; tmp/sysinfo.txt  #append text to file\ncat /dev/null &gt; /tmp/sysinfo.txt     #clear file\nfreeee -m 1&gt;&gt; /tmp/error.log         #will not do error to file\nfreeee -m 2&gt;&gt; /tmp/error.log         #get error text to file\nfreeee -m &amp;&gt;&gt; /tmp/error.log         #get error text or command if works to file\n</code></pre>"},{"location":"linux/commands/#get-help-with-any-command","title":"Get help with any command:","text":"<p><code>command --help</code> e.g. <code>ls --help</code></p>"},{"location":"linux/commands/#advanced-commands","title":"Advanced commands:","text":"<pre><code>$ ls -lhatr                   # -l (long format), -h (human-readable sizes), -a (all files include hidden files), -t (sort by modification time, recently modified files first), -r (reverse)\n$ cat /etc/os-release         #OS name &amp; Version from CLI\n$ touch testfile{1..10}.txt   #create 10 files\n</code></pre>"},{"location":"linux/crontab/","title":"Crontab","text":"<p>edit crontab: <code>crontab -e</code></p> <p>first 5 parameters is time and after that is the command </p>"},{"location":"linux/distros/","title":"Popular linux distributions (differences)","text":""},{"location":"linux/distros/#popular-desktop-linux-os","title":"Popular Desktop Linux OS","text":"<ul> <li><code>Ubuntu Linux</code></li> <li><code>Linux Mint</code></li> <li><code>Arch Linux</code></li> <li><code>Fedora</code></li> <li><code>Debian</code></li> <li><code>OpenSuse</code></li> </ul>"},{"location":"linux/distros/#popular-server-linux-os","title":"Popular Server Linux OS","text":"<ul> <li><code>Red Hat Enterprise Linux</code></li> <li><code>Ubuntu Server</code></li> <li><code>Centos</code></li> <li><code>SUSE Enterprise Linux</code></li> </ul>"},{"location":"linux/distros/#rpb-vs-debian","title":"RPB vs Debian","text":"<ul> <li><code>.rpm</code> RPM based distros: <code>RHEL</code> <code>CentOS</code> <code>Oracle</code> <code>Linux</code> \u2192 E.g. installation: <code>rpm -ivh google-chrome.rpm</code></li> <li><code>.deb</code> Debian Based distros: <code>Ubuntu Server</code> <code>Kali Linux</code> \u2192 E.g. installation: <code>dpkg -i google-chrome.deb</code></li> </ul>"},{"location":"linux/env_var/","title":"Environment Variables","text":""},{"location":"linux/env_var/#option-1-activate-from-cli-command-line-interface","title":"Option 1: Activate from CLI (Command Line Interface)","text":"<pre><code>export team=ops\n</code></pre> <p>The <code>export</code> keyword is required so that the variable is available to child processes, such as scripts or applications launched from your shell.</p> <p>Validate <pre><code>echo $team\n</code></pre></p>"},{"location":"linux/env_var/#option-2-activate-variables-while-starting-a-script","title":"Option 2: Activate Variables While Starting a Script","text":"<p>You can set a temporary environment variable just for the duration of a command</p> <pre><code>team=ops python3 main.py\n</code></pre> <p>Sets team=ops only for the main.py process and any child processes that main.py spawns.</p>"},{"location":"linux/env_var/#option-3-activate-from-env-file","title":"Option 3: Activate from <code>.env</code> file","text":"<ol> <li>Create the <code>.env</code> file:</li> </ol> <pre><code>echo \"export team=ops\" &gt;&gt; .env\n</code></pre> <ol> <li>Load the environment variables:</li> </ol> <pre><code>source .env\n</code></pre> <p>Using <code>export</code> in the <code>.env</code> file ensures the variable is available to child processes.</p>"},{"location":"linux/env_var/#repository-security","title":"Repository Security","text":"<p>To keep environment variables secure, ensure <code>.env</code> is ignored by version control:</p> <pre><code>echo \".env\" &gt;&gt; .gitignore\n</code></pre> <p>This prevents accidentally committing sensitive information to your repository.</p>"},{"location":"linux/env_var/#print-environments-activated-for-a-specific-pid","title":"Print environments activated for a specific PID","text":"<pre><code>MY_PID=$$ \\\n&amp;&amp; cat /proc/$MY_PID/environ\n</code></pre>"},{"location":"linux/file_system/","title":"File System","text":""},{"location":"linux/file_system/#root-tree","title":"Root Tree","text":"<pre><code>/\n\u251c\u2500\u2500 bin\n\u251c\u2500\u2500 boot\n\u2502   \u251c\u2500\u2500 vmlinuz-&lt;version&gt;\n\u2502   \u2514\u2500\u2500 grub/\n\u251c\u2500\u2500 dev\n\u251c\u2500\u2500 etc\n\u2502   \u251c\u2500\u2500 passwd\n\u2502   \u251c\u2500\u2500 group\n\u2502   \u251c\u2500\u2500 hosts\n\u2502   \u251c\u2500\u2500 resolv.conf\n\u2502   \u251c\u2500\u2500 ssh/\n\u2502   \u2502   \u2514\u2500\u2500 sshd_config\n\u2502   \u2514\u2500\u2500 systemd/\n\u2502       \u2514\u2500\u2500 system/\n\u251c\u2500\u2500 home\n\u2502   \u2514\u2500\u2500 user/\n\u2502       \u251c\u2500\u2500 .bashrc\n\u2502       \u251c\u2500\u2500 .profile\n\u2502       \u2514\u2500\u2500 projects/\n\u251c\u2500\u2500 lib\n\u251c\u2500\u2500 lib64\n\u251c\u2500\u2500 media\n\u251c\u2500\u2500 mnt\n\u251c\u2500\u2500 opt\n\u251c\u2500\u2500 proc\n\u251c\u2500\u2500 root\n\u251c\u2500\u2500 run\n\u251c\u2500\u2500 sbin\n\u251c\u2500\u2500 srv\n\u251c\u2500\u2500 sys\n\u251c\u2500\u2500 tmp\n\u251c\u2500\u2500 usr\n\u2502   \u251c\u2500\u2500 bin\n\u2502   \u251c\u2500\u2500 lib\n\u2502   \u251c\u2500\u2500 libexec\n\u2502   \u251c\u2500\u2500 sbin\n\u2502   \u251c\u2500\u2500 share\n\u2502   \u2514\u2500\u2500 local/\n\u2502       \u251c\u2500\u2500 bin\n\u2502       \u2514\u2500\u2500 lib\n\u2514\u2500\u2500 var\n    \u251c\u2500\u2500 cache\n    \u251c\u2500\u2500 lib\n    \u251c\u2500\u2500 log/\n    \u2502   \u2514\u2500\u2500 syslog\n    \u251c\u2500\u2500 mail\n    \u251c\u2500\u2500 run\n    \u2514\u2500\u2500 www\n</code></pre>"},{"location":"linux/file_system/#explanation","title":"Explanation","text":"<p>Binaries: <code>/bin</code> <code>/usr/bin</code> <code>/usr/local/bin</code></p> <ul> <li>executable examples: <code>ls</code> <code>mkdir</code> <code>rm</code> <code>cd</code>.</li> </ul> <p>System/SuperUser Binaries: <code>/sbin</code> <code>/usr/sbin</code> <code>/usr/local/sbin</code></p> <ul> <li>executable example: <code>deluser</code>.</li> </ul> <p>User: <code>/usr</code></p> <ul> <li>INFO: long list of things that needs to be shared between apps and services.</li> <li>many binaries files lives here.</li> </ul> <p>Optional: <code>/opt</code></p> <ul> <li>additional software &amp; add-on packages (not part of default installation).</li> <li>software that you build and compile sometimes land.</li> <li>applications -&gt; <code>/opt/bin</code>.</li> <li>libraries -&gt; <code>/opt/lib</code>.</li> </ul> <p>Configuration: <code>/etc</code></p> <ul> <li><code>*.conf</code></li> </ul> <p>Boot: <code>/boot</code></p> <ul> <li>files to boot a linux combuter e.g.: kernel &amp; bootloader.</li> </ul> <p>Shared Libraries: <code>/lib</code> <code>/usr/lib</code> <code>usr/local/lib</code></p> <ul> <li>libraries for system programs.</li> <li>binaries required to boot the system.</li> </ul> <p>Temporary Files: <code>/tmp</code></p> <ul> <li>temporary files placed there by apps that are running.</li> </ul> <p>Var: <code>/var</code></p> <ul> <li>logs: <code>var/logs</code></li> <li>tasks: </li> <li>temp files between reboots: </li> <li>snap dir on ubuntu: </li> </ul> <p>Server Data: <code>/srv</code></p> <p>Device: <code>/dev</code></p> <ul> <li>USB devices</li> </ul> <p>Mount: <code>/mnt</code></p> <ul> <li>mount other file systems or storage devices for short period of time.</li> <li>not used very often nowadays.</li> </ul> <p>Media: <code>/media</code></p> <ul> <li>external storage devices will be automatically mounted here.</li> </ul> <p>System Information: <code>/proc</code> <code>/sys</code></p> <p>Home Directory: <code>/home/user</code></p> <p>Superuser Home Directory: <code>/root</code></p>"},{"location":"linux/filter/","title":"Filter","text":""},{"location":"linux/filter/#grep","title":"Grep","text":"<p><pre><code>grep -orIinm1 --color=always --exclude-dir=\".git\" \"replace_me\" ./ | cut -c1-1000 &amp;&amp; tput sgr0\n</code></pre> <pre><code>less -I +5 +/replace_me file.txt\nless -I +5 file.txt\nnvim +5 file.txt\n</code></pre></p>"},{"location":"linux/filter/#find","title":"Find","text":"<pre><code>find . -path \"./.git\" -prune -o -name \"*.txt\" -print\n</code></pre>"},{"location":"linux/filter/#extra-commands","title":"Extra Commands","text":""},{"location":"linux/filter/#filter_1","title":"Filter","text":"<pre><code>grep -i firewall example.txt         #looking for \"firewall\" pattern in example.txt wheter the letters are capital or not.\ngrep -i firewall &lt; example.txt       #\ngrep -i firewall *                   #lookin for firewall word in all files.\ngrep -iR firewall *                  #\ngrep -R SELINUX /etc/*               #search for \"SELINUX\" in all file and directories in etc\ngrep -vi firewall example.txt        #everything that do not contain firewall pattern\nless example.txt                     #\nmore example.txt                     #\nhead -10 example.txt                 #first 10 lines\ntail -10 example.txt                 #last 10 lines\ntail -f var/log/messages             #monitor system log messages in real time\ncut -d: -f1 /etc/passwd              #cut separator\nawk -F':' '{print $1}' /etc/passwd   #awk separator\nsed -i 's/word/new_word/g' *.txt     #replace all words containing coronavirus to covid19 to all txt files             #\nfind /etc -name 'host*'              #\n\nFIRST-COMMAND$ updatedb              #updates path\nSECOND-COMMAND$ locate host          #search for files that are named \"host\" \n</code></pre>"},{"location":"linux/filter/#pipes","title":"PIPES","text":"<pre><code>ls | wc -l                                         #count number of files\nls | grep host                                     #lists all that starts with host\ntail -20 /var/log/messages | grep -i vagrant       #\nfree -m | grep Mem                                 #\nls -l | head                                       #\n</code></pre>"},{"location":"linux/kernel/","title":"Kernel","text":"<pre><code>graph TD\nS[\"Software\"]\nK[\"Kernel\"]\nH[\"HARDWARE\"]\n\nS &lt;--&gt; K\nK &lt;--&gt; H</code></pre> <p>Kernel operates hardware on low level</p> <p>Whenever you compile and run your C code, then the C-library uses system calls</p> <p>It accepts system calls to perform functions</p>"},{"location":"linux/kernel/#kernel-is-monolithic","title":"Kernel is monolithic","text":"<ul> <li> <p>more built in to it compared to other kernels (Windows NT, MacOS)</p> </li> <li> <p>a lot of included drivers</p> </li> <li>GPU</li> <li>peripherals (pen tablets)</li> <li>don't get option to edit/remove features (unless you compile the kernel yourself)</li> </ul>"},{"location":"linux/kernel/#videos","title":"Videos","text":"<p>The Linux Kernel: What it is it</p> <p>Kernel to IoT</p>"},{"location":"linux/path/","title":"Path","text":""},{"location":"linux/path/#what-is-path-in-linux","title":"What is PATH in Linux?","text":"<p>The PATH is an environment variable that tells Linux where to look for executable programs. When you type a command, Linux searches through the directories listed in PATH to find the program to execute.</p>"},{"location":"linux/path/#check-path","title":"Check PATH","text":"<p><pre><code>echo $PATH\n</code></pre> or <pre><code>printenv PATH\n</code></pre></p> <p>output example: <pre><code>/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n</code></pre></p>"},{"location":"linux/path/#adding-a-new-path-temporarily","title":"Adding a new PATH temporarily","text":"<p>To add a new directory to PATH for your current terminal session: <pre><code>export PATH=$PATH:/your/new/path\n</code></pre></p>"},{"location":"linux/path/#adding-a-path-permanently","title":"Adding a PATH permanently","text":"<ol> <li>Edit your shell's configuration file:</li> <li> <p>For Bash:    <pre><code>nano ~/.bashrc\n</code></pre></p> </li> <li> <p>Add this line at the end of the file: <pre><code>export PATH=$PATH:/your/new/path\n</code></pre></p> </li> <li> <p>Save and apply changes: <pre><code>source ~/.bashrc\n</code></pre></p> </li> <li> <p>Validate newly appended PATH: <pre><code>which program_name\n</code></pre></p> </li> </ol>"},{"location":"linux/path/#common-path-locations","title":"Common PATH locations","text":"<ul> <li><code>/bin</code>: Essential user commands</li> <li><code>/usr/bin</code>: Most user commands</li> <li><code>/usr/local/bin</code>: User-installed programs</li> <li><code>/sbin</code>: System administration commands</li> <li><code>/usr/sbin</code>: Additional system admin commands</li> </ul>"},{"location":"linux/path/#tips-for-beginners","title":"Tips for Beginners","text":"<ol> <li>Never remove default PATH directories</li> <li>Keep custom scripts in <code>~/bin</code> or <code>/usr/local/bin</code></li> <li>Use absolute paths when adding new directories</li> <li>Separate multiple paths with colons (:)</li> </ol>"},{"location":"linux/permission/","title":"Permission","text":""},{"location":"linux/permission/#file-permission-bits","title":"File Permission Bits","text":""},{"location":"linux/permission/#bit-list","title":"Bit list","text":""},{"location":"linux/permission/#bit-and-type-reference-table","title":"Bit and Type Reference Table","text":""},{"location":"linux/permission/#bit-and-type-reference-table_1","title":"Bit and Type Reference Table","text":"Symbol Meaning Applies To Numeric (Octal) Structure Example Notes <code>-</code> Regular file Files (n/a) <code>-rw-r--r--</code> Standard file (text, binary, script, etc.) <code>d</code> Directory Directories (n/a) <code>drwxr-xr-x</code> Contains files/subdirectories <code>l</code> Symbolic link Files (n/a) <code>lrwxrwxrwx</code> Points to another file or directory <code>b</code> Block device Devices (n/a) <code>brw-rw----</code> Device file providing buffered I/O (e.g. disks) <code>c</code> Character device Devices (n/a) <code>crw-rw----</code> Device file providing unbuffered I/O (e.g. serial ports) <code>p</code> Named pipe (FIFO) Special files (n/a) <code>prw-r--r--</code> Enables interprocess communication through a pipe <code>s</code> Socket Special files (n/a) <code>srwxr-xr-x</code> Used for network or interprocess communication <code>r</code> Read Files &amp; Directories <code>4</code> <code>-r--r--r--</code> Read file contents / list directory <code>w</code> Write Files &amp; Directories <code>2</code> <code>--w--w--w-</code> Modify file / create or delete files in directory <code>x</code> Execute Files &amp; Directories <code>1</code> <code>---x--x--x</code> Run file / enter directory (<code>cd</code>) <code>T</code> Sticky bit set, but execute bit missing Directories only <code>1</code> (special bit) <code>drwxrwxrwT</code> Files inside can only be deleted or renamed by their owner, the directory\u2019s owner, or root <code>t</code> Sticky bit + execute bit set Directories only <code>1</code> (special bit) <code>drwxrwxrwt</code> Files inside can only be deleted or renamed by their owner, the directory\u2019s owner, or root <code>S</code> Setuid/Setgid bit set, but execute bit missing Files &amp; Directories <code>4</code> (setuid) / <code>2</code> (setgid) <code>-rwSr--r--</code> Means <code>s</code> bit is active but no execute (<code>x</code>) permission <code>s</code> Setuid/Setgid + execute bit set Files &amp; Directories <code>4</code> (setuid) / <code>2</code> (setgid) <code>-rwsr-sr-x</code> <ul><li>File (user): run as file owner (setuid)</li><li>File (group): run as file group (setgid)</li><li>File (others): no effect (acts like <code>x</code>)</li><li>Directory (group): new files inherit directory\u2019s group</li></ul> <code>.</code> SELinux context or extended attributes Files &amp; Directories (n/a) <code>drwxr-xr-x.</code> Indicates extra metadata; check with <code>ls -Z</code> <code>+</code> Access Control List (ACL) Files &amp; Directories (n/a) <code>drwxr-xr-x+</code> Shows extra ACL entries; check with <code>getfacl</code>"},{"location":"linux/permission/#file-structure","title":"File Structure","text":"<p>Structure of <code>ls -l</code> Output: <pre><code>drwxrwsrwt.  2 &lt;owner&gt; &lt;group&gt;  40  Jul  5 14:09  &lt;name&gt;\n^            ^    ^       ^      ^  ^^^^^^^^^^^^^   ^\n|            |    |       |      |        |         \u2514\u2500\u2500\u2500\u2500\u2500 filename\n|            |    |       |      |        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 modification time\n|            |    |       |      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 size (bytes; for dirs: entry size)\n|            |    |       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 group owner\n|            |    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 user owner\n|            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 link count (dirs: 2 + #subdirs)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 type+perms (d/-, r/w/x, s, t)\n</code></pre></p> <p>Example: <pre><code>drwxrwsrwt.  2 alex devteam  40 Jul  5 14:09 shared_dir\n</code></pre></p> <p>Breakdown:</p> Section Example Meaning 1st character <code>d</code> File type \u2192 <code>-</code> = file, <code>d</code> = directory, <code>l</code> = symlink, etc. 2nd\u20134th <code>rwx</code> Owner (user) permissions: read, write, execute 5th\u20137th <code>rws</code> Group permissions: read, write, execute/setgid 8th\u201310th <code>rwt</code> Others permissions: read, write, execute/sticky <code>.</code> or <code>+</code> <code>.</code> SELinux (<code>.</code>) or ACL (<code>+</code>) indicator Link count <code>2</code> Number of hard links (for dirs: itself + subdirs) Owner <code>alex</code> User who owns the file Group <code>devteam</code> Group owner File size <code>40</code> Size in bytes (for directories: metadata size) Date <code>Jul 5 14:09</code> Last modification date/time Filename <code>shared_dir</code> The name of the file or directory"},{"location":"linux/permission/#change-permission","title":"Change Permission","text":""},{"location":"linux/permission/#octal-numeric-mode","title":"Octal (numeric) mode","text":"<p>Pattern</p> <pre><code>chmod [SPECIAL][OWNER][GROUP][OTHERS] TARGET\n</code></pre> <ul> <li>OWNER/GROUP/OTHERS are each a digit 0\u20137 combining <code>r=4</code>, <code>w=2</code>, <code>x=1</code>.</li> <li>SPECIAL (optional, leading digit) combines: setuid=4, setgid=2, sticky=1.</li> </ul> <p>Examples</p> <pre><code>chmod 700  file     # rwx------            (owner only)\nchmod 644  file     # rw-r--r--            (common for text files)\nchmod 755  file     # rwxr-xr-x            (common for executables)\nchmod 775  dir      # rwxrwxr-x            (team directories)\nchmod 770  devopsdir/  # rwxrwx---         (owner+group full, others none)\n\n# Special bits\nchmod 4755 file     # setuid + 755  \u2192 -rwsr-xr-x\nchmod 2755 file     # setgid + 755  \u2192 -rwxr-sr-x\nchmod 6755 file     # suid+sgid+755 \u2192 -rwsr-sr-x\nchmod 1777 dir      # sticky + 777  \u2192 drwxrwxrwt (like /tmp)\n</code></pre>"},{"location":"linux/permission/#symbolic-mode","title":"Symbolic mode","text":"<p>Syntax</p> <pre><code>chmod [ugoa][+-=][rwxXst] TARGET...\n</code></pre> <ul> <li>Who: <code>u</code> (owner), <code>g</code> (group), <code>o</code> (others), <code>a</code> (all)</li> <li>Operation: <code>+</code> add, <code>-</code> remove, <code>=</code> set exactly</li> <li>Bits: <code>r</code> read, <code>w</code> write, <code>x</code> execute, <code>X</code> conditional execute (dirs or if any execute bit already set), <code>s</code> setuid/setgid, <code>t</code> sticky</li> </ul> <p>Examples</p> <pre><code># Remove read for others\nchmod o-r /opt/devopsdir\n\n# Add write for group\nchmod g+w /opt/devopsdir\n\n# Remove execute for owner (on a directory this prevents cd for owner)\nchmod u-x /opt/devopsdir\n\n# Add setgid on a directory so new files inherit the directory's group\nchmod g+s /opt/devopsdir\n\n# Add sticky bit so only owners can delete their own files in a shared dir\nchmod +t /opt/share\n\n# For the group, set only read (r) and execute (x) permissions \u2014 and remove everything else, including write (w).\nchmod g=rx\n</code></pre>"},{"location":"linux/permission/#ownership-chown","title":"Ownership: chown","text":"<p>Syntax: <pre><code>chown\n</code></pre> chown [FLAGS] USER[:GROUP] TARGET <pre><code>Common flags\n- `-R` - recursive (apply to all files and subdirectories)\n\nExamples\n</code></pre></p>"},{"location":"linux/permission/#set-both-user-and-group-recursively","title":"Set both user and group recursively","text":"<p>chown -R ansible:devops /opt/devopsdir</p>"},{"location":"linux/permission/#set-only-user","title":"Set only user","text":"<p>chown ansible /opt/devopsdir</p>"},{"location":"linux/permission/#set-only-group","title":"Set only group","text":"<p>chown :devops /opt/devopsdir  chown -R ansible:devops directory chmod o-r /opt/devopsdir chmod g+w /opt/devopsdir chmod u-x /opt/devopsdir chmod 770 devopsdir/ <pre><code>```shell\nsudo usermod -a -G mygroup jenkins\nsudo groupadd mygroup\nsudo chown -R alex:mygroup /home/alex/test\n</code></pre></p> <pre><code>sudo chown jenkins:jenkins /home/alex/test\nsudo chown -R jenkins:jenkins /home/alex # add group to all\n</code></pre> <p>Users</p> <pre><code>sudo useradd alex2\nsudo passwd alex2\nsu alex2\n</code></pre>"},{"location":"linux/permission/#groups","title":"Groups","text":"<pre><code>cat /etc/passwd\ncat /etc/groups\nid vagrant\nuseradd dev\npasswd dev\nusrdel dev\nusrdel -r dev                   #delete user along with his home directory\nsu - dev                        #login\ngroupadd devops\ngroupdel devops\nusermod -aG devops dev\nid ansible\nvim /etc/group\n\nlast\nwho\nlsof -u vagrant                 #will list files opened by user \n</code></pre>"},{"location":"linux/permission/#add-sudo-usergroup","title":"Add Sudo User/Group","text":""},{"location":"linux/permission/#option-a-not-safe","title":"Option A (not safe):","text":"<p><pre><code>visudo     #edit /etc/sudoers file\n</code></pre> <code>add user:</code> <pre><code>100    root    ALL=(ALL)       ALL\n101    ansible ALL=(ALL)       NOPASSWD: ALL\n</code></pre> <code>add group:</code> <pre><code>100    root     ALL=(ALL)       ALL\n101    %ansible ALL=(ALL)       NOPASSWD: ALL\n</code></pre></p>"},{"location":"linux/permission/#option-b-safe","title":"Option B (safe):","text":"<p><pre><code>cd /etc/sudoers.d\ncp vagrant devops\nvim devops\n</code></pre> <code>add user:</code> <pre><code>devops ALL=(ALL) NOPASSWD: ALL\n</code></pre> <code>add group:</code> <pre><code>%devops ALL=(ALL) NOPASSWD: ALL\n</code></pre></p>"},{"location":"linux/permission/#verification-commands","title":"Verification commands","text":"<pre><code># Show long listing of a directory itself (not its contents)\nls -ld /opt/devopsdir\n\n\n# Confirm inheritance behavior\ntouch /opt/devopsdir/test\nls -l /opt/devopsdir/test\n\n\n# Show ACLs / SELinux\ngetfacl /opt/devopsdir\nls -Z /opt/devopsdir\n</code></pre>"},{"location":"linux/services/","title":"Services (CentOS)","text":"<p>lets analize httpd (do this before: <code>yum install httpd</code>)</p> <pre><code>systemctl status httpd\nsystemctl start httpd\nsystemctl stop httpd\nsystemctl restart httpd\nsystemctl reload httpd\nsystemctl enable httpd\nsystectl disable httpd\nsystemctl is-active httpd\nsystemctl is-enabled httpd\n</code></pre> <p>where the config file is created for httpd when installed:</p> <pre><code>cat /etc/systemd/system/multi-user.target.wants/httpd.service\n</code></pre>"},{"location":"linux/services/#processes","title":"Processes","text":"<pre><code>top\nps aux\nps -ef\nps -ef | grep httpd | grep -v \"grep\"\nkill 1420                              #kill process and close child processes if the process is a parent.\nkill -9 1420                           #kill the process without closing child processes\nps -ef | grep httpd | grep -v \"grep\" | awk \"{print $2}\"\nps -ef | grep httpd | grep -v \"grep\" | awk \"{print $2}\" | xargs kill -9\n</code></pre>"},{"location":"linux/user/","title":"User","text":""},{"location":"linux/user/#user-prompt","title":"User prompt","text":"<p><code>[steve@localhost ~]$</code></p> <ul> <li>username: <code>steve</code></li> <li>hostname: <code>localhost</code></li> <li>home-directory: <code>~</code></li> <li>normal user: <code>$</code></li> <li>system administrator(root): <code>#</code> (will replace the dollar($) sign when switching to root user)</li> </ul>"},{"location":"linux/user/#user-home-path","title":"User home path","text":"<ul> <li><code>/home/$USER</code></li> </ul>"},{"location":"linux/vim/","title":"Vim","text":""},{"location":"linux/vim/#how-to-edit-or-create-a-file-with-the-vim-text-editor","title":"How to edit or create a file with the Vim text editor","text":"<pre><code>$ vim file.txt    # create a text file and open it in Vim\n</code></pre>"},{"location":"linux/vim/#common-commands-while-editing-in-vim","title":"Common commands (while editing in Vim)","text":"<ul> <li>Enter insert mode (edit): <code>i</code></li> <li>Enter insert mode and create a new line below the cursor: <code>o</code></li> <li>Save file: <code>Esc</code> then <code>:w</code> then <code>Enter</code></li> <li>Quit file: <code>Esc</code> then <code>:q</code> then <code>Enter</code></li> <li>Quit file without saving: <code>Esc</code> then <code>:q!</code> then <code>Enter</code></li> <li>Save and quit: <code>Esc</code> then <code>:wq</code> then <code>Enter</code> OR <code>Esc</code> then <code>:x</code> then <code>Enter</code></li> <li>Show line numbers: <code>Esc</code> then <code>:set number</code> (or <code>:se nu</code>)</li> <li>Go to the last line: <code>Shift</code> + <code>G</code></li> <li>Go to the first line: <code>gg</code></li> <li>Copy a line: <code>yy</code> (or <code>3yy</code> to copy 3 lines)</li> <li>Select multiple lines (visual line mode): <code>Shift</code> + <code>V</code> then use <code>j</code>/<code>k</code> to move down/up</li> <li>Copy lines 10 to 20: <code>:10,20y</code></li> <li>Paste line above: <code>Shift</code> + <code>P</code></li> <li>Paste line below: <code>p</code></li> <li>Cut (delete) a line: <code>dd</code></li> <li>Search for a pattern: <code>/pattern</code> then <code>Enter</code></li> <li>Undo: <code>u</code></li> <li>Redo: <code>Ctrl</code> + <code>R</code></li> <li>Replace all occurrences of a word: <code>:%s/name/new_name/g</code></li> <li>Replace a literal dot in a pattern (example: replace <code>name.main</code> with <code>name.rg</code>): <code>:%s/name\\.main/name\\.rg/g</code></li> </ul>"},{"location":"networking/","title":"Networking","text":"<p>This is a documentation site about Networking, covering various topics.</p> <p>Use the left sidebar to navigate through different sections.</p>"},{"location":"networking/OSI/","title":"OSI Model","text":""},{"location":"networking/OSI/#osi-layers","title":"OSI Layers","text":"<pre><code>graph TD\n1[\"1. Physical\"]\n2[\"2. Data Link\"]\n3[\"3. Network\"]\n4[\"4. Transport\"]\n5[\"5. Session\"]\n6[\"6. Presentation\"]\n7[\"7. Application\"]\n\n7 &lt;--&gt; 6 &lt;--&gt; 5 &lt;--&gt; 4 &lt;--&gt; 3 &lt;--&gt; 2 &lt;--&gt; 1</code></pre>"},{"location":"networking/OSI/#7-application","title":"7. Application","text":""},{"location":"networking/OSI/#6-presentation","title":"6. Presentation","text":""},{"location":"networking/OSI/#5-session","title":"5. Session","text":""},{"location":"networking/OSI/#4-transport","title":"4. Transport","text":"<p>Transmits data using transmission protocols including TCP &amp; UDP</p>"},{"location":"networking/OSI/#3-network","title":"3. Network","text":"<p>Decides which physical path the data will take.</p> <p>Routing data and logical addressing (e.g. IP), determining the best path from source to destination across networks.</p>"},{"location":"networking/OSI/#2-data-link","title":"2. Data Link","text":"<p>Defines the format of data on the network</p> <ol> <li>Receives data from physical layer</li> <li>Checks for transmission errors</li> <li>Packages bits to data frames (e.g.: <code>| MAC1 | MAC2 | IP1 IP2 Segment | FCS</code>)</li> <li>Manages the physical addressing layer:</li> <li>Media Access Control (MAC)</li> <li>Logical Link Control (LLC)</li> </ol>"},{"location":"networking/OSI/#1-physical","title":"1. Physical","text":"<p>Transmission and reception of raw bitstreams over a physical medium.</p> <p>e.g.: network cable, power plug, wireless, pulses of light.</p>"},{"location":"networking/OSI/#table-of-osi-layers","title":"Table of OSI Layers","text":"Layer Name # Info 7 Application HTTP, SSH, DNS, IRC, FTP 6 Presentation SSL, SSH, IMAP, FTP, MPEG, JPEG 5 Session API, Socket, WinSock 4 Transport TCP, UDP 3 Network IP, ICMP, IPSec, IGMP 2 Data Link Ethernet, PPP, Switch, Bridge 1 Physical Coax, Fiber, Wireless, Hubs, Repeaters"},{"location":"networking/OSI/#links","title":"Links","text":"<p>What is OSI (video)</p> <p>OSI Deep Dive (video)</p> <p>What is OSI (cloudflare)</p>"},{"location":"networking/ip/","title":"IP (Internet Protocol)","text":""},{"location":"networking/ip/#ip-classes","title":"IP classes","text":"Class Public IP range Private IP range Subnet mask # of Networks # of hosts per network Class A 1.0.0.0 to 127.0.0.0 10.0.0.0 to 10.255.255.255 255.0.0.0 126 16,777,214 Class B 128.0.0.0 to 191.255.0.0 172.16.0.0 to 172.31.255.255 255.255.0.0 16,382 65,534 Class C 192.0.0.0 to 223.255.255.0 192.168.0.0 to 192.168.255.255 255.255.255.0 2,097,150 254"},{"location":"networking/linux_commands/","title":"Linux network commands","text":"<p>test connection to host: ping www.google.com</p> <p>ports: netstat -antp</p> <p>check port: telnet ip port</p> <p>nmap: nmap localhost</p> <p>DNS Lookup: dig www.google.com or nslookup www.google.com</p> <p>Gateways: route -n or route</p> <p>Macadress (kernels arp table): arp</p> <p>Live Packets: mtr</p> <p>edit host file: vim /etc/hosts</p>"}]}